{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Image Captioning Using Encoder-Decoder Architecture.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OepSu4Uv8Hg3"
      },
      "source": [
        "In this notebook, you would need to use **Python 3.6+** along with the following packages (**need to update**):\n",
        "```\n",
        "1. pytorch 1.2\n",
        "2. torchvision\n",
        "3. numpy\n",
        "4. matplotlib\n",
        "5. nltk\n",
        "```\n",
        "To install pytorch, please follow the instructions on the [Official website](https://pytorch.org/). In addition, the [official document](https://pytorch.org/docs/stable/) could be very helpful when you want to find certain functionalities. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvSJ_SPO8HhA"
      },
      "source": [
        "# Image Captioning Using Encoder-Decoder Architecture\n",
        "\n",
        "Simply, the encoder will take the image as input and encode it into a vector of feature values. The decoder will take this output from encoder as hidden state and starts to predict next words at each step. The following figure illustrates this:\n",
        "\n",
        "<img src=\"figs/image_captioning_overview.jpg\" width=\"600\">\n",
        "Figure 1. An overview of the encoder-decoder architecture\n",
        "(image credit: <a href=\"https://link.springer.com/chapter/10.1007/978-3-030-04780-1_23\">Deep Neural Network Based Image Captioning</a>)\n",
        "\n",
        "You will use a pre-trained CNN as the encoder and Vanilla RNN/LSTM as decoder to predict the captions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu_6wLOv8HhB"
      },
      "source": [
        "## How to download the data (Google Colab)\n",
        "Step 1: Register a Kaggle account.  https://www.kaggle.com/\n",
        "\n",
        "Step 2: Download your kaggle.json file from  https://www.kaggle.com/Your_Username/account. In API section, click Create New API Token.\n",
        "\n",
        "Step 3: As we did before, upload all files on Google Drive and open Google Colab.\n",
        "\n",
        "Step 4: Install required packages.\n",
        "    \n",
        "    ! pip install -q kaggle nltk\n",
        "\n",
        "Step 5: Insert a cell.\n",
        "    \n",
        "    \n",
        "    from google.colab import files\n",
        "    files.upload()\n",
        "    \n",
        "    \n",
        "    Upload `kaggle.json` you just downloaded.\n",
        "    \n",
        "Step 6: Move `kaggle.json` to the right place,\n",
        "    \n",
        "    \n",
        "     ! mkdir ~/.kaggle\n",
        "     ! cp kaggle.json ~/.kaggle/\n",
        "    \n",
        "\n",
        "Step 7: Change the permission.\n",
        "    \n",
        "    ! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "Step 8: Download.\n",
        "    \n",
        "    !kaggle datasets download hsankesara/flickr-image-dataset\n",
        "\n",
        "Step 9: Move it to your drive and unzip it.\n",
        "    \n",
        "    unzip flickr-image-dataset.zip -x \"flickr30k_images/flickr30k_images/flickr30k_images/*.jpg\" -d \"/path-to-Assignment_4/Assignment_4/\"\n",
        "    \n",
        "Step 10: Move \"dataset_flickr30k.json\" to \"flickr30k_images\" folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyElxqoH8HhC"
      },
      "source": [
        "### Colab Setup: \n",
        "- Below are some basic steps for colab setup. \n",
        "- Make changes based on requirements.\n",
        "- Comment out in case of ARC or your local device with powerful GPU.\n",
        "\n",
        "**Note: For Google Colab give proper paths in this notebook and in dataloader.py if required.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if42ubve8XXp"
      },
      "source": [
        "#! pip install -q kaggle nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lep08MT78hP2"
      },
      "source": [
        "#from google.colab import files\n",
        "#files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb9eBK_u84Sg"
      },
      "source": [
        " #! mkdir ~/.kaggle\n",
        "# ! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y2vkK2b8_1j"
      },
      "source": [
        "#! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz9dy8j89Iem"
      },
      "source": [
        "#!kaggle datasets download hsankesara/flickr-image-dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRx6lxcr-aZc"
      },
      "source": [
        "#!unzip flickr-image-dataset.zip -x \"flickr30k_images/flickr30k_images/flickr30k_images/*.jpg\" -d \"/content/drive/My Drive/Assignment_4/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmcYLPqB8HhD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99590944-2117-468b-e3b2-eff227be2a5d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y_5A2Sr8HhG"
      },
      "source": [
        "import sys\n",
        "# modify \"customized_path_to_homework\", path of folder in drive, where you uploaded your homework\n",
        "path_to_homework = \"/content/drive/My Drive/Assignment_4/\"\n",
        "sys.path.append(path_to_homework)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG2quhmmwKnX"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjuvc_rn8Hg4"
      },
      "source": [
        "# import necessary packages and modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da3UihoW8HhK"
      },
      "source": [
        "from dataloader import Flickr30k, get_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVH8mVVa8HhQ"
      },
      "source": [
        "# Section 1.2 Take a look at the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpnaeqDj8HhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7c239fe-826c-4698-e7da-eb5d3cbb4b6d"
      },
      "source": [
        "# visualize images and captions\n",
        "flickr = Flickr30k(split='val', root=path_to_homework+'flickr30k_images/')  # load validation set as an example\n",
        "flickr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------flickr30k--------\n",
            "image root: /content/drive/My Drive/Assignment_4/flickr30k_images/flickr30k_images\n",
            "dataset split: val\n",
            "the length of the dataset: 1014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VROo-PZ48Hhe"
      },
      "source": [
        "# Section 1.3 Build vocabulary\n",
        "We need to build a vocabulary for our dataset. The vocabulary stores all the words and their indices. We will use it to embed and recover the words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAmNQ0FM8Hhf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a704faf-c29b-4f6b-9f52-dc53b8da0d7a"
      },
      "source": [
        "import nltk\n",
        "import pickle\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "nltk.download('punkt') # You can comment this line once you've downloaded 'punkt'\n",
        "\n",
        "class Vocabulary(object):\n",
        "    \"\"\"Simple vocabulary wrapper.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.word2idx = {'<pad>': 0, '<unk>': 1, '<start>': 2, '<end>': 3}  # follow Pytorch padding rules: pad sentence with zero.\n",
        "        self.idx = 4\n",
        "        self.idx2word = {v: k for k, v in self.word2idx.items()}\n",
        "\n",
        "    def __call__(self, key):\n",
        "        if key not in self.word2idx:\n",
        "            return self.word2idx['<unk>']\n",
        "        return self.word2idx[key]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.word2idx)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        \"\"\"\n",
        "        Add new words\n",
        "        :param word: word\n",
        "        \"\"\"\n",
        "        if word not in self.word2idx:\n",
        "            self.word2idx[word] = self.idx  # add a new word\n",
        "            self.idx2word[self.idx] = word\n",
        "            self.idx += 1\n",
        "\n",
        "    def reverse(self, value):\n",
        "        \"\"\"\n",
        "        From idx to words.\n",
        "        :param value: index\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if value not in self.idx2word:\n",
        "            return self.idx2word[1]  # return '<unk>' if the word is unseen before.\n",
        "        return self.idx2word[value]\n",
        "\n",
        "def build_vocab(json_file=path_to_homework+ '/flickr30k_images/dataset_flickr30k.json', threshold=3):\n",
        "    with open(json_file) as f:\n",
        "            data = json.load(f)\n",
        "    f.close()\n",
        "    counter = Counter()\n",
        "    for img_idx in tqdm(range(len(data['images']))):\n",
        "        img_annos = data['images'][img_idx]\n",
        "        for sent_idx in range(len(img_annos['sentids'])):\n",
        "#             tokens = img_annos['sentences'][sent_idx]['tokens']  # directly load tokens\n",
        "\n",
        "            caption = img_annos['sentences'][sent_idx]['raw']\n",
        "            tokens = nltk.tokenize.word_tokenize(caption.lower())\n",
        "            \n",
        "            counter.update(tokens)\n",
        "\n",
        "    # If the number of words is less than threshold we don't count it.\n",
        "    words = [word for word, cnt in counter.items() if cnt >= threshold]\n",
        "\n",
        "\n",
        "    # create a Vocabulary class\n",
        "    vocab = Vocabulary()\n",
        "\n",
        "    # add words to Vocab\n",
        "    for i, word in enumerate(words):\n",
        "        vocab.add_word(word)\n",
        "\n",
        "    return vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIt-GlhV8Hhj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06b1ec63-ab03-4b4f-d8b5-59b837afec96"
      },
      "source": [
        "# let's create a vocabulary for future usage\n",
        "vocab_path = path_to_homework + '/flickr30k_images/vocab.pkl'\n",
        "if not os.path.isfile(vocab_path):  # if we don't have vocab, create one\n",
        "    vocab = build_vocab(json_file=path_to_homework + '/flickr30k_images/dataset_flickr30k.json', threshold=3)\n",
        "    with open(vocab_path, 'wb') as f:\n",
        "        pickle.dump(vocab, f)\n",
        "    print(\"Total vocabulary size: {}\".format(len(vocab)))\n",
        "    print(\"Saved the vocabulary wrapper to '{}'\".format(vocab_path))\n",
        "else:  # if we have, load the existing vocab\n",
        "    with open(vocab_path, 'rb') as f:\n",
        "        vocab = pickle.load(f)\n",
        "    print('vocab loaded!')\n",
        "    print('the size of vocab:', len(vocab))\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab loaded!\n",
            "the size of vocab: 9991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6G7iNB_8Hhm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4026c87-0d26-4ea4-a05c-9060f2599c22"
      },
      "source": [
        "vocab_path = path_to_homework + '/flickr30k_images/vocab.pkl'\n",
        "with open(vocab_path, 'rb') as f:\n",
        "    vocab = pickle.load(f)\n",
        "print('vocab loaded!')\n",
        "print('the size of vocab:', len(vocab))\n",
        "# print(vocab.word2idx.keys())\n",
        "# print(vocab.idx2word)\n",
        "\n",
        "# check some random words\n",
        "for i in range(3):\n",
        "    random_idx = np.random.randint(len(vocab))\n",
        "    print('word: {}, index: {}'.format(list(vocab.word2idx.keys())[random_idx], vocab(list(vocab.word2idx.keys())[random_idx])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab loaded!\n",
            "the size of vocab: 9991\n",
            "word: game, index: 646\n",
            "word: gasoline, index: 9105\n",
            "word: command, index: 9753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_WnySG88Hhp"
      },
      "source": [
        "# Section 2 Vanilla RNN [45 pts]\n",
        "# Section 2.1 Design the Network: Encoder [5 pts]\n",
        "Implement the baseline model by using pre-trained ResNet-50 as the encoder and Vanilla RNN as the decoder. Note that we will remove the last layer (fc layer) of ResNet-50 and add a trainable linear layer to finetune it for our task. During the training, we will **freeze** the layer before the fc layer. The encoder should output a feature vector of a fixed size for each image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsmuHLIL8Hhp"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        \"\"\"\n",
        "        Use ResNet-50 as encoder.\n",
        "        :param emb_dim: output size of ResNet-50.\n",
        "        \"\"\"\n",
        "        super(Encoder, self).__init__()\n",
        "        self.resnet = torchvision.models.resnet50(pretrained=True)\n",
        "        ###########Your code###############\n",
        "        # freeze the parameters\n",
        "        for param in self.resnet.parameters():\n",
        "            param.requires_grad_(False)\n",
        "        \n",
        "        # replace the last layer (fc layer) with a trainable layer for finetuning\n",
        "        #modules = list(self.resnet.children())[:-1]\n",
        "        #self.resnet = nn.Sequential(*modules)\n",
        "        #self.embed = nn.Linear(resnet.fc.in_features, embed_size)\n",
        "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, emb_dim)\n",
        "\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.resnet(x)  # output shape: [N, emb_dim]\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duTf4YD38Hhu"
      },
      "source": [
        "# Section 2.2 Design the Network: Decoder [10 pts]\n",
        "During decoding, we will train a RNN (https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN) to learn the structure of the caption text throught \"**Teacher Forcing**\". Teacher forcing works by using the teaching signal from the training dataset at the current time step, $target(t)$, as input in the next time step $x(t+1) = target(t)$, rather than the output $y(t)$ generated by the network. \n",
        "\n",
        "As shown in Figure 1 above, RNN will take three inputs: the *current feature*, hidden state ($h_0$) and cell state ($c_0$). The *current feature* for the first step should be the output of encoder to predict '\\<start\\>' word. Hidden states for this step should be set to None. Then in the second step '\\<start\\>' will be passed into RNN as the input, and so on.\n",
        "\n",
        "To use '\\<start\\>' or any subsequent word as current feature, get its index from the vocabulary you created, convert it to one-hot vector and pass it through a linear layer to embed into a feature (or you can take advantage of Pytorch’s nn.Embedding which does one-hot encoding + linear layer for you).\n",
        "\n",
        "For convenience, you might want to 'pad' the captions in a mini-batch to convert them into fixed length. You can use 'pack_padded_sequence' function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56sqDiGL8Hhw"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, num_layers=1, dropout=0):\n",
        "        \"\"\"\n",
        "        Use RNN as decoder for captions.\n",
        "        :param emb_dim: Embedding dimensions.\n",
        "        :param hidden_dim: Hidden states dimensions.\n",
        "        :param num_layers: Number of RNN layers.\n",
        "        :param vocab_size: The size of Vocabulary.\n",
        "        :param dropout: the probability for dropout.\n",
        "        \"\"\"\n",
        "        super(Decoder, self).__init__()\n",
        "        self.max_length = 30  # the maximum length of a sentence, in case it's trapped\n",
        "        \n",
        "        #############Your code############\n",
        "        # you need to implement a Vanilla RNN for the decoder. Take a look at the official documentation.\n",
        "        # https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN\n",
        "        \n",
        "        # one-hot encoding + linear layer\n",
        "        self.embedding_layer = nn.Embedding(vocab_size, emb_dim)\n",
        "        \n",
        "        # vanilla rnn network\n",
        "        self.rnn = nn.RNN(input_size = emb_dim,hidden_size = hidden_dim,\n",
        "                            num_layers = num_layers, batch_first = True)\n",
        "        \n",
        "        \n",
        "        # output layer\n",
        "        self.linear = nn.Linear(hidden_dim, vocab_size)\n",
        "        \n",
        "\n",
        "    def forward(self, encode_features, captions, lengths):\n",
        "        \"\"\"\n",
        "        Feed forward to generate captions. Note that you need to pad the input so they have the same length\n",
        "        :param encode_features: output of encoder, size [N, emb_dim]\n",
        "        :param captions: captions, size [N, max(lengths)]\n",
        "        :param lengths: a list indicating valid length for each caption. size is (batch_size).\n",
        "        \"\"\"\n",
        "        #############Your Code###################\n",
        "        # compute the embedding using one-hot technique and linear function\n",
        "        embed = self.embedding_layer(captions)\n",
        "        # concatenate the encoded features from encoder and embeddings\n",
        "        embed = torch.cat((encode_features.unsqueeze(1), embed), dim = 1)\n",
        "        packed_input = pack_padded_sequence(embed, lengths, batch_first=True)\n",
        "                \n",
        "        # feed into RNN.\n",
        "        hiddens, _ = self.rnn(packed_input )\n",
        "\n",
        "        \n",
        "        # output layer\n",
        "        outputs = self.linear(hiddens[0])\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7URCxwe8Hh0"
      },
      "source": [
        "# Encoder-decoder [10 pts]\n",
        "Now we need to put our encoder and decoder together. \n",
        "\n",
        "In the sample_generate stage, the idea is to “let the network run on its own”, predicting the next word, and then use the network’s prediction to obtain the next input word. There are at least two ways to obtain the next word.\n",
        "\n",
        "- **Deterministic**: Take the maximum output at each step.\n",
        "- **Stochastic**: Sample from the probability distribution. To get the distribution, we need to compute the weighted softmax of the outputs: $y^i = \\exp(o^j/\\tau) / \\sum_n \\exp(o^n/\\tau)$, where $o^j$ is the output from the last layer, $n$ is the size of the vocabulary, and $\\tau$ is the so-called \"temperature\". By doing this, you should get a different caption each time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfuBc23I8Hh0"
      },
      "source": [
        "class Vanilla_rnn(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, num_layers=1, dropout=0):\n",
        "        \"\"\"\n",
        "        Encoder-decoder vanilla RNN.\n",
        "        :param vocab_size: the size of Vocabulary.\n",
        "        :param emb_dim: the dimensions of word embedding.\n",
        "        :param hidden_dim: the dimensions of hidden units.\n",
        "        :param num_layers: the number of RNN layers.\n",
        "        :param dropout: dropout probability\n",
        "        \"\"\"\n",
        "        super(Vanilla_rnn, self).__init__()\n",
        "        #########Your Code################\n",
        "        # Encoder: ResNet-50\n",
        "        self.Encoder= Encoder(emb_dim)\n",
        "\n",
        "        # Decoder: RNN\n",
        "        self.Decoder = Decoder(vocab_size, emb_dim, hidden_dim, num_layers=1, dropout=0)\n",
        "        self.max_length = self.Decoder.max_length\n",
        "\n",
        "        \n",
        "\n",
        "    def forward(self, x, captions, lengths):\n",
        "        \"\"\"\n",
        "        Feed forward.\n",
        "        :param x: Images, [N, 3, H, W]\n",
        "        :param captions: encoded captions, [N, max(lengths)]\n",
        "        :param lengths: a list indicating valid length for each caption. length is (batch_size).\n",
        "        :return: output logits, usually followed by a softmax layer.\n",
        "        \"\"\"\n",
        "        ##########Your code###################\n",
        "        # forward passing\n",
        "        Encoder= self.Encoder(x)\n",
        "        x = self.Decoder(Encoder,captions, lengths)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def sample_generate(self, x, states=None, mode='Deterministic', temperature=5.0):\n",
        "        \"\"\"\n",
        "        Generate samples during the evaluation.\n",
        "        \n",
        "        :param x: input image\n",
        "        :param states: rnn states\n",
        "        :param mode: which mode we use.  \n",
        "         - 'Deterministic': Take the maximum output at each step.\n",
        "         - 'Stochastic': Sample from the probability distribution from the output layer.\n",
        "        :param temperature: will be used in the stochastic mode\n",
        "        :return: sample_idxs. Word indices. We can use vocab to recover the sentence later.\n",
        "        \"\"\"\n",
        "        sample_idxs = []  # record the index of your generated words\n",
        "        #################Your Code##################\n",
        "        # compute the encoded features\n",
        "        features = self.Encoder(x)\n",
        "        inputs = features.unsqueeze(1)\n",
        "        # decide which mode we use\n",
        "        if mode == 'Deterministic':\n",
        "          for i in range(self.max_length):\n",
        "              hiddens, states = self.Decoder.rnn(inputs, states)  \n",
        "              outputs = self.Decoder.linear(hiddens.squeeze(1)) \n",
        "           # take the maximum index after the softmax\n",
        "              _, predicted = outputs.max(1)                        # predicted: (batch_size)\n",
        "              sample_idxs.append(predicted)\n",
        "              inputs= self.Decoder.embedding_layer(predicted)\n",
        "              inputs = inputs.unsqueeze(1)\n",
        "          sample_idxs = torch.stack(sample_idxs, dim=1)\n",
        "            \n",
        "        elif mode == 'Stochastic':\n",
        "            for i in range(self.max_length):\n",
        "              hiddens, states = self.Decoder.rnn(inputs, states)  \n",
        "              outputs = self.Decoder.linear(hiddens.squeeze(1)) \n",
        "\n",
        "            # sample from the probability distribution after the softmax\n",
        "            # Hint: use torch.multinomial() to sample from a distribution.\n",
        "              #probabilities = F.softmax(outputs.div(temperature).squeeze(0).squeeze(0), dim=1)\n",
        "              probabilities = F.softmax(outputs.div(temperature), dim=1)\n",
        "              predicted = torch.multinomial(probabilities, 1) \n",
        "\n",
        "              sample_idxs.append(predicted[:, 0])\n",
        "              inputs = self.Decoder.embedding_layer(predicted[:,0])                       # inputs: (batch_size, embed_size)\n",
        "              inputs = inputs.unsqueeze(1)                         # inputs: (batch_size, 1, embed_size)\n",
        "            sample_idxs = torch.stack(sample_idxs, 1)                # sampled_ids: (batch_size, max_seq_length)\n",
        "            \n",
        "        return sample_idxs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92HuNgIj8Hh3"
      },
      "source": [
        "# Section 2.3 Training [10 pts]\n",
        "Train your encoder-decoder. You might also want to check the output sentence every epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H_ZTG598Hh4"
      },
      "source": [
        "# some hyperparameters, you can change them\n",
        "## training parameters\n",
        "batch_size = 256\n",
        "lr = 1e-2\n",
        "num_epochs = 50\n",
        "weight_decay = 0.0\n",
        "log_step = 50\n",
        "\n",
        "## network architecture\n",
        "emb_dim = 1024\n",
        "hidden_dim = 256\n",
        "num_layers = 1 # number of RNN layers\n",
        "dropout = 0.0\n",
        "\n",
        "## image transformation\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        #     transforms.RandomCrop(224, pad_if_needed=True),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                             std=(0.229, 0.224, 0.225))])\n",
        "\n",
        "## Output directory\n",
        "output_dir = path_to_homework + '/checkpoints/rnn/'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "## device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBVhTm_F8Hh7"
      },
      "source": [
        "# Validation code here. We are gonna use this during the training. \n",
        "def val(model, data_loader, vocab):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "    :param model: the encoder-decoder network.\n",
        "    :param data_loader: validation data loader\n",
        "    :param vocab: pre-built vocabulary\n",
        "    Output:\n",
        "    the mean value of validation losses\n",
        "    \"\"\"\n",
        "    print('Validating...')\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()  # CE loss\n",
        "    \n",
        "    val_loss = []\n",
        "    total_step = len(data_loader)\n",
        "    validatin_loss= 0\n",
        "    for itr, (images, captions, lengths) in enumerate(data_loader):\n",
        "        #######Your Code#########\n",
        "        # forward inputs and compute the validation loss\n",
        "        images = Variable(images).to(device)\n",
        "        captions = Variable(captions).to(device)\n",
        "        targets = Variable(pack_padded_sequence(captions, lengths, batch_first=True)[0]).to(device)\n",
        "            \n",
        "        outputs = model(images, captions, lengths)\n",
        "\n",
        "        loss = criterion(outputs, targets)\n",
        " \n",
        "     \n",
        "        # record the validation loss\n",
        "        val_loss.append(loss.data.detach().cpu().numpy())\n",
        "        \n",
        "        # Print current loss\n",
        "        if itr % log_step == 0:\n",
        "            print('Step [{}/{}], Loss: {:.4f}, Perplexity: {:5.4f}'\n",
        "                  .format(itr, total_step, loss.item(), np.exp(loss.item())))\n",
        "    \n",
        "    # (optional) you might also want to print out the sentence to see the qualitative performance of your model. \n",
        "    # You can use deterministic mode to generate sentences\n",
        "    \n",
        "\n",
        "    return np.mean(val_loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f35PHfgIpuYH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2fdd0bd-1e6d-477b-c281-e52c127368c5"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD6pE7WM8HiA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "67f5fb3e-675d-430b-9b6e-d15335dc2531"
      },
      "source": [
        "# Training code here\n",
        "\n",
        "\n",
        "train_data_loader = get_loader(root=path_to_homework + 'flickr30k_images/', split='train', vocab=vocab, \n",
        "                               transform=transform, batch_size=batch_size, shuffle=True, num_workers=8)\n",
        "val_data_loader = get_loader(root=path_to_homework + 'flickr30k_images/', split='val', vocab=vocab, \n",
        "                               transform=transform, batch_size=8, shuffle=True, num_workers=8)\n",
        "\n",
        "model = Vanilla_rnn(vocab_size=len(vocab), emb_dim=emb_dim, hidden_dim=hidden_dim, \n",
        "                   num_layers=1, dropout=dropout).to(device)  # build a model\n",
        "\n",
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # CE loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)  # optimizer\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n",
        "                                      step_size=5,\n",
        "                                      gamma=0.5)  # decay LR by a factor of 0.5 every 10 epochs. You can change this\n",
        "\n",
        "# logs\n",
        "Train_Losses = []  # record average training loss each epoch\n",
        "Val_Losses = []   # record average validation loss each epoch\n",
        "total_step = len(train_data_loader)  # number of iterations each epoch\n",
        "best_val_loss = np.inf\n",
        "\n",
        "# start training\n",
        "print('Start training...')\n",
        "import time\n",
        "tic = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    print('Switch to training...')\n",
        "    model.train()\n",
        "    Train_loss_iter = []  # record the the training loss each iteration\n",
        "    for itr, (images, captions, lengths) in enumerate(train_data_loader):\n",
        "        ########Your Code###########\n",
        "        # train your model\n",
        "        images = Variable(images).to(device)\n",
        "        captions = Variable(captions).to(device)\n",
        "        targets = Variable(pack_padded_sequence(captions, lengths, batch_first=True)[0]).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images, captions, lengths)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()  \n",
        "        optimizer.step()\n",
        "\n",
        "        # record the training loss\n",
        "        Train_loss_iter = Train_loss_iter+loss.data.detach().cpu().numpy()\n",
        "\n",
        "        # print log info\n",
        "        if itr % log_step == 0:\n",
        "            # print current loss and perplexity\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Perplexity: {:5.4f}'\n",
        "                      .format(epoch, num_epochs, itr, total_step, loss.item(), np.exp(loss.item())))\n",
        "    scheduler.step()\n",
        "    Train_Losses.append(np.mean(Train_loss_iter))\n",
        "    np.save(os.path.join(output_dir, 'TrainingLoss_rnn.npy'), Train_Losses)  # save the training loss\n",
        "    \n",
        "    model.eval()\n",
        "    # (optional) generate a sample during the training, you can use deterministic mode\n",
        "    # Your code\n",
        "    \n",
        "    \n",
        "    # validation\n",
        "    Val_Losses.append(val(model, val_data_loader, vocab))\n",
        "    np.save(os.path.join(output_dir, 'ValLoss_rnn.npy'), Val_Losses) # save the val loss\n",
        "    \n",
        "    # save model\n",
        "    if Val_Losses[-1] < best_val_loss:\n",
        "        best_val_loss = Val_Losses[-1]\n",
        "        print('updated best val loss:', best_val_loss)\n",
        "        print('Save model weights to...', output_dir)\n",
        "        torch.save(model.state_dict(), \n",
        "                   os.path.join(output_dir, 'vanilla_rnn-best.pth'.format(epoch + 1, itr + 1)))\n",
        "\n",
        "print('It took: {} s'.format(time.time() - tic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "Switch to training...\n",
            "Epoch [0/50], Step [0/114], Loss: 9.2886, Perplexity: 10814.3532\n",
            "Epoch [0/50], Step [50/114], Loss: 3.8253, Perplexity: 45.8447\n",
            "Epoch [0/50], Step [100/114], Loss: 3.6685, Perplexity: 39.1919\n",
            "Validating...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step [0/127], Loss: 3.6928, Perplexity: 40.1580\n",
            "Step [50/127], Loss: 3.3617, Perplexity: 28.8396\n",
            "Step [100/127], Loss: 3.7779, Perplexity: 43.7222\n",
            "updated best val loss: 3.6196856\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/rnn/\n",
            "Switch to training...\n",
            "Epoch [1/50], Step [0/114], Loss: 3.5814, Perplexity: 35.9252\n",
            "Epoch [1/50], Step [50/114], Loss: 3.5934, Perplexity: 36.3577\n",
            "Epoch [1/50], Step [100/114], Loss: 3.5670, Perplexity: 35.4116\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.7276, Perplexity: 41.5784\n",
            "Step [50/127], Loss: 3.3852, Perplexity: 29.5244\n",
            "Step [100/127], Loss: 3.7080, Perplexity: 40.7721\n",
            "updated best val loss: 3.5572746\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/rnn/\n",
            "Switch to training...\n",
            "Epoch [2/50], Step [0/114], Loss: 3.4455, Perplexity: 31.3584\n",
            "Epoch [2/50], Step [50/114], Loss: 3.4773, Perplexity: 32.3723\n",
            "Epoch [2/50], Step [100/114], Loss: 3.5945, Perplexity: 36.3975\n",
            "Validating...\n",
            "Step [0/127], Loss: 4.4924, Perplexity: 89.3371\n",
            "Step [50/127], Loss: 3.9778, Perplexity: 53.3968\n",
            "Step [100/127], Loss: 2.9547, Perplexity: 19.1965\n",
            "Switch to training...\n",
            "Epoch [3/50], Step [0/114], Loss: 3.4664, Perplexity: 32.0219\n",
            "Epoch [3/50], Step [50/114], Loss: 3.4420, Perplexity: 31.2484\n",
            "Epoch [3/50], Step [100/114], Loss: 3.4095, Perplexity: 30.2498\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.5207, Perplexity: 33.8072\n",
            "Step [50/127], Loss: 3.6208, Perplexity: 37.3657\n",
            "Step [100/127], Loss: 2.9767, Perplexity: 19.6221\n",
            "updated best val loss: 3.5191712\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/rnn/\n",
            "Switch to training...\n",
            "Epoch [4/50], Step [0/114], Loss: 3.4405, Perplexity: 31.2015\n",
            "Epoch [4/50], Step [50/114], Loss: 3.3770, Perplexity: 29.2829\n",
            "Epoch [4/50], Step [100/114], Loss: 3.5398, Perplexity: 34.4585\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.7031, Perplexity: 40.5716\n",
            "Step [50/127], Loss: 3.4654, Perplexity: 31.9905\n",
            "Step [100/127], Loss: 2.7577, Perplexity: 15.7642\n",
            "Switch to training...\n",
            "Epoch [5/50], Step [0/114], Loss: 3.4323, Perplexity: 30.9480\n",
            "Epoch [5/50], Step [50/114], Loss: 3.2505, Perplexity: 25.8034\n",
            "Epoch [5/50], Step [100/114], Loss: 3.2419, Perplexity: 25.5810\n",
            "Validating...\n",
            "Step [0/127], Loss: 4.2091, Perplexity: 67.2941\n",
            "Step [50/127], Loss: 3.2904, Perplexity: 26.8536\n",
            "Step [100/127], Loss: 2.6271, Perplexity: 13.8330\n",
            "updated best val loss: 3.3406265\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/rnn/\n",
            "Switch to training...\n",
            "Epoch [6/50], Step [0/114], Loss: 3.2030, Perplexity: 24.6057\n",
            "Epoch [6/50], Step [50/114], Loss: 3.2179, Perplexity: 24.9751\n",
            "Epoch [6/50], Step [100/114], Loss: 3.1449, Perplexity: 23.2174\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.2453, Perplexity: 25.6681\n",
            "Step [50/127], Loss: 3.5774, Perplexity: 35.7822\n",
            "Step [100/127], Loss: 3.2305, Perplexity: 25.2928\n",
            "updated best val loss: 3.3050737\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/rnn/\n",
            "Switch to training...\n",
            "Epoch [7/50], Step [0/114], Loss: 3.1413, Perplexity: 23.1342\n",
            "Epoch [7/50], Step [50/114], Loss: 3.0586, Perplexity: 21.2974\n",
            "Epoch [7/50], Step [100/114], Loss: 3.1051, Perplexity: 22.3115\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.1584, Perplexity: 23.5322\n",
            "Step [50/127], Loss: 2.9936, Perplexity: 19.9568\n",
            "Step [100/127], Loss: 3.1673, Perplexity: 23.7428\n",
            "updated best val loss: 3.2460256\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/rnn/\n",
            "Switch to training...\n",
            "Epoch [8/50], Step [0/114], Loss: 3.0856, Perplexity: 21.8809\n",
            "Epoch [8/50], Step [50/114], Loss: 3.1719, Perplexity: 23.8517\n",
            "Epoch [8/50], Step [100/114], Loss: 3.1230, Perplexity: 22.7147\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.2331, Perplexity: 25.3579\n",
            "Step [50/127], Loss: 3.3581, Perplexity: 28.7339\n",
            "Step [100/127], Loss: 3.4657, Perplexity: 31.9973\n",
            "Switch to training...\n",
            "Epoch [9/50], Step [0/114], Loss: 3.1052, Perplexity: 22.3141\n",
            "Epoch [9/50], Step [50/114], Loss: 3.1841, Perplexity: 24.1461\n",
            "Epoch [9/50], Step [100/114], Loss: 3.0938, Perplexity: 22.0609\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.5864, Perplexity: 36.1033\n",
            "Step [50/127], Loss: 3.8432, Perplexity: 46.6734\n",
            "Step [100/127], Loss: 3.7021, Perplexity: 40.5304\n",
            "updated best val loss: 3.2301815\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/rnn/\n",
            "Switch to training...\n",
            "Epoch [10/50], Step [0/114], Loss: 3.0485, Perplexity: 21.0845\n",
            "Epoch [10/50], Step [50/114], Loss: 3.0290, Perplexity: 20.6772\n",
            "Epoch [10/50], Step [100/114], Loss: 3.0730, Perplexity: 21.6067\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.2940, Perplexity: 26.9493\n",
            "Step [50/127], Loss: 2.9146, Perplexity: 18.4418\n",
            "Step [100/127], Loss: 2.6277, Perplexity: 13.8423\n",
            "updated best val loss: 3.171485\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/rnn/\n",
            "Switch to training...\n",
            "Epoch [11/50], Step [0/114], Loss: 2.8929, Perplexity: 18.0462\n",
            "Epoch [11/50], Step [50/114], Loss: 3.0292, Perplexity: 20.6799\n",
            "Epoch [11/50], Step [100/114], Loss: 3.0116, Perplexity: 20.3203\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.6940, Perplexity: 14.7912\n",
            "Step [50/127], Loss: 3.3646, Perplexity: 28.9230\n",
            "Step [100/127], Loss: 3.3422, Perplexity: 28.2816\n",
            "Switch to training...\n",
            "Epoch [12/50], Step [0/114], Loss: 2.8895, Perplexity: 17.9848\n",
            "Epoch [12/50], Step [50/114], Loss: 3.0660, Perplexity: 21.4567\n",
            "Epoch [12/50], Step [100/114], Loss: 2.8927, Perplexity: 18.0422\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.8075, Perplexity: 45.0360\n",
            "Step [50/127], Loss: 3.1391, Perplexity: 23.0832\n",
            "Step [100/127], Loss: 2.6310, Perplexity: 13.8872\n",
            "updated best val loss: 3.1350825\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/rnn/\n",
            "Switch to training...\n",
            "Epoch [13/50], Step [0/114], Loss: 2.9173, Perplexity: 18.4916\n",
            "Epoch [13/50], Step [50/114], Loss: 2.9558, Perplexity: 19.2166\n",
            "Epoch [13/50], Step [100/114], Loss: 3.0156, Perplexity: 20.4010\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.7121, Perplexity: 15.0601\n",
            "Step [50/127], Loss: 3.1235, Perplexity: 22.7252\n",
            "Step [100/127], Loss: 2.7806, Perplexity: 16.1289\n",
            "Switch to training...\n",
            "Epoch [14/50], Step [0/114], Loss: 2.8933, Perplexity: 18.0534\n",
            "Epoch [14/50], Step [50/114], Loss: 2.9164, Perplexity: 18.4743\n",
            "Epoch [14/50], Step [100/114], Loss: 2.9396, Perplexity: 18.9083\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.8862, Perplexity: 17.9257\n",
            "Step [50/127], Loss: 3.3905, Perplexity: 29.6821\n",
            "Step [100/127], Loss: 3.1508, Perplexity: 23.3547\n",
            "updated best val loss: 3.1305714\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/rnn/\n",
            "Switch to training...\n",
            "Epoch [15/50], Step [0/114], Loss: 2.8675, Perplexity: 17.5925\n",
            "Epoch [15/50], Step [50/114], Loss: 2.8348, Perplexity: 17.0278\n",
            "Epoch [15/50], Step [100/114], Loss: 2.9161, Perplexity: 18.4692\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.6228, Perplexity: 13.7744\n",
            "Step [50/127], Loss: 3.1103, Perplexity: 22.4272\n",
            "Step [100/127], Loss: 3.3231, Perplexity: 27.7463\n",
            "updated best val loss: 3.11965\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/rnn/\n",
            "Switch to training...\n",
            "Epoch [16/50], Step [0/114], Loss: 2.8034, Perplexity: 16.5011\n",
            "Epoch [16/50], Step [50/114], Loss: 2.8330, Perplexity: 16.9970\n",
            "Epoch [16/50], Step [100/114], Loss: 2.9121, Perplexity: 18.3961\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.4529, Perplexity: 31.5926\n",
            "Step [50/127], Loss: 3.3085, Perplexity: 27.3444\n",
            "Step [100/127], Loss: 2.8168, Perplexity: 16.7240\n",
            "updated best val loss: 3.1142802\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/rnn/\n",
            "Switch to training...\n",
            "Epoch [17/50], Step [0/114], Loss: 2.8617, Perplexity: 17.4913\n",
            "Epoch [17/50], Step [50/114], Loss: 2.8570, Perplexity: 17.4092\n",
            "Epoch [17/50], Step [100/114], Loss: 2.8907, Perplexity: 18.0067\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.2912, Perplexity: 26.8754\n",
            "Step [50/127], Loss: 3.8065, Perplexity: 44.9909\n",
            "Step [100/127], Loss: 3.1585, Perplexity: 23.5343\n",
            "Switch to training...\n",
            "Epoch [18/50], Step [0/114], Loss: 2.7887, Perplexity: 16.2601\n",
            "Epoch [18/50], Step [50/114], Loss: 2.7826, Perplexity: 16.1612\n",
            "Epoch [18/50], Step [100/114], Loss: 2.8119, Perplexity: 16.6409\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.0190, Perplexity: 20.4713\n",
            "Step [50/127], Loss: 3.2231, Perplexity: 25.1070\n",
            "Step [100/127], Loss: 2.4616, Perplexity: 11.7231\n",
            "Switch to training...\n",
            "Epoch [19/50], Step [0/114], Loss: 2.8432, Perplexity: 17.1714\n",
            "Epoch [19/50], Step [50/114], Loss: 2.7971, Perplexity: 16.3977\n",
            "Epoch [19/50], Step [100/114], Loss: 2.8508, Perplexity: 17.3021\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.4841, Perplexity: 32.5932\n",
            "Step [50/127], Loss: 2.6954, Perplexity: 14.8111\n",
            "Step [100/127], Loss: 2.7809, Perplexity: 16.1330\n",
            "updated best val loss: 3.0906336\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/rnn/\n",
            "Switch to training...\n",
            "Epoch [20/50], Step [0/114], Loss: 2.7895, Perplexity: 16.2728\n",
            "Epoch [20/50], Step [50/114], Loss: 2.7537, Perplexity: 15.7012\n",
            "Epoch [20/50], Step [100/114], Loss: 2.7714, Perplexity: 15.9803\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.0478, Perplexity: 21.0684\n",
            "Step [50/127], Loss: 3.4689, Perplexity: 32.1002\n",
            "Step [100/127], Loss: 2.8860, Perplexity: 17.9220\n",
            "updated best val loss: 3.0682244\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/rnn/\n",
            "Switch to training...\n",
            "Epoch [21/50], Step [0/114], Loss: 2.7306, Perplexity: 15.3422\n",
            "Epoch [21/50], Step [50/114], Loss: 2.8433, Perplexity: 17.1730\n",
            "Epoch [21/50], Step [100/114], Loss: 2.7884, Perplexity: 16.2544\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.7710, Perplexity: 15.9746\n",
            "Step [50/127], Loss: 3.0316, Perplexity: 20.7298\n",
            "Step [100/127], Loss: 3.1170, Perplexity: 22.5778\n",
            "updated best val loss: 3.041525\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/rnn/\n",
            "Switch to training...\n",
            "Epoch [22/50], Step [0/114], Loss: 2.7233, Perplexity: 15.2310\n",
            "Epoch [22/50], Step [50/114], Loss: 2.7862, Perplexity: 16.2198\n",
            "Epoch [22/50], Step [100/114], Loss: 2.7825, Perplexity: 16.1589\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.6603, Perplexity: 14.3009\n",
            "Step [50/127], Loss: 3.2548, Perplexity: 25.9132\n",
            "Step [100/127], Loss: 2.9340, Perplexity: 18.8030\n",
            "Switch to training...\n",
            "Epoch [23/50], Step [0/114], Loss: 2.7238, Perplexity: 15.2376\n",
            "Epoch [23/50], Step [50/114], Loss: 2.7945, Perplexity: 16.3551\n",
            "Epoch [23/50], Step [100/114], Loss: 2.7580, Perplexity: 15.7682\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.8330, Perplexity: 16.9969\n",
            "Step [50/127], Loss: 2.9274, Perplexity: 18.6792\n",
            "Step [100/127], Loss: 2.8410, Perplexity: 17.1325\n",
            "Switch to training...\n",
            "Epoch [24/50], Step [0/114], Loss: 2.6935, Perplexity: 14.7831\n",
            "Epoch [24/50], Step [50/114], Loss: 2.7570, Perplexity: 15.7525\n",
            "Epoch [24/50], Step [100/114], Loss: 2.7444, Perplexity: 15.5553\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.0782, Perplexity: 21.7202\n",
            "Step [50/127], Loss: 3.0981, Perplexity: 22.1560\n",
            "Step [100/127], Loss: 3.2616, Perplexity: 26.0904\n",
            "Switch to training...\n",
            "Epoch [25/50], Step [0/114], Loss: 2.7687, Perplexity: 15.9377\n",
            "Epoch [25/50], Step [50/114], Loss: 2.7690, Perplexity: 15.9430\n",
            "Epoch [25/50], Step [100/114], Loss: 2.6905, Perplexity: 14.7391\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.0019, Perplexity: 20.1240\n",
            "Step [50/127], Loss: 2.7000, Perplexity: 14.8791\n",
            "Step [100/127], Loss: 3.3019, Perplexity: 27.1642\n",
            "Switch to training...\n",
            "Epoch [26/50], Step [0/114], Loss: 2.7883, Perplexity: 16.2534\n",
            "Epoch [26/50], Step [50/114], Loss: 2.7197, Perplexity: 15.1764\n",
            "Epoch [26/50], Step [100/114], Loss: 2.7631, Perplexity: 15.8483\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.9543, Perplexity: 19.1877\n",
            "Step [50/127], Loss: 2.7510, Perplexity: 15.6580\n",
            "Step [100/127], Loss: 3.2980, Perplexity: 27.0581\n",
            "updated best val loss: 3.0322013\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/rnn/\n",
            "Switch to training...\n",
            "Epoch [27/50], Step [0/114], Loss: 2.7506, Perplexity: 15.6517\n",
            "Epoch [27/50], Step [50/114], Loss: 2.7591, Perplexity: 15.7852\n",
            "Epoch [27/50], Step [100/114], Loss: 2.7354, Perplexity: 15.4155\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.1637, Perplexity: 23.6570\n",
            "Step [50/127], Loss: 2.9493, Perplexity: 19.0928\n",
            "Step [100/127], Loss: 3.1041, Perplexity: 22.2901\n",
            "Switch to training...\n",
            "Epoch [28/50], Step [0/114], Loss: 2.7170, Perplexity: 15.1349\n",
            "Epoch [28/50], Step [50/114], Loss: 2.7428, Perplexity: 15.5309\n",
            "Epoch [28/50], Step [100/114], Loss: 2.7033, Perplexity: 14.9282\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.1382, Perplexity: 23.0615\n",
            "Step [50/127], Loss: 2.6379, Perplexity: 13.9841\n",
            "Step [100/127], Loss: 2.8556, Perplexity: 17.3843\n",
            "Switch to training...\n",
            "Epoch [29/50], Step [0/114], Loss: 2.6993, Perplexity: 14.8696\n",
            "Epoch [29/50], Step [50/114], Loss: 2.7107, Perplexity: 15.0402\n",
            "Epoch [29/50], Step [100/114], Loss: 2.7896, Perplexity: 16.2745\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.2334, Perplexity: 25.3651\n",
            "Step [50/127], Loss: 3.2447, Perplexity: 25.6552\n",
            "Step [100/127], Loss: 3.3405, Perplexity: 28.2321\n",
            "Switch to training...\n",
            "Epoch [30/50], Step [0/114], Loss: 2.7260, Perplexity: 15.2713\n",
            "Epoch [30/50], Step [50/114], Loss: 2.7384, Perplexity: 15.4617\n",
            "Epoch [30/50], Step [100/114], Loss: 2.7883, Perplexity: 16.2533\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.5528, Perplexity: 34.9123\n",
            "Step [50/127], Loss: 2.8230, Perplexity: 16.8268\n",
            "Step [100/127], Loss: 2.5639, Perplexity: 12.9866\n",
            "Switch to training...\n",
            "Epoch [31/50], Step [0/114], Loss: 2.7627, Perplexity: 15.8432\n",
            "Epoch [31/50], Step [50/114], Loss: 2.7467, Perplexity: 15.5909\n",
            "Epoch [31/50], Step [100/114], Loss: 2.7275, Perplexity: 15.2940\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.4044, Perplexity: 30.0958\n",
            "Step [50/127], Loss: 2.5227, Perplexity: 12.4625\n",
            "Step [100/127], Loss: 2.8333, Perplexity: 17.0017\n",
            "Switch to training...\n",
            "Epoch [32/50], Step [0/114], Loss: 2.7152, Perplexity: 15.1077\n",
            "Epoch [32/50], Step [50/114], Loss: 2.7160, Perplexity: 15.1194\n",
            "Epoch [32/50], Step [100/114], Loss: 2.7351, Perplexity: 15.4114\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.7143, Perplexity: 15.0946\n",
            "Step [50/127], Loss: 2.8448, Perplexity: 17.1976\n",
            "Step [100/127], Loss: 2.7705, Perplexity: 15.9672\n",
            "Switch to training...\n",
            "Epoch [33/50], Step [0/114], Loss: 2.7405, Perplexity: 15.4944\n",
            "Epoch [33/50], Step [50/114], Loss: 2.7349, Perplexity: 15.4084\n",
            "Epoch [33/50], Step [100/114], Loss: 2.7338, Perplexity: 15.3909\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.3664, Perplexity: 28.9742\n",
            "Step [50/127], Loss: 2.9861, Perplexity: 19.8084\n",
            "Step [100/127], Loss: 3.0949, Perplexity: 22.0849\n",
            "Switch to training...\n",
            "Epoch [34/50], Step [0/114], Loss: 2.6994, Perplexity: 14.8715\n",
            "Epoch [34/50], Step [50/114], Loss: 2.7685, Perplexity: 15.9355\n",
            "Epoch [34/50], Step [100/114], Loss: 2.7128, Perplexity: 15.0720\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.4353, Perplexity: 31.0409\n",
            "Step [50/127], Loss: 3.0173, Perplexity: 20.4358\n",
            "Step [100/127], Loss: 2.6823, Perplexity: 14.6184\n",
            "Switch to training...\n",
            "Epoch [35/50], Step [0/114], Loss: 2.8003, Perplexity: 16.4492\n",
            "Epoch [35/50], Step [50/114], Loss: 2.6852, Perplexity: 14.6607\n",
            "Epoch [35/50], Step [100/114], Loss: 2.6786, Perplexity: 14.5653\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.7338, Perplexity: 15.3917\n",
            "Step [50/127], Loss: 3.4342, Perplexity: 31.0052\n",
            "Step [100/127], Loss: 2.3678, Perplexity: 10.6742\n",
            "Switch to training...\n",
            "Epoch [36/50], Step [0/114], Loss: 2.7716, Perplexity: 15.9837\n",
            "Epoch [36/50], Step [50/114], Loss: 2.7298, Perplexity: 15.3302\n",
            "Epoch [36/50], Step [100/114], Loss: 2.6858, Perplexity: 14.6694\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.9511, Perplexity: 19.1267\n",
            "Step [50/127], Loss: 2.6736, Perplexity: 14.4926\n",
            "Step [100/127], Loss: 3.5186, Perplexity: 33.7357\n",
            "Switch to training...\n",
            "Epoch [37/50], Step [0/114], Loss: 2.7434, Perplexity: 15.5391\n",
            "Epoch [37/50], Step [50/114], Loss: 2.6816, Perplexity: 14.6085\n",
            "Epoch [37/50], Step [100/114], Loss: 2.7057, Perplexity: 14.9644\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.1691, Perplexity: 23.7862\n",
            "Step [50/127], Loss: 2.5575, Perplexity: 12.9032\n",
            "Step [100/127], Loss: 2.8314, Perplexity: 16.9691\n",
            "Switch to training...\n",
            "Epoch [38/50], Step [0/114], Loss: 2.7036, Perplexity: 14.9335\n",
            "Epoch [38/50], Step [50/114], Loss: 2.7063, Perplexity: 14.9734\n",
            "Epoch [38/50], Step [100/114], Loss: 2.7047, Perplexity: 14.9496\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.1402, Perplexity: 23.1093\n",
            "Step [50/127], Loss: 2.9318, Perplexity: 18.7622\n",
            "Step [100/127], Loss: 3.1735, Perplexity: 23.8899\n",
            "Switch to training...\n",
            "Epoch [39/50], Step [0/114], Loss: 2.6714, Perplexity: 14.4603\n",
            "Epoch [39/50], Step [50/114], Loss: 2.6968, Perplexity: 14.8316\n",
            "Epoch [39/50], Step [100/114], Loss: 2.7159, Perplexity: 15.1185\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.3631, Perplexity: 28.8779\n",
            "Step [50/127], Loss: 2.8968, Perplexity: 18.1158\n",
            "Step [100/127], Loss: 2.7349, Perplexity: 15.4078\n",
            "Switch to training...\n",
            "Epoch [40/50], Step [0/114], Loss: 2.6869, Perplexity: 14.6859\n",
            "Epoch [40/50], Step [50/114], Loss: 2.7820, Perplexity: 16.1514\n",
            "Epoch [40/50], Step [100/114], Loss: 2.6481, Perplexity: 14.1277\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.8061, Perplexity: 16.5459\n",
            "Step [50/127], Loss: 3.0449, Perplexity: 21.0077\n",
            "Step [100/127], Loss: 4.0132, Perplexity: 55.3238\n",
            "Switch to training...\n",
            "Epoch [41/50], Step [0/114], Loss: 2.6984, Perplexity: 14.8558\n",
            "Epoch [41/50], Step [50/114], Loss: 2.7105, Perplexity: 15.0374\n",
            "Epoch [41/50], Step [100/114], Loss: 2.7636, Perplexity: 15.8574\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.2889, Perplexity: 9.8645\n",
            "Step [50/127], Loss: 3.1093, Perplexity: 22.4053\n",
            "Step [100/127], Loss: 2.7452, Perplexity: 15.5670\n",
            "Switch to training...\n",
            "Epoch [42/50], Step [0/114], Loss: 2.6908, Perplexity: 14.7440\n",
            "Epoch [42/50], Step [50/114], Loss: 2.7182, Perplexity: 15.1525\n",
            "Epoch [42/50], Step [100/114], Loss: 2.7213, Perplexity: 15.2008\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.6706, Perplexity: 14.4484\n",
            "Step [50/127], Loss: 3.3295, Perplexity: 27.9253\n",
            "Step [100/127], Loss: 3.1722, Perplexity: 23.8599\n",
            "Switch to training...\n",
            "Epoch [43/50], Step [0/114], Loss: 2.7190, Perplexity: 15.1657\n",
            "Epoch [43/50], Step [50/114], Loss: 2.6972, Perplexity: 14.8380\n",
            "Epoch [43/50], Step [100/114], Loss: 2.7558, Perplexity: 15.7332\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.8041, Perplexity: 16.5116\n",
            "Step [50/127], Loss: 3.4539, Perplexity: 31.6223\n",
            "Step [100/127], Loss: 3.2668, Perplexity: 26.2282\n",
            "Switch to training...\n",
            "Epoch [44/50], Step [0/114], Loss: 2.7104, Perplexity: 15.0353\n",
            "Epoch [44/50], Step [50/114], Loss: 2.6740, Perplexity: 14.4981\n",
            "Epoch [44/50], Step [100/114], Loss: 2.6935, Perplexity: 14.7830\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.4715, Perplexity: 32.1859\n",
            "Step [50/127], Loss: 2.7521, Perplexity: 15.6754\n",
            "Step [100/127], Loss: 2.4192, Perplexity: 11.2364\n",
            "Switch to training...\n",
            "Epoch [45/50], Step [0/114], Loss: 2.7685, Perplexity: 15.9346\n",
            "Epoch [45/50], Step [50/114], Loss: 2.6855, Perplexity: 14.6652\n",
            "Epoch [45/50], Step [100/114], Loss: 2.7345, Perplexity: 15.4018\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.2759, Perplexity: 26.4676\n",
            "Step [50/127], Loss: 3.5333, Perplexity: 34.2367\n",
            "Step [100/127], Loss: 3.0969, Perplexity: 22.1297\n",
            "Switch to training...\n",
            "Epoch [46/50], Step [0/114], Loss: 2.6701, Perplexity: 14.4409\n",
            "Epoch [46/50], Step [50/114], Loss: 2.7645, Perplexity: 15.8704\n",
            "Epoch [46/50], Step [100/114], Loss: 2.7040, Perplexity: 14.9399\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.6218, Perplexity: 37.4060\n",
            "Step [50/127], Loss: 2.7893, Perplexity: 16.2701\n",
            "Step [100/127], Loss: 2.8852, Perplexity: 17.9064\n",
            "Switch to training...\n",
            "Epoch [47/50], Step [0/114], Loss: 2.7418, Perplexity: 15.5141\n",
            "Epoch [47/50], Step [50/114], Loss: 2.6881, Perplexity: 14.7031\n",
            "Epoch [47/50], Step [100/114], Loss: 2.6881, Perplexity: 14.7037\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.5385, Perplexity: 34.4136\n",
            "Step [50/127], Loss: 2.5594, Perplexity: 12.9278\n",
            "Step [100/127], Loss: 3.5634, Perplexity: 35.2815\n",
            "updated best val loss: 3.02697\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/rnn/\n",
            "Switch to training...\n",
            "Epoch [48/50], Step [0/114], Loss: 2.7056, Perplexity: 14.9640\n",
            "Epoch [48/50], Step [50/114], Loss: 2.6394, Perplexity: 14.0047\n",
            "Epoch [48/50], Step [100/114], Loss: 2.7264, Perplexity: 15.2771\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.4817, Perplexity: 11.9613\n",
            "Step [50/127], Loss: 3.2725, Perplexity: 26.3759\n",
            "Step [100/127], Loss: 2.6820, Perplexity: 14.6138\n",
            "Switch to training...\n",
            "Epoch [49/50], Step [0/114], Loss: 2.7082, Perplexity: 15.0030\n",
            "Epoch [49/50], Step [50/114], Loss: 2.7662, Perplexity: 15.8981\n",
            "Epoch [49/50], Step [100/114], Loss: 2.7642, Perplexity: 15.8661\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.0202, Perplexity: 20.4947\n",
            "Step [50/127], Loss: 3.2163, Perplexity: 24.9357\n",
            "Step [100/127], Loss: 2.9490, Perplexity: 19.0869\n",
            "It took: 11761.778471946716 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtPUQu6o8HiG"
      },
      "source": [
        "# Section 2.4 Evaluation [10 pts]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAPv1Thj8HiH"
      },
      "source": [
        "## evaluation code\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "smoother = SmoothingFunction()\n",
        "\n",
        "def caption_generator(model, images, vocab, img_ids, captions, mode='Deterministic', temperature=1.0):\n",
        "    \"\"\"\n",
        "    Generate captions.\n",
        "    :param mode:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    sample_idxs = model.sample_generate(images, mode=mode,\n",
        "                                        temperature=temperature).data.cpu().numpy()  # [N, max_length]\n",
        "    for i, sentence in enumerate(sample_idxs):  # every sentence in this batch\n",
        "        sentence_caption = ''\n",
        "        for word_idx in sentence:\n",
        "            word = vocab.idx2word[word_idx]\n",
        "            if word != '<start>' and word != '<end>':\n",
        "                if word == '.':\n",
        "                    sentence_caption += '.'\n",
        "                else:\n",
        "                    sentence_caption += word + ' '\n",
        "            if word == '<end>':\n",
        "                break\n",
        "        captions.append({'caption': sentence_caption})\n",
        "        # captions.append(sentence_caption)\n",
        "\n",
        "    return captions\n",
        "\n",
        "def run_test(model, data_loader, vocab, mode='Deterministic', temperature=1.0):\n",
        "    \"\"\"\n",
        "    Run your model on the test set.\n",
        "    Inputs:\n",
        "    :param model: the model you use\n",
        "    :param data_loader: the data_loader\n",
        "    :param mode: use 'deterministic' or 'stochastic'\n",
        "    Outputs:\n",
        "    :param predictions\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    for itr, (images, captions, lengths) in enumerate(tqdm(data_loader)):\n",
        "        images = Variable(images).to(device)\n",
        "        captions = Variable(captions).to(device)\n",
        "        outputs = model(images, captions, lengths)\n",
        "        \n",
        "        img_ids = list(range(itr * data_loader.batch_size, (itr + 1) * data_loader.batch_size))\n",
        "        predictions = caption_generator(model, images, vocab, img_ids, \n",
        "                                        predictions, mode=mode, temperature=temperature)\n",
        "        \n",
        "    return predictions\n",
        "\n",
        "def evaluation(model, vocab, data_path=path_to_homework + 'flickr30k_images/', mode='Deterministic', temperature=1.0,\n",
        "               split='test'):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of your model on the test set using BLEU scores.\n",
        "    Inputs:\n",
        "    :param model: the model you use\n",
        "    :param weight_path: the directory to the weights of your model\n",
        "    :param vocab: vocabulary\n",
        "    :param data_path: the directory to the dataset\n",
        "    :param mode: use 'deterministic' or 'stochastic'\n",
        "    Outputs:\n",
        "    :param predictions\n",
        "    \"\"\"\n",
        "    # data loader\n",
        "    test_data_loader = get_loader(root=path_to_homework + 'flickr30k_images/', split=split, vocab=vocab, \n",
        "                                  transform=transform, batch_size=8, shuffle=False, num_workers=4)\n",
        "    \n",
        "    # run your model on the test set\n",
        "    print('Run on the test set...')\n",
        "    preds = run_test(model, test_data_loader, vocab, mode, temperature)\n",
        "    \n",
        "    # load the groundtruth\n",
        "    gt = test_data_loader.dataset.annos\n",
        "    \n",
        "    # evaluate the performance using BLEU score\n",
        "    score1 = 0\n",
        "    score2 = 0\n",
        "    score3 = 0\n",
        "    score4 = 0\n",
        "    \n",
        "    print('Computing BLEU')\n",
        "    for itr in tqdm(range(len(gt))):\n",
        "        candidate = preds[itr]['caption']\n",
        "        reference = [sent['raw'] for sent in gt[itr]['sentences']]\n",
        "        score1 += sentence_bleu(reference, candidate, weights=(1, 0, 0, 0), smoothing_function=smoother.method1)\n",
        "        score2 += sentence_bleu(reference, candidate, weights=(0, 1, 0, 0), smoothing_function=smoother.method1)\n",
        "        score3 += sentence_bleu(reference, candidate, weights=(0, 0, 1, 0), smoothing_function=smoother.method1)\n",
        "        score4 += sentence_bleu(reference, candidate, weights=(0, 0, 0, 1), smoothing_function=smoother.method1)\n",
        "    \n",
        "    bleu1 = 100 * score1/len(gt)\n",
        "    bleu2 = 100 * score2/len(gt)\n",
        "    bleu3 = 100 * score3/len(gt)\n",
        "    bleu4 = 100 * score4/len(gt)\n",
        "    \n",
        "    return bleu1, bleu2, bleu3, bleu4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AVdOM5-8HiK"
      },
      "source": [
        "- Test your outputs in the **Deterministic** way by using BLEU scores. You should at achieve a BLEU 4 of 25."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6p0jaOD8HiK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a802d63c-4971-47df-9582-7a0201edca20"
      },
      "source": [
        "## Evaluate your model using BLEU score. Use Deterministic mode.\n",
        "\n",
        "## Image transformation\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        #     transforms.RandomCrop(224, pad_if_needed=True),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                             std=(0.229, 0.224, 0.225))])\n",
        "\n",
        "## Evaluate your model using BLEU score. Use Deterministic mode\n",
        "model = Vanilla_rnn(vocab_size=len(vocab), emb_dim=emb_dim, hidden_dim=hidden_dim, \n",
        "                   num_layers=1, dropout=dropout).to(device)  # build a model\n",
        "model.load_state_dict(torch.load(path_to_homework + '/checkpoints/rnn/vanilla_rnn-best.pth', map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "bleu1, bleu2, bleu3, bleu4 = evaluation(model, vocab, mode='Deterministic')\n",
        "print(\"BLEU 1:{}, BLEU 2:{}, BLEU 3:{}, BLEU 4:{}\".format(bleu1, bleu2, bleu3, bleu4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Run on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  1%|          | 1/125 [00:04<08:19,  4.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 2/125 [00:07<07:43,  3.77s/it]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 3/125 [00:10<07:17,  3.58s/it]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 4/125 [00:13<06:59,  3.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 5/125 [00:16<06:46,  3.39s/it]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▍         | 6/125 [00:19<06:33,  3.31s/it]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 7/125 [00:23<06:35,  3.35s/it]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▋         | 8/125 [00:26<06:25,  3.30s/it]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 9/125 [00:29<06:17,  3.25s/it]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 10/125 [00:32<06:10,  3.22s/it]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 11/125 [00:35<06:05,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 10%|▉         | 12/125 [00:39<05:58,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 13/125 [00:42<05:53,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 14/125 [00:45<05:50,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 15/125 [00:48<05:45,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 16/125 [00:51<05:42,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▎        | 17/125 [00:54<05:38,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 18/125 [00:57<05:35,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 19/125 [01:00<05:31,  3.13s/it]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 20/125 [01:04<05:29,  3.13s/it]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 21/125 [01:07<05:26,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 22/125 [01:10<05:22,  3.13s/it]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 23/125 [01:13<05:19,  3.13s/it]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 24/125 [01:16<05:16,  3.13s/it]\u001b[A\u001b[A\n",
            "\n",
            " 20%|██        | 25/125 [01:19<05:13,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 26/125 [01:22<05:11,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 27/125 [01:26<05:08,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 28/125 [01:29<05:05,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 29/125 [01:32<05:01,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 30/125 [01:35<04:58,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▍       | 31/125 [01:38<04:55,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 32/125 [01:41<04:52,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▋       | 33/125 [01:44<04:49,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 34/125 [01:48<04:48,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 35/125 [01:51<04:44,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 36/125 [01:54<04:40,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 30%|██▉       | 37/125 [01:57<04:36,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 38/125 [02:00<04:33,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 39/125 [02:03<04:31,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 40/125 [02:07<04:28,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 41/125 [02:10<04:24,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▎      | 42/125 [02:13<04:21,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 43/125 [02:16<04:18,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▌      | 44/125 [02:19<04:15,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 45/125 [02:22<04:12,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 46/125 [02:26<04:10,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 47/125 [02:29<04:07,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 48/125 [02:32<04:03,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 49/125 [02:35<04:00,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 50/125 [02:38<03:56,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 51/125 [02:41<03:52,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 52/125 [02:44<03:51,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 53/125 [02:48<03:47,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 54/125 [02:51<03:43,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 55/125 [02:54<03:39,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▍     | 56/125 [02:57<03:36,  3.13s/it]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 57/125 [03:00<03:32,  3.13s/it]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▋     | 58/125 [03:03<03:30,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 59/125 [03:06<03:27,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 60/125 [03:10<03:25,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 61/125 [03:13<03:22,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|████▉     | 62/125 [03:16<03:19,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 63/125 [03:19<03:16,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 64/125 [03:22<03:13,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 65/125 [03:26<03:11,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 66/125 [03:29<03:09,  3.22s/it]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▎    | 67/125 [03:32<03:07,  3.23s/it]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 68/125 [03:35<03:02,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▌    | 69/125 [03:38<02:58,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 70/125 [03:42<02:54,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 71/125 [03:45<02:51,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 72/125 [03:48<02:48,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 73/125 [03:51<02:44,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 74/125 [03:54<02:41,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 75/125 [03:57<02:38,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 76/125 [04:01<02:35,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 77/125 [04:04<02:31,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 78/125 [04:07<02:28,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 79/125 [04:10<02:25,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 80/125 [04:13<02:22,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▍   | 81/125 [04:16<02:18,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 82/125 [04:20<02:16,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▋   | 83/125 [04:23<02:12,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 84/125 [04:26<02:10,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 85/125 [04:29<02:06,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 86/125 [04:32<02:03,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 70%|██████▉   | 87/125 [04:35<02:00,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 88/125 [04:39<01:57,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 89/125 [04:42<01:53,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 90/125 [04:45<01:50,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 91/125 [04:48<01:47,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▎  | 92/125 [04:51<01:43,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 93/125 [04:54<01:40,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 94/125 [04:57<01:37,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 95/125 [05:01<01:34,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 96/125 [05:04<01:31,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 97/125 [05:07<01:28,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 98/125 [05:10<01:25,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 99/125 [05:13<01:22,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 100/125 [05:16<01:18,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 101/125 [05:20<01:15,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 102/125 [05:23<01:12,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 103/125 [05:26<01:09,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 104/125 [05:29<01:06,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 105/125 [05:32<01:02,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▍ | 106/125 [05:35<00:59,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 107/125 [05:38<00:56,  3.13s/it]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▋ | 108/125 [05:42<00:53,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 109/125 [05:45<00:50,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 110/125 [05:48<00:47,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 111/125 [05:51<00:43,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 90%|████████▉ | 112/125 [05:54<00:40,  3.13s/it]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 113/125 [05:57<00:37,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 114/125 [06:00<00:34,  3.13s/it]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 115/125 [06:03<00:31,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 116/125 [06:07<00:28,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▎| 117/125 [06:10<00:25,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 118/125 [06:13<00:22,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▌| 119/125 [06:16<00:18,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 120/125 [06:19<00:15,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 121/125 [06:22<00:12,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 122/125 [06:26<00:09,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 123/125 [06:29<00:06,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 124/125 [06:32<00:03,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 125/125 [06:35<00:00,  3.16s/it]\n",
            "\n",
            "\n",
            "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 21/1000 [00:00<00:04, 202.18it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Computing BLEU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  4%|▍         | 42/1000 [00:00<00:04, 201.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 62/1000 [00:00<00:04, 199.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 83/1000 [00:00<00:04, 200.21it/s]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 102/1000 [00:00<00:04, 196.51it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 121/1000 [00:00<00:04, 192.87it/s]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 140/1000 [00:00<00:04, 189.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 160/1000 [00:00<00:04, 191.46it/s]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 179/1000 [00:00<00:04, 187.38it/s]\u001b[A\u001b[A\n",
            "\n",
            " 20%|██        | 200/1000 [00:01<00:04, 191.36it/s]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 221/1000 [00:01<00:03, 196.49it/s]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 242/1000 [00:01<00:03, 199.71it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 262/1000 [00:01<00:03, 199.65it/s]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 282/1000 [00:01<00:03, 199.21it/s]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 302/1000 [00:01<00:03, 198.48it/s]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 322/1000 [00:01<00:03, 197.97it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 343/1000 [00:01<00:03, 198.71it/s]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▋      | 363/1000 [00:01<00:03, 195.91it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 383/1000 [00:01<00:03, 196.66it/s]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 404/1000 [00:02<00:02, 200.07it/s]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▎     | 425/1000 [00:02<00:02, 200.84it/s]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▍     | 446/1000 [00:02<00:02, 199.89it/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 466/1000 [00:02<00:02, 199.46it/s]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▊     | 487/1000 [00:02<00:02, 199.71it/s]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 507/1000 [00:02<00:02, 198.69it/s]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 527/1000 [00:02<00:02, 196.65it/s]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▍    | 547/1000 [00:02<00:02, 194.51it/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 567/1000 [00:02<00:02, 195.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 588/1000 [00:02<00:02, 197.66it/s]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 608/1000 [00:03<00:01, 196.11it/s]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 629/1000 [00:03<00:01, 197.56it/s]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▍   | 649/1000 [00:03<00:01, 194.14it/s]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 669/1000 [00:03<00:01, 195.45it/s]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 689/1000 [00:03<00:01, 190.89it/s]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 709/1000 [00:03<00:01, 193.05it/s]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 730/1000 [00:03<00:01, 196.14it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 750/1000 [00:03<00:01, 191.90it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 771/1000 [00:03<00:01, 193.76it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 791/1000 [00:04<00:01, 192.22it/s]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 811/1000 [00:04<00:00, 193.71it/s]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 831/1000 [00:04<00:00, 194.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▌ | 851/1000 [00:04<00:00, 193.57it/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 871/1000 [00:04<00:00, 188.39it/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 890/1000 [00:04<00:00, 184.06it/s]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 909/1000 [00:04<00:00, 185.54it/s]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 928/1000 [00:04<00:00, 185.65it/s]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▍| 947/1000 [00:04<00:00, 184.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 966/1000 [00:04<00:00, 184.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 1000/1000 [00:05<00:00, 193.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU 1:89.68767687069148, BLEU 2:63.75724619747129, BLEU 3:41.23849656594904, BLEU 4:27.7544551175118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mvv83bSw8HiO"
      },
      "source": [
        "- Try different temperatures (e.g. 0.1, 0.2, 0.5, 1.0, 1.5, 2, etc.) during the generation. Report BLEU scores for at least 3 different temperatures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEqg1iLS8HiP"
      },
      "source": [
        "## Use at least 3 different temperatures to generate captions on the test set. Report the BLEU scores.\n",
        "# Your code here\n",
        "## evaluation code for temperature 1.5\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "smoother = SmoothingFunction()\n",
        "\n",
        "def caption_generator(model, images, vocab, img_ids, captions, mode='Deterministic', temperature=1.5):\n",
        "    \"\"\"\n",
        "    Generate captions.\n",
        "    :param mode:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    sample_idxs = model.sample_generate(images, mode=mode,\n",
        "                                        temperature=temperature).data.cpu().numpy()  # [N, max_length]\n",
        "    for i, sentence in enumerate(sample_idxs):  # every sentence in this batch\n",
        "        sentence_caption = ''\n",
        "        for word_idx in sentence:\n",
        "            word = vocab.idx2word[word_idx]\n",
        "            if word != '<start>' and word != '<end>':\n",
        "                if word == '.':\n",
        "                    sentence_caption += '.'\n",
        "                else:\n",
        "                    sentence_caption += word + ' '\n",
        "            if word == '<end>':\n",
        "                break\n",
        "        captions.append({'caption': sentence_caption})\n",
        "        # captions.append(sentence_caption)\n",
        "\n",
        "    return captions\n",
        "\n",
        "def run_test(model, data_loader, vocab, mode='Deterministic', temperature=1.5):\n",
        "    \"\"\"\n",
        "    Run your model on the test set.\n",
        "    Inputs:\n",
        "    :param model: the model you use\n",
        "    :param data_loader: the data_loader\n",
        "    :param mode: use 'deterministic' or 'stochastic'\n",
        "    Outputs:\n",
        "    :param predictions\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    for itr, (images, captions, lengths) in enumerate(tqdm(data_loader)):\n",
        "        images = Variable(images).to(device)\n",
        "        captions = Variable(captions).to(device)\n",
        "        outputs = model(images, captions, lengths)\n",
        "        \n",
        "        img_ids = list(range(itr * data_loader.batch_size, (itr + 1) * data_loader.batch_size))\n",
        "        predictions = caption_generator(model, images, vocab, img_ids, \n",
        "                                        predictions, mode=mode, temperature=temperature)\n",
        "        \n",
        "    return predictions\n",
        "\n",
        "def evaluation(model, vocab, data_path=path_to_homework + '/flickr30k_images/', mode='Deterministic', temperature=1.5,\n",
        "               split='test'):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of your model on the test set using BLEU scores.\n",
        "    Inputs:\n",
        "    :param model: the model you use\n",
        "    :param weight_path: the directory to the weights of your model\n",
        "    :param vocab: vocabulary\n",
        "    :param data_path: the directory to the dataset\n",
        "    :param mode: use 'deterministic' or 'stochastic'\n",
        "    Outputs:\n",
        "    :param predictions\n",
        "    \"\"\"\n",
        "    # data loader\n",
        "    test_data_loader = get_loader(root=path_to_homework + '/flickr30k_images/', split=split, vocab=vocab, \n",
        "                                  transform=transform, batch_size=8, shuffle=False, num_workers=4)\n",
        "    \n",
        "    # run your model on the test set\n",
        "    print('Run on the test set...')\n",
        "    preds = run_test(model, test_data_loader, vocab, mode, temperature)\n",
        "    \n",
        "    # load the groundtruth\n",
        "    gt = test_data_loader.dataset.annos\n",
        "    \n",
        "    # evaluate the performance using BLEU score\n",
        "    score1 = 0\n",
        "    score2 = 0\n",
        "    score3 = 0\n",
        "    score4 = 0\n",
        "    \n",
        "    print('Computing BLEU')\n",
        "    for itr in tqdm(range(len(gt))):\n",
        "        candidate = preds[itr]['caption']\n",
        "        reference = [sent['raw'] for sent in gt[itr]['sentences']]\n",
        "        score1 += sentence_bleu(reference, candidate, weights=(1, 0, 0, 0), smoothing_function=smoother.method1)\n",
        "        score2 += sentence_bleu(reference, candidate, weights=(0, 1, 0, 0), smoothing_function=smoother.method1)\n",
        "        score3 += sentence_bleu(reference, candidate, weights=(0, 0, 1, 0), smoothing_function=smoother.method1)\n",
        "        score4 += sentence_bleu(reference, candidate, weights=(0, 0, 0, 1), smoothing_function=smoother.method1)\n",
        "    \n",
        "    bleu1 = 100 * score1/len(gt)\n",
        "    bleu2 = 100 * score2/len(gt)\n",
        "    bleu3 = 100 * score3/len(gt)\n",
        "    bleu4 = 100 * score4/len(gt)\n",
        "    \n",
        "    return bleu1, bleu2, bleu3, bleu4\n",
        "\n",
        "# End of code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4iPPLFNJWYO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a4e1fab-f77e-4e37-b1da-e83977d4c576"
      },
      "source": [
        "## Evaluate your model using BLEU score. Use Deterministic mode.\n",
        "\n",
        "## Image transformation\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        #     transforms.RandomCrop(224, pad_if_needed=True),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                             std=(0.229, 0.224, 0.225))])\n",
        "\n",
        "## Evaluate your model using BLEU score. Use Deterministic mode\n",
        "model = Vanilla_rnn(vocab_size=len(vocab), emb_dim=emb_dim, hidden_dim=hidden_dim, \n",
        "                   num_layers=1, dropout=dropout).to(device)  # build a model\n",
        "model.load_state_dict(torch.load(path_to_homework + '/checkpoints/rnn/vanilla_rnn-best.pth', map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "bleu1, bleu2, bleu3, bleu4 = evaluation(model, vocab, mode='Deterministic')\n",
        "print(\"BLEU 1:{}, BLEU 2:{}, BLEU 3:{}, BLEU 4:{}\".format(bleu1, bleu2, bleu3, bleu4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Run on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  1%|          | 1/125 [00:05<12:12,  5.90s/it]\u001b[A\n",
            "  2%|▏         | 2/125 [00:06<09:02,  4.41s/it]\u001b[A\n",
            "  3%|▎         | 4/125 [00:06<06:15,  3.10s/it]\u001b[A\n",
            "  4%|▍         | 5/125 [00:10<06:43,  3.37s/it]\u001b[A\n",
            "  6%|▌         | 7/125 [00:11<04:39,  2.37s/it]\u001b[A\n",
            "  8%|▊         | 10/125 [00:12<03:25,  1.79s/it]\u001b[A\n",
            "  9%|▉         | 11/125 [00:12<02:42,  1.42s/it]\u001b[A\n",
            " 10%|█         | 13/125 [00:16<02:54,  1.56s/it]\u001b[A\n",
            " 11%|█         | 14/125 [00:18<03:10,  1.72s/it]\u001b[A\n",
            " 14%|█▎        | 17/125 [00:22<02:50,  1.58s/it]\u001b[A\n",
            " 14%|█▍        | 18/125 [00:24<03:06,  1.74s/it]\u001b[A\n",
            " 17%|█▋        | 21/125 [00:27<02:36,  1.51s/it]\u001b[A\n",
            " 18%|█▊        | 22/125 [00:30<03:15,  1.90s/it]\u001b[A\n",
            " 19%|█▉        | 24/125 [00:30<02:15,  1.35s/it]\u001b[A\n",
            " 20%|██        | 25/125 [00:33<03:18,  1.98s/it]\u001b[A\n",
            " 21%|██        | 26/125 [00:35<03:15,  1.98s/it]\u001b[A\n",
            " 22%|██▏       | 27/125 [00:36<02:21,  1.44s/it]\u001b[A\n",
            " 23%|██▎       | 29/125 [00:39<02:21,  1.48s/it]\u001b[A\n",
            " 24%|██▍       | 30/125 [00:40<02:28,  1.57s/it]\u001b[A\n",
            " 25%|██▍       | 31/125 [00:41<02:05,  1.34s/it]\u001b[A\n",
            " 26%|██▋       | 33/125 [00:45<02:12,  1.44s/it]\u001b[A\n",
            " 27%|██▋       | 34/125 [00:46<02:09,  1.43s/it]\u001b[A\n",
            " 28%|██▊       | 35/125 [00:47<01:50,  1.23s/it]\u001b[A\n",
            " 30%|██▉       | 37/125 [00:50<01:59,  1.36s/it]\u001b[A\n",
            " 30%|███       | 38/125 [00:52<02:07,  1.46s/it]\u001b[A\n",
            " 31%|███       | 39/125 [00:52<01:40,  1.17s/it]\u001b[A\n",
            " 33%|███▎      | 41/125 [00:56<01:52,  1.34s/it]\u001b[A\n",
            " 34%|███▎      | 42/125 [00:57<02:01,  1.46s/it]\u001b[A\n",
            " 34%|███▍      | 43/125 [00:58<01:35,  1.16s/it]\u001b[A\n",
            " 36%|███▌      | 45/125 [01:01<01:47,  1.34s/it]\u001b[A\n",
            " 37%|███▋      | 46/125 [01:03<01:48,  1.37s/it]\u001b[A\n",
            " 38%|███▊      | 47/125 [01:03<01:27,  1.12s/it]\u001b[A\n",
            " 39%|███▉      | 49/125 [01:07<01:37,  1.28s/it]\u001b[A\n",
            " 40%|████      | 50/125 [01:08<01:46,  1.42s/it]\u001b[A\n",
            " 41%|████      | 51/125 [01:09<01:33,  1.26s/it]\u001b[A\n",
            " 42%|████▏     | 53/125 [01:12<01:34,  1.32s/it]\u001b[A\n",
            " 43%|████▎     | 54/125 [01:14<01:47,  1.51s/it]\u001b[A\n",
            " 44%|████▍     | 55/125 [01:15<01:28,  1.27s/it]\u001b[A\n",
            " 46%|████▌     | 57/125 [01:17<01:25,  1.26s/it]\u001b[A\n",
            " 46%|████▋     | 58/125 [01:19<01:37,  1.45s/it]\u001b[A\n",
            " 47%|████▋     | 59/125 [01:21<01:32,  1.40s/it]\u001b[A\n",
            " 49%|████▉     | 61/125 [01:23<01:23,  1.30s/it]\u001b[A\n",
            " 50%|████▉     | 62/125 [01:25<01:31,  1.46s/it]\u001b[A\n",
            " 50%|█████     | 63/125 [01:26<01:35,  1.53s/it]\u001b[A\n",
            " 52%|█████▏    | 65/125 [01:28<01:21,  1.36s/it]\u001b[A\n",
            " 53%|█████▎    | 66/125 [01:30<01:34,  1.60s/it]\u001b[A\n",
            " 54%|█████▎    | 67/125 [01:32<01:32,  1.59s/it]\u001b[A\n",
            " 55%|█████▌    | 69/125 [01:34<01:18,  1.39s/it]\u001b[A\n",
            " 56%|█████▌    | 70/125 [01:36<01:32,  1.67s/it]\u001b[A\n",
            " 57%|█████▋    | 71/125 [01:38<01:26,  1.60s/it]\u001b[A\n",
            " 58%|█████▊    | 73/125 [01:39<01:10,  1.36s/it]\u001b[A\n",
            " 59%|█████▉    | 74/125 [01:42<01:29,  1.76s/it]\u001b[A\n",
            " 60%|██████    | 75/125 [01:43<01:22,  1.65s/it]\u001b[A\n",
            " 62%|██████▏   | 77/125 [01:45<01:06,  1.40s/it]\u001b[A\n",
            " 62%|██████▏   | 78/125 [01:47<01:20,  1.71s/it]\u001b[A\n",
            " 63%|██████▎   | 79/125 [01:49<01:12,  1.58s/it]\u001b[A\n",
            " 65%|██████▍   | 81/125 [01:50<01:01,  1.39s/it]\u001b[A\n",
            " 66%|██████▌   | 82/125 [01:53<01:16,  1.77s/it]\u001b[A\n",
            " 66%|██████▋   | 83/125 [01:54<01:06,  1.59s/it]\u001b[A\n",
            " 68%|██████▊   | 85/125 [01:55<00:51,  1.29s/it]\u001b[A\n",
            " 69%|██████▉   | 86/125 [01:59<01:16,  1.95s/it]\u001b[A\n",
            " 70%|██████▉   | 87/125 [02:00<01:00,  1.60s/it]\u001b[A\n",
            " 71%|███████   | 89/125 [02:01<00:47,  1.33s/it]\u001b[A\n",
            " 72%|███████▏  | 90/125 [02:04<01:07,  1.93s/it]\u001b[A\n",
            " 73%|███████▎  | 91/125 [02:05<00:55,  1.62s/it]\u001b[A\n",
            " 74%|███████▍  | 93/125 [02:07<00:43,  1.36s/it]\u001b[A\n",
            " 75%|███████▌  | 94/125 [02:11<01:04,  2.09s/it]\u001b[A\n",
            " 77%|███████▋  | 96/125 [02:11<00:43,  1.48s/it]\u001b[A\n",
            " 78%|███████▊  | 97/125 [02:12<00:37,  1.35s/it]\u001b[A\n",
            " 78%|███████▊  | 98/125 [02:16<01:02,  2.32s/it]\u001b[A\n",
            " 81%|████████  | 101/125 [02:17<00:40,  1.71s/it]\u001b[A\n",
            " 82%|████████▏ | 102/125 [02:22<00:59,  2.59s/it]\u001b[A\n",
            " 82%|████████▏ | 103/125 [02:22<00:41,  1.90s/it]\u001b[A\n",
            " 84%|████████▍ | 105/125 [02:23<00:28,  1.41s/it]\u001b[A\n",
            " 85%|████████▍ | 106/125 [02:27<00:42,  2.22s/it]\u001b[A\n",
            " 86%|████████▌ | 107/125 [02:28<00:33,  1.84s/it]\u001b[A\n",
            " 87%|████████▋ | 109/125 [02:29<00:22,  1.41s/it]\u001b[A\n",
            " 88%|████████▊ | 110/125 [02:33<00:32,  2.15s/it]\u001b[A\n",
            " 89%|████████▉ | 111/125 [02:33<00:24,  1.73s/it]\u001b[A\n",
            " 90%|█████████ | 113/125 [02:34<00:16,  1.34s/it]\u001b[A\n",
            " 91%|█████████ | 114/125 [02:38<00:22,  2.08s/it]\u001b[A\n",
            " 92%|█████████▏| 115/125 [02:38<00:15,  1.60s/it]\u001b[A\n",
            " 94%|█████████▎| 117/125 [02:40<00:10,  1.29s/it]\u001b[A\n",
            " 94%|█████████▍| 118/125 [02:43<00:14,  2.09s/it]\u001b[A\n",
            " 95%|█████████▌| 119/125 [02:44<00:09,  1.65s/it]\u001b[A\n",
            " 97%|█████████▋| 121/125 [02:46<00:05,  1.39s/it]\u001b[A\n",
            " 98%|█████████▊| 122/125 [02:49<00:05,  1.87s/it]\u001b[A\n",
            " 98%|█████████▊| 123/125 [02:50<00:03,  1.58s/it]\u001b[A\n",
            "100%|██████████| 125/125 [02:52<00:00,  1.38s/it]\n",
            "\n",
            "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 22/1000 [00:00<00:04, 215.79it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Computing BLEU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  4%|▍         | 44/1000 [00:00<00:04, 214.47it/s]\u001b[A\n",
            "  6%|▋         | 63/1000 [00:00<00:04, 205.00it/s]\u001b[A\n",
            "  8%|▊         | 85/1000 [00:00<00:04, 208.53it/s]\u001b[A\n",
            " 11%|█         | 107/1000 [00:00<00:04, 209.67it/s]\u001b[A\n",
            " 13%|█▎        | 127/1000 [00:00<00:04, 206.24it/s]\u001b[A\n",
            " 15%|█▍        | 149/1000 [00:00<00:04, 208.62it/s]\u001b[A\n",
            " 17%|█▋        | 172/1000 [00:00<00:03, 212.37it/s]\u001b[A\n",
            " 20%|█▉        | 195/1000 [00:00<00:03, 214.57it/s]\u001b[A\n",
            " 22%|██▏       | 216/1000 [00:01<00:03, 212.11it/s]\u001b[A\n",
            " 24%|██▍       | 238/1000 [00:01<00:03, 213.38it/s]\u001b[A\n",
            " 26%|██▌       | 262/1000 [00:01<00:03, 218.76it/s]\u001b[A\n",
            " 28%|██▊       | 284/1000 [00:01<00:03, 216.04it/s]\u001b[A\n",
            " 31%|███       | 306/1000 [00:01<00:03, 214.41it/s]\u001b[A\n",
            " 33%|███▎      | 328/1000 [00:01<00:03, 210.92it/s]\u001b[A\n",
            " 35%|███▌      | 350/1000 [00:01<00:03, 211.44it/s]\u001b[A\n",
            " 37%|███▋      | 373/1000 [00:01<00:02, 215.22it/s]\u001b[A\n",
            " 40%|███▉      | 396/1000 [00:01<00:02, 217.68it/s]\u001b[A\n",
            " 42%|████▏     | 419/1000 [00:01<00:02, 220.93it/s]\u001b[A\n",
            " 44%|████▍     | 442/1000 [00:02<00:02, 219.40it/s]\u001b[A\n",
            " 46%|████▋     | 465/1000 [00:02<00:02, 221.24it/s]\u001b[A\n",
            " 49%|████▉     | 488/1000 [00:02<00:02, 220.81it/s]\u001b[A\n",
            " 51%|█████     | 511/1000 [00:02<00:02, 217.59it/s]\u001b[A\n",
            " 53%|█████▎    | 534/1000 [00:02<00:02, 219.10it/s]\u001b[A\n",
            " 56%|█████▌    | 556/1000 [00:02<00:02, 213.20it/s]\u001b[A\n",
            " 58%|█████▊    | 578/1000 [00:02<00:01, 211.04it/s]\u001b[A\n",
            " 60%|██████    | 600/1000 [00:02<00:01, 211.18it/s]\u001b[A\n",
            " 62%|██████▏   | 623/1000 [00:02<00:01, 214.49it/s]\u001b[A\n",
            " 64%|██████▍   | 645/1000 [00:03<00:01, 211.80it/s]\u001b[A\n",
            " 67%|██████▋   | 667/1000 [00:03<00:01, 209.05it/s]\u001b[A\n",
            " 69%|██████▉   | 689/1000 [00:03<00:01, 210.20it/s]\u001b[A\n",
            " 71%|███████   | 711/1000 [00:03<00:01, 209.87it/s]\u001b[A\n",
            " 73%|███████▎  | 733/1000 [00:03<00:01, 211.79it/s]\u001b[A\n",
            " 76%|███████▌  | 755/1000 [00:03<00:01, 210.30it/s]\u001b[A\n",
            " 78%|███████▊  | 777/1000 [00:03<00:01, 204.78it/s]\u001b[A\n",
            " 80%|███████▉  | 798/1000 [00:03<00:00, 205.69it/s]\u001b[A\n",
            " 82%|████████▏ | 820/1000 [00:03<00:00, 209.29it/s]\u001b[A\n",
            " 84%|████████▍ | 841/1000 [00:03<00:00, 209.37it/s]\u001b[A\n",
            " 86%|████████▌ | 862/1000 [00:04<00:00, 209.25it/s]\u001b[A\n",
            " 88%|████████▊ | 883/1000 [00:04<00:00, 204.61it/s]\u001b[A\n",
            " 90%|█████████ | 904/1000 [00:04<00:00, 204.10it/s]\u001b[A\n",
            " 92%|█████████▎| 925/1000 [00:04<00:00, 203.56it/s]\u001b[A\n",
            " 95%|█████████▍| 946/1000 [00:04<00:00, 199.28it/s]\u001b[A\n",
            " 97%|█████████▋| 966/1000 [00:04<00:00, 198.24it/s]\u001b[A\n",
            "100%|██████████| 1000/1000 [00:04<00:00, 210.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU 1:89.68767687069148, BLEU 2:63.75724619747129, BLEU 3:41.23849656594904, BLEU 4:27.7544551175118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfEr-xcgLdFy"
      },
      "source": [
        "## Use at least 3 different temperatures to generate captions on the test set. Report the BLEU scores.\n",
        "# Your code here\n",
        "## evaluation code for temperature 0.5\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "smoother = SmoothingFunction()\n",
        "\n",
        "def caption_generator(model, images, vocab, img_ids, captions, mode='Deterministic', temperature=0.5):\n",
        "    \"\"\"\n",
        "    Generate captions.\n",
        "    :param mode:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    sample_idxs = model.sample_generate(images, mode=mode,\n",
        "                                        temperature=temperature).data.cpu().numpy()  # [N, max_length]\n",
        "    for i, sentence in enumerate(sample_idxs):  # every sentence in this batch\n",
        "        sentence_caption = ''\n",
        "        for word_idx in sentence:\n",
        "            word = vocab.idx2word[word_idx]\n",
        "            if word != '<start>' and word != '<end>':\n",
        "                if word == '.':\n",
        "                    sentence_caption += '.'\n",
        "                else:\n",
        "                    sentence_caption += word + ' '\n",
        "            if word == '<end>':\n",
        "                break\n",
        "        captions.append({'caption': sentence_caption})\n",
        "        # captions.append(sentence_caption)\n",
        "\n",
        "    return captions\n",
        "\n",
        "def run_test(model, data_loader, vocab, mode='Deterministic', temperature=0.5):\n",
        "    \"\"\"\n",
        "    Run your model on the test set.\n",
        "    Inputs:\n",
        "    :param model: the model you use\n",
        "    :param data_loader: the data_loader\n",
        "    :param mode: use 'deterministic' or 'stochastic'\n",
        "    Outputs:\n",
        "    :param predictions\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    for itr, (images, captions, lengths) in enumerate(tqdm(data_loader)):\n",
        "        images = Variable(images).to(device)\n",
        "        captions = Variable(captions).to(device)\n",
        "        outputs = model(images, captions, lengths)\n",
        "        \n",
        "        img_ids = list(range(itr * data_loader.batch_size, (itr + 1) * data_loader.batch_size))\n",
        "        predictions = caption_generator(model, images, vocab, img_ids, \n",
        "                                        predictions, mode=mode, temperature=temperature)\n",
        "        \n",
        "    return predictions\n",
        "\n",
        "def evaluation(model, vocab, data_path=path_to_homework + '/flickr30k_images/', mode='Deterministic', temperature=0.5,\n",
        "               split='test'):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of your model on the test set using BLEU scores.\n",
        "    Inputs:\n",
        "    :param model: the model you use\n",
        "    :param weight_path: the directory to the weights of your model\n",
        "    :param vocab: vocabulary\n",
        "    :param data_path: the directory to the dataset\n",
        "    :param mode: use 'deterministic' or 'stochastic'\n",
        "    Outputs:\n",
        "    :param predictions\n",
        "    \"\"\"\n",
        "    # data loader\n",
        "    test_data_loader = get_loader(root=path_to_homework + '/flickr30k_images/', split=split, vocab=vocab, \n",
        "                                  transform=transform, batch_size=8, shuffle=False, num_workers=4)\n",
        "    \n",
        "    # run your model on the test set\n",
        "    print('Run on the test set...')\n",
        "    preds = run_test(model, test_data_loader, vocab, mode, temperature)\n",
        "    \n",
        "    # load the groundtruth\n",
        "    gt = test_data_loader.dataset.annos\n",
        "    \n",
        "    # evaluate the performance using BLEU score\n",
        "    score1 = 0\n",
        "    score2 = 0\n",
        "    score3 = 0\n",
        "    score4 = 0\n",
        "    \n",
        "    print('Computing BLEU')\n",
        "    for itr in tqdm(range(len(gt))):\n",
        "        candidate = preds[itr]['caption']\n",
        "        reference = [sent['raw'] for sent in gt[itr]['sentences']]\n",
        "        score1 += sentence_bleu(reference, candidate, weights=(1, 0, 0, 0), smoothing_function=smoother.method1)\n",
        "        score2 += sentence_bleu(reference, candidate, weights=(0, 1, 0, 0), smoothing_function=smoother.method1)\n",
        "        score3 += sentence_bleu(reference, candidate, weights=(0, 0, 1, 0), smoothing_function=smoother.method1)\n",
        "        score4 += sentence_bleu(reference, candidate, weights=(0, 0, 0, 1), smoothing_function=smoother.method1)\n",
        "    \n",
        "    bleu1 = 100 * score1/len(gt)\n",
        "    bleu2 = 100 * score2/len(gt)\n",
        "    bleu3 = 100 * score3/len(gt)\n",
        "    bleu4 = 100 * score4/len(gt)\n",
        "    \n",
        "    return bleu1, bleu2, bleu3, bleu4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h50N3EIyJesW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9087433f-43af-4eb3-ff89-1e80157f01b6"
      },
      "source": [
        "## Evaluate your model using BLEU score. Use Deterministic mode.\n",
        "\n",
        "## Image transformation\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        #     transforms.RandomCrop(224, pad_if_needed=True),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                             std=(0.229, 0.224, 0.225))])\n",
        "\n",
        "## Evaluate your model using BLEU score. Use Deterministic mode\n",
        "model = Vanilla_rnn(vocab_size=len(vocab), emb_dim=emb_dim, hidden_dim=hidden_dim, \n",
        "                   num_layers=1, dropout=dropout).to(device)  # build a model\n",
        "model.load_state_dict(torch.load(path_to_homework + '/checkpoints/rnn/vanilla_rnn-best.pth', map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "bleu1, bleu2, bleu3, bleu4 = evaluation(model, vocab, mode='Deterministic')\n",
        "print(\"BLEU 1:{}, BLEU 2:{}, BLEU 3:{}, BLEU 4:{}\".format(bleu1, bleu2, bleu3, bleu4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Run on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  1%|          | 1/125 [00:00<01:01,  2.01it/s]\u001b[A\n",
            "  2%|▏         | 2/125 [00:00<00:50,  2.46it/s]\u001b[A\n",
            "  3%|▎         | 4/125 [00:00<00:37,  3.25it/s]\u001b[A\n",
            "  5%|▍         | 6/125 [00:01<00:29,  3.97it/s]\u001b[A\n",
            "  6%|▌         | 7/125 [00:01<00:26,  4.50it/s]\u001b[A\n",
            "  7%|▋         | 9/125 [00:01<00:21,  5.52it/s]\u001b[A\n",
            "  9%|▉         | 11/125 [00:01<00:17,  6.40it/s]\u001b[A\n",
            " 10%|▉         | 12/125 [00:01<00:16,  6.91it/s]\u001b[A\n",
            " 11%|█         | 14/125 [00:01<00:13,  8.33it/s]\u001b[A\n",
            " 13%|█▎        | 16/125 [00:02<00:11,  9.20it/s]\u001b[A\n",
            " 14%|█▍        | 18/125 [00:02<00:11,  9.13it/s]\u001b[A\n",
            " 16%|█▌        | 20/125 [00:02<00:11,  9.39it/s]\u001b[A\n",
            " 18%|█▊        | 22/125 [00:02<00:10,  9.76it/s]\u001b[A\n",
            " 19%|█▉        | 24/125 [00:02<00:09, 10.19it/s]\u001b[A\n",
            " 21%|██        | 26/125 [00:02<00:09, 10.78it/s]\u001b[A\n",
            " 22%|██▏       | 28/125 [00:03<00:08, 10.92it/s]\u001b[A\n",
            " 24%|██▍       | 30/125 [00:03<00:08, 10.90it/s]\u001b[A\n",
            " 26%|██▌       | 32/125 [00:03<00:07, 12.04it/s]\u001b[A\n",
            " 27%|██▋       | 34/125 [00:03<00:07, 11.57it/s]\u001b[A\n",
            " 29%|██▉       | 36/125 [00:03<00:08, 11.09it/s]\u001b[A\n",
            " 30%|███       | 38/125 [00:03<00:07, 12.19it/s]\u001b[A\n",
            " 32%|███▏      | 40/125 [00:04<00:07, 11.02it/s]\u001b[A\n",
            " 34%|███▎      | 42/125 [00:04<00:07, 10.83it/s]\u001b[A\n",
            " 35%|███▌      | 44/125 [00:04<00:07, 11.40it/s]\u001b[A\n",
            " 37%|███▋      | 46/125 [00:04<00:06, 12.33it/s]\u001b[A\n",
            " 38%|███▊      | 48/125 [00:04<00:07, 10.75it/s]\u001b[A\n",
            " 40%|████      | 50/125 [00:05<00:06, 12.33it/s]\u001b[A\n",
            " 42%|████▏     | 52/125 [00:05<00:06, 11.17it/s]\u001b[A\n",
            " 43%|████▎     | 54/125 [00:05<00:06, 11.41it/s]\u001b[A\n",
            " 45%|████▍     | 56/125 [00:05<00:06, 11.12it/s]\u001b[A\n",
            " 46%|████▋     | 58/125 [00:05<00:05, 11.67it/s]\u001b[A\n",
            " 48%|████▊     | 60/125 [00:05<00:05, 11.42it/s]\u001b[A\n",
            " 50%|████▉     | 62/125 [00:06<00:05, 11.80it/s]\u001b[A\n",
            " 51%|█████     | 64/125 [00:06<00:04, 12.59it/s]\u001b[A\n",
            " 53%|█████▎    | 66/125 [00:06<00:05, 11.61it/s]\u001b[A\n",
            " 54%|█████▍    | 68/125 [00:06<00:05, 10.93it/s]\u001b[A\n",
            " 56%|█████▌    | 70/125 [00:06<00:05, 10.75it/s]\u001b[A\n",
            " 58%|█████▊    | 72/125 [00:06<00:04, 12.38it/s]\u001b[A\n",
            " 59%|█████▉    | 74/125 [00:07<00:04, 11.65it/s]\u001b[A\n",
            " 61%|██████    | 76/125 [00:07<00:04, 11.27it/s]\u001b[A\n",
            " 62%|██████▏   | 78/125 [00:07<00:03, 11.86it/s]\u001b[A\n",
            " 64%|██████▍   | 80/125 [00:07<00:03, 11.49it/s]\u001b[A\n",
            " 66%|██████▌   | 82/125 [00:07<00:03, 11.61it/s]\u001b[A\n",
            " 67%|██████▋   | 84/125 [00:07<00:03, 11.32it/s]\u001b[A\n",
            " 69%|██████▉   | 86/125 [00:08<00:03, 11.66it/s]\u001b[A\n",
            " 70%|███████   | 88/125 [00:08<00:03, 10.89it/s]\u001b[A\n",
            " 72%|███████▏  | 90/125 [00:08<00:03, 11.60it/s]\u001b[A\n",
            " 74%|███████▎  | 92/125 [00:08<00:02, 11.46it/s]\u001b[A\n",
            " 75%|███████▌  | 94/125 [00:08<00:02, 11.20it/s]\u001b[A\n",
            " 77%|███████▋  | 96/125 [00:09<00:02, 11.55it/s]\u001b[A\n",
            " 78%|███████▊  | 98/125 [00:09<00:02, 10.88it/s]\u001b[A\n",
            " 80%|████████  | 100/125 [00:09<00:02, 10.90it/s]\u001b[A\n",
            " 82%|████████▏ | 102/125 [00:09<00:01, 11.89it/s]\u001b[A\n",
            " 83%|████████▎ | 104/125 [00:09<00:01, 12.14it/s]\u001b[A\n",
            " 85%|████████▍ | 106/125 [00:09<00:01, 11.33it/s]\u001b[A\n",
            " 86%|████████▋ | 108/125 [00:10<00:01, 11.63it/s]\u001b[A\n",
            " 88%|████████▊ | 110/125 [00:10<00:01, 12.19it/s]\u001b[A\n",
            " 90%|████████▉ | 112/125 [00:10<00:01, 11.99it/s]\u001b[A\n",
            " 91%|█████████ | 114/125 [00:10<00:00, 11.54it/s]\u001b[A\n",
            " 93%|█████████▎| 116/125 [00:10<00:00, 11.56it/s]\u001b[A\n",
            " 94%|█████████▍| 118/125 [00:10<00:00, 11.92it/s]\u001b[A\n",
            " 97%|█████████▋| 121/125 [00:11<00:00, 13.82it/s]\u001b[A\n",
            "100%|██████████| 125/125 [00:11<00:00, 11.04it/s]\n",
            "\n",
            "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 21/1000 [00:00<00:04, 203.79it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Computing BLEU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  4%|▍         | 44/1000 [00:00<00:04, 208.67it/s]\u001b[A\n",
            "  7%|▋         | 66/1000 [00:00<00:04, 209.24it/s]\u001b[A\n",
            "  8%|▊         | 85/1000 [00:00<00:04, 199.36it/s]\u001b[A\n",
            " 10%|█         | 105/1000 [00:00<00:04, 197.10it/s]\u001b[A\n",
            " 13%|█▎        | 126/1000 [00:00<00:04, 200.31it/s]\u001b[A\n",
            " 15%|█▍        | 148/1000 [00:00<00:04, 205.52it/s]\u001b[A\n",
            " 17%|█▋        | 170/1000 [00:00<00:03, 209.15it/s]\u001b[A\n",
            " 19%|█▉        | 193/1000 [00:00<00:03, 213.29it/s]\u001b[A\n",
            " 22%|██▏       | 216/1000 [00:01<00:03, 216.86it/s]\u001b[A\n",
            " 24%|██▍       | 238/1000 [00:01<00:03, 214.58it/s]\u001b[A\n",
            " 26%|██▌       | 261/1000 [00:01<00:03, 218.14it/s]\u001b[A\n",
            " 28%|██▊       | 284/1000 [00:01<00:03, 219.05it/s]\u001b[A\n",
            " 31%|███       | 307/1000 [00:01<00:03, 221.08it/s]\u001b[A\n",
            " 33%|███▎      | 329/1000 [00:01<00:03, 220.43it/s]\u001b[A\n",
            " 35%|███▌      | 351/1000 [00:01<00:02, 217.99it/s]\u001b[A\n",
            " 37%|███▋      | 374/1000 [00:01<00:02, 220.84it/s]\u001b[A\n",
            " 40%|███▉      | 397/1000 [00:01<00:02, 219.20it/s]\u001b[A\n",
            " 42%|████▏     | 421/1000 [00:01<00:02, 222.73it/s]\u001b[A\n",
            " 44%|████▍     | 444/1000 [00:02<00:02, 221.10it/s]\u001b[A\n",
            " 47%|████▋     | 467/1000 [00:02<00:02, 219.10it/s]\u001b[A\n",
            " 49%|████▉     | 490/1000 [00:02<00:02, 219.76it/s]\u001b[A\n",
            " 51%|█████     | 512/1000 [00:02<00:02, 217.08it/s]\u001b[A\n",
            " 53%|█████▎    | 534/1000 [00:02<00:02, 212.42it/s]\u001b[A\n",
            " 56%|█████▌    | 556/1000 [00:02<00:02, 212.31it/s]\u001b[A\n",
            " 58%|█████▊    | 580/1000 [00:02<00:01, 217.61it/s]\u001b[A\n",
            " 60%|██████    | 602/1000 [00:02<00:01, 217.49it/s]\u001b[A\n",
            " 62%|██████▏   | 624/1000 [00:02<00:01, 216.83it/s]\u001b[A\n",
            " 65%|██████▍   | 646/1000 [00:03<00:01, 209.69it/s]\u001b[A\n",
            " 67%|██████▋   | 668/1000 [00:03<00:01, 207.28it/s]\u001b[A\n",
            " 69%|██████▉   | 689/1000 [00:03<00:01, 205.37it/s]\u001b[A\n",
            " 71%|███████   | 711/1000 [00:03<00:01, 208.38it/s]\u001b[A\n",
            " 73%|███████▎  | 733/1000 [00:03<00:01, 210.74it/s]\u001b[A\n",
            " 76%|███████▌  | 755/1000 [00:03<00:01, 199.99it/s]\u001b[A\n",
            " 78%|███████▊  | 776/1000 [00:03<00:01, 202.32it/s]\u001b[A\n",
            " 80%|███████▉  | 798/1000 [00:03<00:00, 205.98it/s]\u001b[A\n",
            " 82%|████████▏ | 821/1000 [00:03<00:00, 210.98it/s]\u001b[A\n",
            " 84%|████████▍ | 843/1000 [00:03<00:00, 209.62it/s]\u001b[A\n",
            " 86%|████████▋ | 865/1000 [00:04<00:00, 208.96it/s]\u001b[A\n",
            " 89%|████████▊ | 886/1000 [00:04<00:00, 204.02it/s]\u001b[A\n",
            " 91%|█████████ | 907/1000 [00:04<00:00, 200.27it/s]\u001b[A\n",
            " 93%|█████████▎| 928/1000 [00:04<00:00, 202.46it/s]\u001b[A\n",
            " 95%|█████████▌| 950/1000 [00:04<00:00, 206.97it/s]\u001b[A\n",
            " 97%|█████████▋| 971/1000 [00:04<00:00, 206.80it/s]\u001b[A\n",
            "100%|██████████| 1000/1000 [00:04<00:00, 211.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU 1:89.68767687069148, BLEU 2:63.75724619747129, BLEU 3:41.23849656594904, BLEU 4:27.7544551175118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W23YSmZLuYd"
      },
      "source": [
        "## Use at least 3 different temperatures to generate captions on the test set. Report the BLEU scores.\n",
        "# Your code here\n",
        "## evaluation code for temperature 0.1\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "smoother = SmoothingFunction()\n",
        "\n",
        "def caption_generator(model, images, vocab, img_ids, captions, mode='Deterministic', temperature=0.1):\n",
        "    \"\"\"\n",
        "    Generate captions.\n",
        "    :param mode:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    sample_idxs = model.sample_generate(images, mode=mode,\n",
        "                                        temperature=temperature).data.cpu().numpy()  # [N, max_length]\n",
        "    for i, sentence in enumerate(sample_idxs):  # every sentence in this batch\n",
        "        sentence_caption = ''\n",
        "        for word_idx in sentence:\n",
        "            word = vocab.idx2word[word_idx]\n",
        "            if word != '<start>' and word != '<end>':\n",
        "                if word == '.':\n",
        "                    sentence_caption += '.'\n",
        "                else:\n",
        "                    sentence_caption += word + ' '\n",
        "            if word == '<end>':\n",
        "                break\n",
        "        captions.append({'caption': sentence_caption})\n",
        "        # captions.append(sentence_caption)\n",
        "\n",
        "    return captions\n",
        "\n",
        "def run_test(model, data_loader, vocab, mode='Deterministic', temperature=0.1):\n",
        "    \"\"\"\n",
        "    Run your model on the test set.\n",
        "    Inputs:\n",
        "    :param model: the model you use\n",
        "    :param data_loader: the data_loader\n",
        "    :param mode: use 'deterministic' or 'stochastic'\n",
        "    Outputs:\n",
        "    :param predictions\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    for itr, (images, captions, lengths) in enumerate(tqdm(data_loader)):\n",
        "        images = Variable(images).to(device)\n",
        "        captions = Variable(captions).to(device)\n",
        "        outputs = model(images, captions, lengths)\n",
        "        \n",
        "        img_ids = list(range(itr * data_loader.batch_size, (itr + 1) * data_loader.batch_size))\n",
        "        predictions = caption_generator(model, images, vocab, img_ids, \n",
        "                                        predictions, mode=mode, temperature=temperature)\n",
        "        \n",
        "    return predictions\n",
        "\n",
        "def evaluation(model, vocab, data_path=path_to_homework + '/flickr30k_images/', mode='Deterministic', temperature=0.1,\n",
        "               split='test'):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of your model on the test set using BLEU scores.\n",
        "    Inputs:\n",
        "    :param model: the model you use\n",
        "    :param weight_path: the directory to the weights of your model\n",
        "    :param vocab: vocabulary\n",
        "    :param data_path: the directory to the dataset\n",
        "    :param mode: use 'deterministic' or 'stochastic'\n",
        "    Outputs:\n",
        "    :param predictions\n",
        "    \"\"\"\n",
        "    # data loader\n",
        "    test_data_loader = get_loader(root=path_to_homework + '/flickr30k_images/', split=split, vocab=vocab, \n",
        "                                  transform=transform, batch_size=8, shuffle=False, num_workers=4)\n",
        "    \n",
        "    # run your model on the test set\n",
        "    print('Run on the test set...')\n",
        "    preds = run_test(model, test_data_loader, vocab, mode, temperature)\n",
        "    \n",
        "    # load the groundtruth\n",
        "    gt = test_data_loader.dataset.annos\n",
        "    \n",
        "    # evaluate the performance using BLEU score\n",
        "    score1 = 0\n",
        "    score2 = 0\n",
        "    score3 = 0\n",
        "    score4 = 0\n",
        "    \n",
        "    print('Computing BLEU')\n",
        "    for itr in tqdm(range(len(gt))):\n",
        "        candidate = preds[itr]['caption']\n",
        "        reference = [sent['raw'] for sent in gt[itr]['sentences']]\n",
        "        score1 += sentence_bleu(reference, candidate, weights=(1, 0, 0, 0), smoothing_function=smoother.method1)\n",
        "        score2 += sentence_bleu(reference, candidate, weights=(0, 1, 0, 0), smoothing_function=smoother.method1)\n",
        "        score3 += sentence_bleu(reference, candidate, weights=(0, 0, 1, 0), smoothing_function=smoother.method1)\n",
        "        score4 += sentence_bleu(reference, candidate, weights=(0, 0, 0, 1), smoothing_function=smoother.method1)\n",
        "    \n",
        "    bleu1 = 100 * score1/len(gt)\n",
        "    bleu2 = 100 * score2/len(gt)\n",
        "    bleu3 = 100 * score3/len(gt)\n",
        "    bleu4 = 100 * score4/len(gt)\n",
        "    \n",
        "    return bleu1, bleu2, bleu3, bleu4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgmriAFfJhVj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ceade95-29aa-44eb-9f30-2a5c3141669f"
      },
      "source": [
        "## Evaluate your model using BLEU score. Use Deterministic mode.\n",
        "\n",
        "## Image transformation\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        #     transforms.RandomCrop(224, pad_if_needed=True),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                             std=(0.229, 0.224, 0.225))])\n",
        "\n",
        "## Evaluate your model using BLEU score. Use Deterministic mode\n",
        "model = Vanilla_rnn(vocab_size=len(vocab), emb_dim=emb_dim, hidden_dim=hidden_dim, \n",
        "                   num_layers=1, dropout=dropout).to(device)  # build a model\n",
        "model.load_state_dict(torch.load(path_to_homework + '/checkpoints/rnn/vanilla_rnn-best.pth', map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "bleu1, bleu2, bleu3, bleu4 = evaluation(model, vocab, mode='Deterministic')\n",
        "print(\"BLEU 1:{}, BLEU 2:{}, BLEU 3:{}, BLEU 4:{}\".format(bleu1, bleu2, bleu3, bleu4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Run on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  1%|          | 1/125 [00:00<01:24,  1.47it/s]\u001b[A\n",
            "  2%|▏         | 2/125 [00:00<01:03,  1.95it/s]\u001b[A\n",
            "  2%|▏         | 3/125 [00:00<00:47,  2.55it/s]\u001b[A\n",
            "  4%|▍         | 5/125 [00:01<00:37,  3.23it/s]\u001b[A\n",
            "  6%|▌         | 7/125 [00:01<00:28,  4.15it/s]\u001b[A\n",
            "  6%|▋         | 8/125 [00:01<00:23,  5.00it/s]\u001b[A\n",
            "  8%|▊         | 10/125 [00:01<00:18,  6.21it/s]\u001b[A\n",
            " 10%|▉         | 12/125 [00:01<00:15,  7.28it/s]\u001b[A\n",
            " 11%|█         | 14/125 [00:01<00:13,  8.45it/s]\u001b[A\n",
            " 13%|█▎        | 16/125 [00:02<00:11,  9.20it/s]\u001b[A\n",
            " 14%|█▍        | 18/125 [00:02<00:11,  9.47it/s]\u001b[A\n",
            " 16%|█▌        | 20/125 [00:02<00:10,  9.77it/s]\u001b[A\n",
            " 18%|█▊        | 22/125 [00:02<00:09, 10.48it/s]\u001b[A\n",
            " 20%|██        | 25/125 [00:02<00:08, 11.76it/s]\u001b[A\n",
            " 22%|██▏       | 27/125 [00:02<00:09, 10.72it/s]\u001b[A\n",
            " 23%|██▎       | 29/125 [00:03<00:08, 10.68it/s]\u001b[A\n",
            " 25%|██▍       | 31/125 [00:03<00:08, 10.45it/s]\u001b[A\n",
            " 26%|██▋       | 33/125 [00:03<00:07, 11.53it/s]\u001b[A\n",
            " 28%|██▊       | 35/125 [00:03<00:07, 11.33it/s]\u001b[A\n",
            " 30%|██▉       | 37/125 [00:03<00:06, 12.59it/s]\u001b[A\n",
            " 31%|███       | 39/125 [00:04<00:07, 11.38it/s]\u001b[A\n",
            " 33%|███▎      | 41/125 [00:04<00:07, 11.43it/s]\u001b[A\n",
            " 34%|███▍      | 43/125 [00:04<00:07, 11.28it/s]\u001b[A\n",
            " 36%|███▌      | 45/125 [00:04<00:06, 11.97it/s]\u001b[A\n",
            " 38%|███▊      | 47/125 [00:04<00:06, 11.88it/s]\u001b[A\n",
            " 39%|███▉      | 49/125 [00:04<00:05, 13.00it/s]\u001b[A\n",
            " 41%|████      | 51/125 [00:05<00:06, 11.12it/s]\u001b[A\n",
            " 42%|████▏     | 53/125 [00:05<00:06, 11.51it/s]\u001b[A\n",
            " 44%|████▍     | 55/125 [00:05<00:06, 11.60it/s]\u001b[A\n",
            " 46%|████▌     | 57/125 [00:05<00:06, 10.51it/s]\u001b[A\n",
            " 47%|████▋     | 59/125 [00:05<00:05, 11.23it/s]\u001b[A\n",
            " 49%|████▉     | 61/125 [00:05<00:05, 12.55it/s]\u001b[A\n",
            " 50%|█████     | 63/125 [00:06<00:05, 12.33it/s]\u001b[A\n",
            " 52%|█████▏    | 65/125 [00:06<00:05, 10.45it/s]\u001b[A\n",
            " 54%|█████▎    | 67/125 [00:06<00:05, 10.94it/s]\u001b[A\n",
            " 55%|█████▌    | 69/125 [00:06<00:04, 11.49it/s]\u001b[A\n",
            " 57%|█████▋    | 71/125 [00:06<00:04, 11.65it/s]\u001b[A\n",
            " 58%|█████▊    | 73/125 [00:06<00:04, 11.49it/s]\u001b[A\n",
            " 60%|██████    | 75/125 [00:07<00:04, 12.01it/s]\u001b[A\n",
            " 62%|██████▏   | 77/125 [00:07<00:04, 11.08it/s]\u001b[A\n",
            " 63%|██████▎   | 79/125 [00:07<00:03, 11.59it/s]\u001b[A\n",
            " 65%|██████▍   | 81/125 [00:07<00:03, 12.49it/s]\u001b[A\n",
            " 66%|██████▋   | 83/125 [00:07<00:03, 11.61it/s]\u001b[A\n",
            " 68%|██████▊   | 85/125 [00:07<00:03, 12.55it/s]\u001b[A\n",
            " 70%|██████▉   | 87/125 [00:08<00:03, 11.81it/s]\u001b[A\n",
            " 71%|███████   | 89/125 [00:08<00:02, 12.28it/s]\u001b[A\n",
            " 73%|███████▎  | 91/125 [00:08<00:03, 10.84it/s]\u001b[A\n",
            " 74%|███████▍  | 93/125 [00:08<00:02, 11.75it/s]\u001b[A\n",
            " 76%|███████▌  | 95/125 [00:08<00:02, 12.08it/s]\u001b[A\n",
            " 78%|███████▊  | 97/125 [00:08<00:02, 11.93it/s]\u001b[A\n",
            " 79%|███████▉  | 99/125 [00:09<00:02, 11.16it/s]\u001b[A\n",
            " 81%|████████  | 101/125 [00:09<00:02, 11.57it/s]\u001b[A\n",
            " 82%|████████▏ | 103/125 [00:09<00:01, 12.42it/s]\u001b[A\n",
            " 84%|████████▍ | 105/125 [00:09<00:01, 11.82it/s]\u001b[A\n",
            " 86%|████████▌ | 107/125 [00:09<00:01, 10.84it/s]\u001b[A\n",
            " 87%|████████▋ | 109/125 [00:10<00:01, 11.90it/s]\u001b[A\n",
            " 89%|████████▉ | 111/125 [00:10<00:01, 11.93it/s]\u001b[A\n",
            " 90%|█████████ | 113/125 [00:10<00:01, 11.70it/s]\u001b[A\n",
            " 92%|█████████▏| 115/125 [00:10<00:00, 11.74it/s]\u001b[A\n",
            " 94%|█████████▎| 117/125 [00:10<00:00, 11.78it/s]\u001b[A\n",
            " 95%|█████████▌| 119/125 [00:10<00:00, 12.87it/s]\u001b[A\n",
            " 98%|█████████▊| 122/125 [00:10<00:00, 14.70it/s]\u001b[A\n",
            "100%|██████████| 125/125 [00:11<00:00, 11.16it/s]\n",
            "\n",
            "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 21/1000 [00:00<00:04, 207.23it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Computing BLEU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  4%|▍         | 44/1000 [00:00<00:04, 212.49it/s]\u001b[A\n",
            "  7%|▋         | 66/1000 [00:00<00:04, 212.15it/s]\u001b[A\n",
            "  9%|▉         | 89/1000 [00:00<00:04, 216.42it/s]\u001b[A\n",
            " 11%|█         | 111/1000 [00:00<00:04, 214.92it/s]\u001b[A\n",
            " 13%|█▎        | 133/1000 [00:00<00:04, 215.64it/s]\u001b[A\n",
            " 16%|█▌        | 155/1000 [00:00<00:03, 214.47it/s]\u001b[A\n",
            " 18%|█▊        | 178/1000 [00:00<00:03, 216.94it/s]\u001b[A\n",
            " 20%|█▉        | 199/1000 [00:00<00:03, 212.38it/s]\u001b[A\n",
            " 22%|██▏       | 221/1000 [00:01<00:03, 212.71it/s]\u001b[A\n",
            " 24%|██▍       | 243/1000 [00:01<00:03, 212.70it/s]\u001b[A\n",
            " 27%|██▋       | 266/1000 [00:01<00:03, 216.26it/s]\u001b[A\n",
            " 29%|██▉       | 288/1000 [00:01<00:03, 216.81it/s]\u001b[A\n",
            " 31%|███       | 311/1000 [00:01<00:03, 220.28it/s]\u001b[A\n",
            " 33%|███▎      | 333/1000 [00:01<00:03, 219.96it/s]\u001b[A\n",
            " 36%|███▌      | 355/1000 [00:01<00:03, 213.80it/s]\u001b[A\n",
            " 38%|███▊      | 377/1000 [00:01<00:02, 214.14it/s]\u001b[A\n",
            " 40%|████      | 400/1000 [00:01<00:02, 218.50it/s]\u001b[A\n",
            " 42%|████▏     | 422/1000 [00:01<00:02, 218.88it/s]\u001b[A\n",
            " 44%|████▍     | 445/1000 [00:02<00:02, 220.50it/s]\u001b[A\n",
            " 47%|████▋     | 468/1000 [00:02<00:02, 217.67it/s]\u001b[A\n",
            " 49%|████▉     | 491/1000 [00:02<00:02, 220.03it/s]\u001b[A\n",
            " 51%|█████▏    | 514/1000 [00:02<00:02, 220.72it/s]\u001b[A\n",
            " 54%|█████▍    | 538/1000 [00:02<00:02, 223.86it/s]\u001b[A\n",
            " 56%|█████▌    | 561/1000 [00:02<00:01, 221.42it/s]\u001b[A\n",
            " 58%|█████▊    | 584/1000 [00:02<00:01, 221.53it/s]\u001b[A\n",
            " 61%|██████    | 607/1000 [00:02<00:01, 221.00it/s]\u001b[A\n",
            " 63%|██████▎   | 630/1000 [00:02<00:01, 219.26it/s]\u001b[A\n",
            " 65%|██████▌   | 652/1000 [00:02<00:01, 213.36it/s]\u001b[A\n",
            " 67%|██████▋   | 674/1000 [00:03<00:01, 209.44it/s]\u001b[A\n",
            " 70%|██████▉   | 695/1000 [00:03<00:01, 206.87it/s]\u001b[A\n",
            " 72%|███████▏  | 716/1000 [00:03<00:01, 207.43it/s]\u001b[A\n",
            " 74%|███████▍  | 738/1000 [00:03<00:01, 209.03it/s]\u001b[A\n",
            " 76%|███████▌  | 761/1000 [00:03<00:01, 213.14it/s]\u001b[A\n",
            " 78%|███████▊  | 783/1000 [00:03<00:01, 213.86it/s]\u001b[A\n",
            " 80%|████████  | 805/1000 [00:03<00:00, 213.62it/s]\u001b[A\n",
            " 83%|████████▎ | 827/1000 [00:03<00:00, 212.84it/s]\u001b[A\n",
            " 85%|████████▍ | 849/1000 [00:03<00:00, 213.13it/s]\u001b[A\n",
            " 87%|████████▋ | 871/1000 [00:04<00:00, 206.15it/s]\u001b[A\n",
            " 89%|████████▉ | 892/1000 [00:04<00:00, 199.92it/s]\u001b[A\n",
            " 91%|█████████▏| 913/1000 [00:04<00:00, 202.58it/s]\u001b[A\n",
            " 94%|█████████▎| 935/1000 [00:04<00:00, 205.66it/s]\u001b[A\n",
            " 96%|█████████▌| 957/1000 [00:04<00:00, 209.63it/s]\u001b[A\n",
            "100%|██████████| 1000/1000 [00:04<00:00, 214.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU 1:89.68767687069148, BLEU 2:63.75724619747129, BLEU 3:41.23849656594904, BLEU 4:27.7544551175118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m0JvpIr0ZWK"
      },
      "source": [
        "#It semms that as temperature goes up the Belu score dropes. for small values for temperature it is almost the same"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaRBkKOn8HiS"
      },
      "source": [
        "# Section 3 Variations [55 pts]\n",
        "## Section 3.1 LSTM [35 pts]\n",
        "## Section 3.1.1 Decoder: LSTM [5 pts]\n",
        "This time, replace the RNN module with an LSTM module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CBGWh1K8HiT"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, num_layers=1, dropout=0):\n",
        "        \"\"\"\n",
        "        Use LSTM as decoder for captions.\n",
        "        :param emb_dim: Embedding dimensions.\n",
        "        :param hidden_dim: Hidden states dimensions.\n",
        "        :param num_layers: Number of LSTM layers.\n",
        "        :param vocab_size: The size of Vocabulary.\n",
        "        :param dropout: dropout probability\n",
        "        \"\"\"\n",
        "        super(Decoder, self).__init__()\n",
        "        self.max_length = 30\n",
        "        #############Your code############\n",
        "        # you need to implement a LSTM for the decoder. Take a look at the official documentation.\n",
        "        # https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM\n",
        "         # one-hot encoding + linear layer\n",
        "        self.embedding_layer = nn.Embedding(vocab_size, emb_dim)\n",
        "        \n",
        "        # lstm network\n",
        "        self.lstm = nn.LSTM(input_size = emb_dim,hidden_size = hidden_dim,\n",
        "                            num_layers = num_layers, batch_first = True)\n",
        "        \n",
        "        \n",
        "        # output layer\n",
        "        self.linear = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, encode_features, captions, lengths):\n",
        "        \"\"\"\n",
        "        Feed forward to generate captions.\n",
        "        :param encode_features: output of encoder, size [N, emb_dim]\n",
        "        :param captions: captions, size [N, max(lengths)]\n",
        "        :param lengths: a list indicating valid length for each caption. length is (batch_size).\n",
        "        \"\"\"\n",
        "        #############Your Code###################\n",
        "        embed = self.embedding_layer(captions)\n",
        "        # concatenate the encoded features from encoder and embeddings\n",
        "        embed = torch.cat((encode_features.unsqueeze(1), embed), dim = 1)\n",
        "        packed_input = pack_padded_sequence(embed, lengths, batch_first=True)\n",
        "                \n",
        "        # feed into LSTM.\n",
        "        hiddens, _ = self.lstm(packed_input )\n",
        "\n",
        "        # output layer\n",
        "        outputs = self.linear(hiddens[0])\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFNfeL_j8HiW"
      },
      "source": [
        "## Encoder-Decoder [5 pts]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VplWnZuR8HiX"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, num_layers=1, dropout=0):\n",
        "        \"\"\"\n",
        "        Encoder-decoder vanilla RNN.\n",
        "        :param vocab_size: the size of Vocabulary.\n",
        "        :param emb_dim: the dimensions of word embedding.\n",
        "        :param hidden_dim: the dimensions of hidden units.\n",
        "        :param num_layers: the number of RNN layers.\n",
        "        \"\"\"\n",
        "        super(LSTM, self).__init__()\n",
        "        #self.max_length = self.Decoder.max_length\n",
        "        #########Your Code################\n",
        "        # Encoder: ResNet-50\n",
        "        self.Encoder= Encoder(emb_dim)\n",
        "\n",
        "        # Decoder: LSTM\n",
        "        self.Decoder = Decoder(vocab_size, emb_dim, hidden_dim, num_layers=1, dropout=0)\n",
        "        self.max_length = self.Decoder.max_length\n",
        "\n",
        "    def forward(self, x, captions, lengths):\n",
        "        \"\"\"\n",
        "        Feed forward.\n",
        "        :param x: Images, [N, 3, H, W]\n",
        "        :param captions: encoded captions, [N, max(lengths)]\n",
        "        :param lengths: a list indicating valid length for each caption. length is (batch_size).\n",
        "        :return: output logits, usually followed by a softmax layer.\n",
        "        \"\"\"\n",
        "        ##########Your code###################\n",
        "                # forward passing\n",
        "        Encoder= self.Encoder(x)\n",
        "        x = self.Decoder(Encoder,captions, lengths)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def sample_generate(self, x, states=None, mode='Deterministic', temperature=5.0):\n",
        "        \"\"\"\n",
        "        Generate samples during the evaluation.\n",
        "        \n",
        "        :param x: input image\n",
        "        :param states: rnn states\n",
        "        :param mode: which mode we use.  \n",
        "         - 'Deterministic': Take the maximum output at each step.\n",
        "         - 'Stochastic': Sample from the probability distribution from the output layer.\n",
        "        :param temperature: will be used in the stochastic mode\n",
        "        :return: sample_idxs. Word indices. We can use vocab to recover the sentence.\n",
        "        \"\"\"\n",
        "        sample_idxs = []  # record the index of your generated words\n",
        "        # compute the encoded features\n",
        "        features = self.Encoder(x)\n",
        "        inputs = features.unsqueeze(1)\n",
        "        if mode == 'Deterministic':\n",
        "          for i in range(self.max_length):\n",
        "              hiddens, states = self.Decoder.lstm(inputs, states)  \n",
        "              outputs = self.Decoder.linear(hiddens.squeeze(1)) \n",
        "           # take the maximum index after the softmax\n",
        "              _, predicted = outputs.max(1)                        # predicted: (batch_size)\n",
        "              sample_idxs.append(predicted)\n",
        "              inputs= self.Decoder.embedding_layer(predicted)\n",
        "              inputs = inputs.unsqueeze(1)\n",
        "          sample_idxs=torch.stack(sample_idxs, dim=1)\n",
        "            \n",
        "        elif mode == 'Stochastic':\n",
        "            for i in range(self.max_length):\n",
        "              hiddens, states = self.Decoder.lstm(inputs, states)  \n",
        "              outputs = self.Decoder.linear(hiddens.squeeze(1)) \n",
        "              #outputs = m(outputs/temperature)\n",
        "            # sample from the probability distribution after the softmax\n",
        "            # Hint: use torch.multinomial() to sample from a distribution.\n",
        "              #probabilities = F.softmax(outputs.div(temperature).squeeze(0).squeeze(0), dim=1)\n",
        "              probabilities = F.softmax(outputs.div(temperature), dim=1)\n",
        "              predicted = torch.multinomial(probabilities.data, 1) \n",
        "\n",
        "              sample_idxs.append(predicted[:, 0])\n",
        "              inputs = self.Decoder.embedding_layer(predicted[:,0])                       # inputs: (batch_size, embed_size)\n",
        "              inputs = inputs.unsqueeze(1)                         # inputs: (batch_size, 1, embed_size)\n",
        "            sample_idxs = torch.stack(sample_idxs, dim=1)                # sampled_ids: (batch_size, max_seq_length)\n",
        "            \n",
        "            \n",
        "        return sample_idxs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAUlicFZ8Hib"
      },
      "source": [
        "## Section 3.1.2 Training [10 pts]\n",
        "Use the same set of hyper-parameters (hidden units, optimizer, learning rate etc.) for both models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQtnqHFB8Hic"
      },
      "source": [
        "# some hyperparameters, you can change them\n",
        "## training parameters\n",
        "batch_size = 256\n",
        "lr = 1e-2\n",
        "num_epochs = 50\n",
        "weight_decay = 0.0\n",
        "log_step = 50\n",
        "\n",
        "## network architecture\n",
        "emb_dim = 1024\n",
        "hidden_dim = 256\n",
        "num_layers = 1 # number of RNN layers\n",
        "dropout = 0.0\n",
        "\n",
        "## image transformation\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        #     transforms.RandomCrop(224, pad_if_needed=True),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                             std=(0.229, 0.224, 0.225))])\n",
        "\n",
        "## Output directory\n",
        "output_dir = path_to_homework + '/checkpoints/lstm/'\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8heUtTZ8Hii",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "34dec82d-a985-4600-faf7-9ec37763cff7"
      },
      "source": [
        "# Training code here\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "train_data_loader = get_loader(root=path_to_homework + 'flickr30k_images/', split='train', vocab=vocab,\n",
        "                               transform=transform, batch_size=batch_size, shuffle=True, num_workers=12)\n",
        "val_data_loader = get_loader(root=path_to_homework + 'flickr30k_images/', split='val', vocab=vocab,\n",
        "                             transform=transform, batch_size=8, shuffle=True, num_workers=4)\n",
        "\n",
        "model = LSTM(vocab_size=len(vocab), emb_dim=emb_dim, hidden_dim=hidden_dim, \n",
        "                   num_layers=1, dropout=dropout).to(device)  # build a model\n",
        "\n",
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss().to(device)  # CE loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)  # optimizer\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n",
        "                                      step_size=5,\n",
        "                                      gamma=0.5)  # decay LR by a factor of 0.5 every 10 epochs. You can change this\n",
        "\n",
        "# logs\n",
        "Train_Losses = []  # record average training loss each epoch\n",
        "Val_Losses = []   # record average validation loss each epoch\n",
        "total_step = len(train_data_loader)  # number of iterations each epoch\n",
        "best_val_loss = np.inf\n",
        "\n",
        "# start training\n",
        "print('Start training...')\n",
        "import time\n",
        "tic = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    print('Switch to training...')\n",
        "    model.train()\n",
        "    Train_loss_iter = []  # record the the training loss each iteration\n",
        "    for itr, (images, captions, lengths) in enumerate(train_data_loader):\n",
        "        ########Your Code###########\n",
        "        \n",
        "        # train your model\n",
        "        images = Variable(images).to(device)\n",
        "        captions = Variable(captions).to(device)\n",
        "        targets = Variable(pack_padded_sequence(captions, lengths, batch_first=True)[0]).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images, captions, lengths)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()  \n",
        "        optimizer.step()\n",
        "\n",
        "        # record the training loss\n",
        "        Train_loss_iter = Train_loss_iter+loss.data.detach().cpu().numpy()\n",
        "        \n",
        "        \n",
        "        # print log info\n",
        "        if itr % log_step == 0:\n",
        "            # print current loss and perplexity\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Perplexity: {:5.4f}'\n",
        "                      .format(epoch, num_epochs, itr, total_step, loss.item(), np.exp(loss.item())))\n",
        "    scheduler.step()\n",
        "    Train_Losses.append(np.mean(Train_loss_iter))\n",
        "    np.save(os.path.join(output_dir, 'TrainingLoss_lstm.npy'), Train_Losses)  # save the training loss\n",
        "    \n",
        "    model.eval()\n",
        "    # (optional) generate a sample during the training, you can use deterministic mode\n",
        "    # Your code\n",
        "    \n",
        "    \n",
        "    # validation\n",
        "    Val_Losses.append(val(model, val_data_loader, vocab))\n",
        "    np.save(os.path.join(output_dir, 'ValLoss_lstm.npy'), Val_Losses) # save the val loss\n",
        "    \n",
        "    # save model\n",
        "    if Val_Losses[-1] < best_val_loss:\n",
        "        best_val_loss = Val_Losses[-1]\n",
        "        print('updated best val loss:', best_val_loss)\n",
        "        print('Save model weights to...', output_dir)\n",
        "        torch.save(model.state_dict(), \n",
        "                   os.path.join(output_dir, 'lstm-best.pth'.format(epoch + 1, itr + 1)))\n",
        "\n",
        "print('It took: {} s'.format(time.time() - tic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "Switch to training...\n",
            "Epoch [0/50], Step [0/114], Loss: 9.2181, Perplexity: 10077.8075\n",
            "Epoch [0/50], Step [50/114], Loss: 3.6306, Perplexity: 37.7345\n",
            "Epoch [0/50], Step [100/114], Loss: 3.4019, Perplexity: 30.0200\n",
            "Validating...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step [0/127], Loss: 3.7728, Perplexity: 43.5004\n",
            "Step [50/127], Loss: 3.1068, Perplexity: 22.3496\n",
            "Step [100/127], Loss: 3.8409, Perplexity: 46.5682\n",
            "updated best val loss: 3.366395\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/lstm/\n",
            "Switch to training...\n",
            "Epoch [1/50], Step [0/114], Loss: 3.3167, Perplexity: 27.5680\n",
            "Epoch [1/50], Step [50/114], Loss: 3.3043, Perplexity: 27.2300\n",
            "Epoch [1/50], Step [100/114], Loss: 3.2659, Perplexity: 26.2047\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.4206, Perplexity: 30.5885\n",
            "Step [50/127], Loss: 3.3993, Perplexity: 29.9436\n",
            "Step [100/127], Loss: 3.3913, Perplexity: 29.7054\n",
            "updated best val loss: 3.2770257\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/lstm/\n",
            "Switch to training...\n",
            "Epoch [2/50], Step [0/114], Loss: 3.2657, Perplexity: 26.1975\n",
            "Epoch [2/50], Step [50/114], Loss: 3.1362, Perplexity: 23.0155\n",
            "Epoch [2/50], Step [100/114], Loss: 3.1070, Perplexity: 22.3543\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.3349, Perplexity: 28.0749\n",
            "Step [50/127], Loss: 2.8570, Perplexity: 17.4085\n",
            "Step [100/127], Loss: 2.8155, Perplexity: 16.7011\n",
            "updated best val loss: 3.2027628\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/lstm/\n",
            "Switch to training...\n",
            "Epoch [3/50], Step [0/114], Loss: 2.9640, Perplexity: 19.3747\n",
            "Epoch [3/50], Step [50/114], Loss: 3.1233, Perplexity: 22.7209\n",
            "Epoch [3/50], Step [100/114], Loss: 3.0414, Perplexity: 20.9336\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.6995, Perplexity: 40.4260\n",
            "Step [50/127], Loss: 3.2081, Perplexity: 24.7320\n",
            "Step [100/127], Loss: 3.0796, Perplexity: 21.7501\n",
            "Switch to training...\n",
            "Epoch [4/50], Step [0/114], Loss: 3.0447, Perplexity: 21.0041\n",
            "Epoch [4/50], Step [50/114], Loss: 3.0016, Perplexity: 20.1185\n",
            "Epoch [4/50], Step [100/114], Loss: 2.9923, Perplexity: 19.9305\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.1439, Perplexity: 23.1946\n",
            "Step [50/127], Loss: 3.2989, Perplexity: 27.0840\n",
            "Step [100/127], Loss: 3.1461, Perplexity: 23.2447\n",
            "updated best val loss: 3.1663105\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/lstm/\n",
            "Switch to training...\n",
            "Epoch [5/50], Step [0/114], Loss: 3.0323, Perplexity: 20.7454\n",
            "Epoch [5/50], Step [50/114], Loss: 2.9365, Perplexity: 18.8502\n",
            "Epoch [5/50], Step [100/114], Loss: 2.9120, Perplexity: 18.3929\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.9879, Perplexity: 19.8435\n",
            "Step [50/127], Loss: 3.0969, Perplexity: 22.1295\n",
            "Step [100/127], Loss: 3.0116, Perplexity: 20.3199\n",
            "updated best val loss: 3.0868416\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/lstm/\n",
            "Switch to training...\n",
            "Epoch [6/50], Step [0/114], Loss: 2.9543, Perplexity: 19.1891\n",
            "Epoch [6/50], Step [50/114], Loss: 2.8740, Perplexity: 17.7080\n",
            "Epoch [6/50], Step [100/114], Loss: 2.9620, Perplexity: 19.3357\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.9232, Perplexity: 18.5998\n",
            "Step [50/127], Loss: 2.9005, Perplexity: 18.1829\n",
            "Step [100/127], Loss: 3.4348, Perplexity: 31.0248\n",
            "updated best val loss: 3.0827463\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/lstm/\n",
            "Switch to training...\n",
            "Epoch [7/50], Step [0/114], Loss: 2.8550, Perplexity: 17.3739\n",
            "Epoch [7/50], Step [50/114], Loss: 2.8399, Perplexity: 17.1139\n",
            "Epoch [7/50], Step [100/114], Loss: 2.8252, Perplexity: 16.8638\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.0703, Perplexity: 21.5491\n",
            "Step [50/127], Loss: 3.5878, Perplexity: 36.1542\n",
            "Step [100/127], Loss: 2.8941, Perplexity: 18.0681\n",
            "updated best val loss: 3.070739\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/lstm/\n",
            "Switch to training...\n",
            "Epoch [8/50], Step [0/114], Loss: 2.8071, Perplexity: 16.5611\n",
            "Epoch [8/50], Step [50/114], Loss: 2.8627, Perplexity: 17.5096\n",
            "Epoch [8/50], Step [100/114], Loss: 2.9374, Perplexity: 18.8669\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.1033, Perplexity: 22.2703\n",
            "Step [50/127], Loss: 3.0700, Perplexity: 21.5427\n",
            "Step [100/127], Loss: 2.9965, Perplexity: 20.0147\n",
            "Switch to training...\n",
            "Epoch [9/50], Step [0/114], Loss: 2.8405, Perplexity: 17.1236\n",
            "Epoch [9/50], Step [50/114], Loss: 2.8183, Perplexity: 16.7482\n",
            "Epoch [9/50], Step [100/114], Loss: 2.7956, Perplexity: 16.3725\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.2863, Perplexity: 26.7431\n",
            "Step [50/127], Loss: 3.2252, Perplexity: 25.1597\n",
            "Step [100/127], Loss: 3.0242, Perplexity: 20.5770\n",
            "Switch to training...\n",
            "Epoch [10/50], Step [0/114], Loss: 2.7056, Perplexity: 14.9638\n",
            "Epoch [10/50], Step [50/114], Loss: 2.6892, Perplexity: 14.7197\n",
            "Epoch [10/50], Step [100/114], Loss: 2.7797, Perplexity: 16.1139\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.8781, Perplexity: 17.7802\n",
            "Step [50/127], Loss: 3.2020, Perplexity: 24.5810\n",
            "Step [100/127], Loss: 3.2361, Perplexity: 25.4338\n",
            "updated best val loss: 3.04472\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/lstm/\n",
            "Switch to training...\n",
            "Epoch [11/50], Step [0/114], Loss: 2.7254, Perplexity: 15.2622\n",
            "Epoch [11/50], Step [50/114], Loss: 2.7494, Perplexity: 15.6325\n",
            "Epoch [11/50], Step [100/114], Loss: 2.6888, Perplexity: 14.7136\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.9019, Perplexity: 18.2078\n",
            "Step [50/127], Loss: 3.1535, Perplexity: 23.4176\n",
            "Step [100/127], Loss: 2.8617, Perplexity: 17.4918\n",
            "updated best val loss: 3.0443063\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/lstm/\n",
            "Switch to training...\n",
            "Epoch [12/50], Step [0/114], Loss: 2.6748, Perplexity: 14.5093\n",
            "Epoch [12/50], Step [50/114], Loss: 2.7178, Perplexity: 15.1465\n",
            "Epoch [12/50], Step [100/114], Loss: 2.6686, Perplexity: 14.4204\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.6200, Perplexity: 37.3389\n",
            "Step [50/127], Loss: 2.8899, Perplexity: 17.9922\n",
            "Step [100/127], Loss: 2.3981, Perplexity: 11.0025\n",
            "updated best val loss: 3.0291443\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/lstm/\n",
            "Switch to training...\n",
            "Epoch [13/50], Step [0/114], Loss: 2.6911, Perplexity: 14.7485\n",
            "Epoch [13/50], Step [50/114], Loss: 2.6737, Perplexity: 14.4933\n",
            "Epoch [13/50], Step [100/114], Loss: 2.6856, Perplexity: 14.6664\n",
            "Validating...\n",
            "Step [0/127], Loss: 4.0244, Perplexity: 55.9483\n",
            "Step [50/127], Loss: 2.6829, Perplexity: 14.6278\n",
            "Step [100/127], Loss: 2.5474, Perplexity: 12.7739\n",
            "Switch to training...\n",
            "Epoch [14/50], Step [0/114], Loss: 2.6295, Perplexity: 13.8664\n",
            "Epoch [14/50], Step [50/114], Loss: 2.6198, Perplexity: 13.7334\n",
            "Epoch [14/50], Step [100/114], Loss: 2.6263, Perplexity: 13.8223\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.9465, Perplexity: 51.7557\n",
            "Step [50/127], Loss: 2.6702, Perplexity: 14.4429\n",
            "Step [100/127], Loss: 2.4425, Perplexity: 11.5020\n",
            "Switch to training...\n",
            "Epoch [15/50], Step [0/114], Loss: 2.6463, Perplexity: 14.1012\n",
            "Epoch [15/50], Step [50/114], Loss: 2.6986, Perplexity: 14.8593\n",
            "Epoch [15/50], Step [100/114], Loss: 2.6466, Perplexity: 14.1061\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.7349, Perplexity: 41.8854\n",
            "Step [50/127], Loss: 3.2410, Perplexity: 25.5585\n",
            "Step [100/127], Loss: 3.0404, Perplexity: 20.9127\n",
            "Switch to training...\n",
            "Epoch [16/50], Step [0/114], Loss: 2.6285, Perplexity: 13.8529\n",
            "Epoch [16/50], Step [50/114], Loss: 2.6277, Perplexity: 13.8425\n",
            "Epoch [16/50], Step [100/114], Loss: 2.6231, Perplexity: 13.7789\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.5185, Perplexity: 33.7336\n",
            "Step [50/127], Loss: 3.1472, Perplexity: 23.2714\n",
            "Step [100/127], Loss: 3.3657, Perplexity: 28.9529\n",
            "Switch to training...\n",
            "Epoch [17/50], Step [0/114], Loss: 2.6180, Perplexity: 13.7086\n",
            "Epoch [17/50], Step [50/114], Loss: 2.6989, Perplexity: 14.8635\n",
            "Epoch [17/50], Step [100/114], Loss: 2.5263, Perplexity: 12.5069\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.2067, Perplexity: 24.6987\n",
            "Step [50/127], Loss: 2.6718, Perplexity: 14.4664\n",
            "Step [100/127], Loss: 3.1423, Perplexity: 23.1572\n",
            "Switch to training...\n",
            "Epoch [18/50], Step [0/114], Loss: 2.5925, Perplexity: 13.3637\n",
            "Epoch [18/50], Step [50/114], Loss: 2.6111, Perplexity: 13.6140\n",
            "Epoch [18/50], Step [100/114], Loss: 2.6702, Perplexity: 14.4423\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.4684, Perplexity: 32.0845\n",
            "Step [50/127], Loss: 2.7605, Perplexity: 15.8077\n",
            "Step [100/127], Loss: 2.8227, Perplexity: 16.8222\n",
            "Switch to training...\n",
            "Epoch [19/50], Step [0/114], Loss: 2.6047, Perplexity: 13.5274\n",
            "Epoch [19/50], Step [50/114], Loss: 2.6314, Perplexity: 13.8937\n",
            "Epoch [19/50], Step [100/114], Loss: 2.5866, Perplexity: 13.2846\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.8533, Perplexity: 47.1493\n",
            "Step [50/127], Loss: 3.2070, Perplexity: 24.7048\n",
            "Step [100/127], Loss: 2.8719, Perplexity: 17.6704\n",
            "Switch to training...\n",
            "Epoch [20/50], Step [0/114], Loss: 2.5811, Perplexity: 13.2112\n",
            "Epoch [20/50], Step [50/114], Loss: 2.5334, Perplexity: 12.5960\n",
            "Epoch [20/50], Step [100/114], Loss: 2.6664, Perplexity: 14.3874\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.5028, Perplexity: 12.2167\n",
            "Step [50/127], Loss: 2.9807, Perplexity: 19.7020\n",
            "Step [100/127], Loss: 3.0448, Perplexity: 21.0069\n",
            "updated best val loss: 2.9981515\n",
            "Save model weights to... /content/drive/My Drive/Assignment_4//checkpoints/lstm/\n",
            "Switch to training...\n",
            "Epoch [21/50], Step [0/114], Loss: 2.6057, Perplexity: 13.5408\n",
            "Epoch [21/50], Step [50/114], Loss: 2.5727, Perplexity: 13.1017\n",
            "Epoch [21/50], Step [100/114], Loss: 2.5466, Perplexity: 12.7640\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.5020, Perplexity: 12.2066\n",
            "Step [50/127], Loss: 3.1290, Perplexity: 22.8502\n",
            "Step [100/127], Loss: 2.8165, Perplexity: 16.7190\n",
            "Switch to training...\n",
            "Epoch [22/50], Step [0/114], Loss: 2.5693, Perplexity: 13.0568\n",
            "Epoch [22/50], Step [50/114], Loss: 2.5442, Perplexity: 12.7327\n",
            "Epoch [22/50], Step [100/114], Loss: 2.5783, Perplexity: 13.1742\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.6548, Perplexity: 38.6607\n",
            "Step [50/127], Loss: 3.6007, Perplexity: 36.6227\n",
            "Step [100/127], Loss: 3.1069, Perplexity: 22.3506\n",
            "Switch to training...\n",
            "Epoch [23/50], Step [0/114], Loss: 2.5668, Perplexity: 13.0234\n",
            "Epoch [23/50], Step [50/114], Loss: 2.5429, Perplexity: 12.7168\n",
            "Epoch [23/50], Step [100/114], Loss: 2.5796, Perplexity: 13.1915\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.0134, Perplexity: 20.3563\n",
            "Step [50/127], Loss: 2.9865, Perplexity: 19.8171\n",
            "Step [100/127], Loss: 3.2859, Perplexity: 26.7329\n",
            "Switch to training...\n",
            "Epoch [24/50], Step [0/114], Loss: 2.6288, Perplexity: 13.8575\n",
            "Epoch [24/50], Step [50/114], Loss: 2.5603, Perplexity: 12.9400\n",
            "Epoch [24/50], Step [100/114], Loss: 2.6305, Perplexity: 13.8811\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.6791, Perplexity: 14.5714\n",
            "Step [50/127], Loss: 2.7423, Perplexity: 15.5231\n",
            "Step [100/127], Loss: 4.0222, Perplexity: 55.8216\n",
            "Switch to training...\n",
            "Epoch [25/50], Step [0/114], Loss: 2.5925, Perplexity: 13.3630\n",
            "Epoch [25/50], Step [50/114], Loss: 2.5234, Perplexity: 12.4714\n",
            "Epoch [25/50], Step [100/114], Loss: 2.5678, Perplexity: 13.0373\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.7694, Perplexity: 43.3542\n",
            "Step [50/127], Loss: 3.6405, Perplexity: 38.1099\n",
            "Step [100/127], Loss: 3.2656, Perplexity: 26.1949\n",
            "Switch to training...\n",
            "Epoch [26/50], Step [0/114], Loss: 2.5085, Perplexity: 12.2862\n",
            "Epoch [26/50], Step [50/114], Loss: 2.5284, Perplexity: 12.5335\n",
            "Epoch [26/50], Step [100/114], Loss: 2.5607, Perplexity: 12.9449\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.6296, Perplexity: 37.6993\n",
            "Step [50/127], Loss: 2.9774, Perplexity: 19.6369\n",
            "Step [100/127], Loss: 3.1251, Perplexity: 22.7628\n",
            "Switch to training...\n",
            "Epoch [27/50], Step [0/114], Loss: 2.5236, Perplexity: 12.4730\n",
            "Epoch [27/50], Step [50/114], Loss: 2.5334, Perplexity: 12.5969\n",
            "Epoch [27/50], Step [100/114], Loss: 2.5527, Perplexity: 12.8414\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.2455, Perplexity: 25.6757\n",
            "Step [50/127], Loss: 2.7564, Perplexity: 15.7426\n",
            "Step [100/127], Loss: 3.0820, Perplexity: 21.8025\n",
            "Switch to training...\n",
            "Epoch [28/50], Step [0/114], Loss: 2.5883, Perplexity: 13.3069\n",
            "Epoch [28/50], Step [50/114], Loss: 2.5931, Perplexity: 13.3715\n",
            "Epoch [28/50], Step [100/114], Loss: 2.5346, Perplexity: 12.6120\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.1652, Perplexity: 23.6944\n",
            "Step [50/127], Loss: 2.9728, Perplexity: 19.5462\n",
            "Step [100/127], Loss: 3.1369, Perplexity: 23.0313\n",
            "Switch to training...\n",
            "Epoch [29/50], Step [0/114], Loss: 2.5192, Perplexity: 12.4182\n",
            "Epoch [29/50], Step [50/114], Loss: 2.5797, Perplexity: 13.1926\n",
            "Epoch [29/50], Step [100/114], Loss: 2.5701, Perplexity: 13.0672\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.9072, Perplexity: 18.3058\n",
            "Step [50/127], Loss: 2.9442, Perplexity: 18.9962\n",
            "Step [100/127], Loss: 3.0853, Perplexity: 21.8750\n",
            "Switch to training...\n",
            "Epoch [30/50], Step [0/114], Loss: 2.5963, Perplexity: 13.4143\n",
            "Epoch [30/50], Step [50/114], Loss: 2.5825, Perplexity: 13.2299\n",
            "Epoch [30/50], Step [100/114], Loss: 2.5244, Perplexity: 12.4835\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.9635, Perplexity: 19.3649\n",
            "Step [50/127], Loss: 3.1148, Perplexity: 22.5296\n",
            "Step [100/127], Loss: 2.7619, Perplexity: 15.8297\n",
            "Switch to training...\n",
            "Epoch [31/50], Step [0/114], Loss: 2.5337, Perplexity: 12.5997\n",
            "Epoch [31/50], Step [50/114], Loss: 2.5460, Perplexity: 12.7561\n",
            "Epoch [31/50], Step [100/114], Loss: 2.5937, Perplexity: 13.3798\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.4050, Perplexity: 30.1130\n",
            "Step [50/127], Loss: 2.9483, Perplexity: 19.0733\n",
            "Step [100/127], Loss: 2.6957, Perplexity: 14.8160\n",
            "Switch to training...\n",
            "Epoch [32/50], Step [0/114], Loss: 2.5107, Perplexity: 12.3131\n",
            "Epoch [32/50], Step [50/114], Loss: 2.5141, Perplexity: 12.3554\n",
            "Epoch [32/50], Step [100/114], Loss: 2.5356, Perplexity: 12.6235\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.6251, Perplexity: 13.8065\n",
            "Step [50/127], Loss: 2.7329, Perplexity: 15.3778\n",
            "Step [100/127], Loss: 2.8465, Perplexity: 17.2281\n",
            "Switch to training...\n",
            "Epoch [33/50], Step [0/114], Loss: 2.5650, Perplexity: 13.0005\n",
            "Epoch [33/50], Step [50/114], Loss: 2.4973, Perplexity: 12.1502\n",
            "Epoch [33/50], Step [100/114], Loss: 2.5421, Perplexity: 12.7069\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.8147, Perplexity: 16.6882\n",
            "Step [50/127], Loss: 2.4725, Perplexity: 11.8515\n",
            "Step [100/127], Loss: 3.0801, Perplexity: 21.7606\n",
            "Switch to training...\n",
            "Epoch [34/50], Step [0/114], Loss: 2.4540, Perplexity: 11.6352\n",
            "Epoch [34/50], Step [50/114], Loss: 2.5384, Perplexity: 12.6593\n",
            "Epoch [34/50], Step [100/114], Loss: 2.4998, Perplexity: 12.1800\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.0750, Perplexity: 21.6507\n",
            "Step [50/127], Loss: 3.3012, Perplexity: 27.1464\n",
            "Step [100/127], Loss: 3.0325, Perplexity: 20.7481\n",
            "Switch to training...\n",
            "Epoch [35/50], Step [0/114], Loss: 2.5465, Perplexity: 12.7619\n",
            "Epoch [35/50], Step [50/114], Loss: 2.4973, Perplexity: 12.1495\n",
            "Epoch [35/50], Step [100/114], Loss: 2.5220, Perplexity: 12.4537\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.2533, Perplexity: 25.8747\n",
            "Step [50/127], Loss: 3.1755, Perplexity: 23.9381\n",
            "Step [100/127], Loss: 2.6607, Perplexity: 14.3056\n",
            "Switch to training...\n",
            "Epoch [36/50], Step [0/114], Loss: 2.5545, Perplexity: 12.8642\n",
            "Epoch [36/50], Step [50/114], Loss: 2.4464, Perplexity: 11.5462\n",
            "Epoch [36/50], Step [100/114], Loss: 2.4413, Perplexity: 11.4875\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.4935, Perplexity: 12.1032\n",
            "Step [50/127], Loss: 3.3204, Perplexity: 27.6701\n",
            "Step [100/127], Loss: 3.1665, Perplexity: 23.7248\n",
            "Switch to training...\n",
            "Epoch [37/50], Step [0/114], Loss: 2.5414, Perplexity: 12.6975\n",
            "Epoch [37/50], Step [50/114], Loss: 2.5384, Perplexity: 12.6593\n",
            "Epoch [37/50], Step [100/114], Loss: 2.5206, Perplexity: 12.4359\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.6767, Perplexity: 14.5370\n",
            "Step [50/127], Loss: 2.5014, Perplexity: 12.1999\n",
            "Step [100/127], Loss: 3.7313, Perplexity: 41.7319\n",
            "Switch to training...\n",
            "Epoch [38/50], Step [0/114], Loss: 2.5265, Perplexity: 12.5098\n",
            "Epoch [38/50], Step [50/114], Loss: 2.5181, Perplexity: 12.4050\n",
            "Epoch [38/50], Step [100/114], Loss: 2.6069, Perplexity: 13.5574\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.4452, Perplexity: 11.5326\n",
            "Step [50/127], Loss: 3.2569, Perplexity: 25.9699\n",
            "Step [100/127], Loss: 3.1782, Perplexity: 24.0037\n",
            "Switch to training...\n",
            "Epoch [39/50], Step [0/114], Loss: 2.5843, Perplexity: 13.2543\n",
            "Epoch [39/50], Step [50/114], Loss: 2.5653, Perplexity: 13.0050\n",
            "Epoch [39/50], Step [100/114], Loss: 2.5749, Perplexity: 13.1302\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.4082, Perplexity: 11.1139\n",
            "Step [50/127], Loss: 2.5451, Perplexity: 12.7440\n",
            "Step [100/127], Loss: 3.0228, Perplexity: 20.5482\n",
            "Switch to training...\n",
            "Epoch [40/50], Step [0/114], Loss: 2.5317, Perplexity: 12.5755\n",
            "Epoch [40/50], Step [50/114], Loss: 2.5633, Perplexity: 12.9786\n",
            "Epoch [40/50], Step [100/114], Loss: 2.5194, Perplexity: 12.4216\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.5741, Perplexity: 35.6612\n",
            "Step [50/127], Loss: 2.8200, Perplexity: 16.7766\n",
            "Step [100/127], Loss: 3.6117, Perplexity: 37.0288\n",
            "Switch to training...\n",
            "Epoch [41/50], Step [0/114], Loss: 2.5105, Perplexity: 12.3108\n",
            "Epoch [41/50], Step [50/114], Loss: 2.5571, Perplexity: 12.8985\n",
            "Epoch [41/50], Step [100/114], Loss: 2.5110, Perplexity: 12.3178\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.9019, Perplexity: 18.2092\n",
            "Step [50/127], Loss: 2.4933, Perplexity: 12.1007\n",
            "Step [100/127], Loss: 3.2466, Perplexity: 25.7024\n",
            "Switch to training...\n",
            "Epoch [42/50], Step [0/114], Loss: 2.4376, Perplexity: 11.4461\n",
            "Epoch [42/50], Step [50/114], Loss: 2.4992, Perplexity: 12.1731\n",
            "Epoch [42/50], Step [100/114], Loss: 2.4609, Perplexity: 11.7158\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.5597, Perplexity: 12.9316\n",
            "Step [50/127], Loss: 2.6314, Perplexity: 13.8933\n",
            "Step [100/127], Loss: 3.3994, Perplexity: 29.9460\n",
            "Switch to training...\n",
            "Epoch [43/50], Step [0/114], Loss: 2.5452, Perplexity: 12.7457\n",
            "Epoch [43/50], Step [50/114], Loss: 2.5418, Perplexity: 12.7025\n",
            "Epoch [43/50], Step [100/114], Loss: 2.6012, Perplexity: 13.4805\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.4804, Perplexity: 32.4738\n",
            "Step [50/127], Loss: 3.1526, Perplexity: 23.3980\n",
            "Step [100/127], Loss: 3.0286, Perplexity: 20.6672\n",
            "Switch to training...\n",
            "Epoch [44/50], Step [0/114], Loss: 2.5393, Perplexity: 12.6703\n",
            "Epoch [44/50], Step [50/114], Loss: 2.4892, Perplexity: 12.0515\n",
            "Epoch [44/50], Step [100/114], Loss: 2.5495, Perplexity: 12.8012\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.5867, Perplexity: 13.2854\n",
            "Step [50/127], Loss: 3.7117, Perplexity: 40.9220\n",
            "Step [100/127], Loss: 3.6380, Perplexity: 38.0173\n",
            "Switch to training...\n",
            "Epoch [45/50], Step [0/114], Loss: 2.5785, Perplexity: 13.1780\n",
            "Epoch [45/50], Step [50/114], Loss: 2.5009, Perplexity: 12.1939\n",
            "Epoch [45/50], Step [100/114], Loss: 2.5578, Perplexity: 12.9078\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.9660, Perplexity: 19.4132\n",
            "Step [50/127], Loss: 2.7666, Perplexity: 15.9045\n",
            "Step [100/127], Loss: 2.4989, Perplexity: 12.1685\n",
            "Switch to training...\n",
            "Epoch [46/50], Step [0/114], Loss: 2.5385, Perplexity: 12.6606\n",
            "Epoch [46/50], Step [50/114], Loss: 2.5140, Perplexity: 12.3539\n",
            "Epoch [46/50], Step [100/114], Loss: 2.4591, Perplexity: 11.6938\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.6401, Perplexity: 38.0969\n",
            "Step [50/127], Loss: 2.9408, Perplexity: 18.9302\n",
            "Step [100/127], Loss: 3.1098, Perplexity: 22.4171\n",
            "Switch to training...\n",
            "Epoch [47/50], Step [0/114], Loss: 2.4728, Perplexity: 11.8560\n",
            "Epoch [47/50], Step [50/114], Loss: 2.5288, Perplexity: 12.5387\n",
            "Epoch [47/50], Step [100/114], Loss: 2.5429, Perplexity: 12.7165\n",
            "Validating...\n",
            "Step [0/127], Loss: 3.0724, Perplexity: 21.5943\n",
            "Step [50/127], Loss: 2.9376, Perplexity: 18.8707\n",
            "Step [100/127], Loss: 3.2140, Perplexity: 24.8792\n",
            "Switch to training...\n",
            "Epoch [48/50], Step [0/114], Loss: 2.5670, Perplexity: 13.0267\n",
            "Epoch [48/50], Step [50/114], Loss: 2.5721, Perplexity: 13.0931\n",
            "Epoch [48/50], Step [100/114], Loss: 2.5100, Perplexity: 12.3043\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.6364, Perplexity: 13.9629\n",
            "Step [50/127], Loss: 2.5057, Perplexity: 12.2526\n",
            "Step [100/127], Loss: 2.9828, Perplexity: 19.7423\n",
            "Switch to training...\n",
            "Epoch [49/50], Step [0/114], Loss: 2.4831, Perplexity: 11.9783\n",
            "Epoch [49/50], Step [50/114], Loss: 2.5612, Perplexity: 12.9511\n",
            "Epoch [49/50], Step [100/114], Loss: 2.4604, Perplexity: 11.7093\n",
            "Validating...\n",
            "Step [0/127], Loss: 2.8807, Perplexity: 17.8268\n",
            "Step [50/127], Loss: 3.1247, Perplexity: 22.7522\n",
            "Step [100/127], Loss: 2.7738, Perplexity: 16.0188\n",
            "It took: 12387.99500656128 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMlrpmkh8Him"
      },
      "source": [
        "## Section 3.1.3 Evalution [10 pts]\n",
        "Evaluate your model on the test set by perplexity score or BLEU score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm9tcQqe8Hin"
      },
      "source": [
        "## Evaluate your model using BLEU score. Use Deterministic mode.\n",
        "# Your code here\n",
        "## evaluation code\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "smoother = SmoothingFunction()\n",
        "\n",
        "def caption_generator(model, images, vocab, img_ids, captions, mode='Deterministic', temperature=1.0):\n",
        "    \"\"\"\n",
        "    Generate captions.\n",
        "    :param mode:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    sample_idxs = model.sample_generate(images, mode=mode,\n",
        "                                        temperature=temperature).data.cpu().numpy()  # [N, max_length]\n",
        "    for i, sentence in enumerate(sample_idxs):  # every sentence in this batch\n",
        "        sentence_caption = ''\n",
        "        for word_idx in sentence:\n",
        "            word = vocab.idx2word[word_idx]\n",
        "            if word != '<start>' and word != '<end>':\n",
        "                if word == '.':\n",
        "                    sentence_caption += '.'\n",
        "                else:\n",
        "                    sentence_caption += word + ' '\n",
        "            if word == '<end>':\n",
        "                break\n",
        "        captions.append({'caption': sentence_caption})\n",
        "        # captions.append(sentence_caption)\n",
        "\n",
        "    return captions\n",
        "\n",
        "def run_test(model, data_loader, vocab, mode='Deterministic', temperature=1.0):\n",
        "    \"\"\"\n",
        "    Run your model on the test set.\n",
        "    Inputs:\n",
        "    :param model: the model you use\n",
        "    :param data_loader: the data_loader\n",
        "    :param mode: use 'deterministic' or 'stochastic'\n",
        "    Outputs:\n",
        "    :param predictions\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    for itr, (images, captions, lengths) in enumerate(tqdm(data_loader)):\n",
        "        images = Variable(images).to(device)\n",
        "        captions = Variable(captions).to(device)\n",
        "        outputs = model(images, captions, lengths)\n",
        "        \n",
        "        img_ids = list(range(itr * data_loader.batch_size, (itr + 1) * data_loader.batch_size))\n",
        "        predictions = caption_generator(model, images, vocab, img_ids, \n",
        "                                        predictions, mode=mode, temperature=temperature)\n",
        "        \n",
        "    return predictions\n",
        "\n",
        "def evaluation(model, vocab, data_path=path_to_homework + '/flickr30k_images/', mode='Deterministic', temperature=1.0,\n",
        "               split='test'):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of your model on the test set using BLEU scores.\n",
        "    Inputs:\n",
        "    :param model: the model you use\n",
        "    :param weight_path: the directory to the weights of your model\n",
        "    :param vocab: vocabulary\n",
        "    :param data_path: the directory to the dataset\n",
        "    :param mode: use 'deterministic' or 'stochastic'\n",
        "    Outputs:\n",
        "    :param predictions\n",
        "    \"\"\"\n",
        "    # data loader\n",
        "    test_data_loader = get_loader(root=path_to_homework + '/flickr30k_images/', split=split, vocab=vocab, \n",
        "                                  transform=transform, batch_size=8, shuffle=False, num_workers=4)\n",
        "    \n",
        "    # run your model on the test set\n",
        "    print('Run on the test set...')\n",
        "    preds = run_test(model, test_data_loader, vocab, mode, temperature)\n",
        "    \n",
        "    # load the groundtruth\n",
        "    gt = test_data_loader.dataset.annos\n",
        "    \n",
        "    # evaluate the performance using BLEU score\n",
        "    score1 = 0\n",
        "    score2 = 0\n",
        "    score3 = 0\n",
        "    score4 = 0\n",
        "    \n",
        "    print('Computing BLEU')\n",
        "    for itr in tqdm(range(len(gt))):\n",
        "        candidate = preds[itr]['caption']\n",
        "        reference = [sent['raw'] for sent in gt[itr]['sentences']]\n",
        "        score1 += sentence_bleu(reference, candidate, weights=(1, 0, 0, 0), smoothing_function=smoother.method1)\n",
        "        score2 += sentence_bleu(reference, candidate, weights=(0, 1, 0, 0), smoothing_function=smoother.method1)\n",
        "        score3 += sentence_bleu(reference, candidate, weights=(0, 0, 1, 0), smoothing_function=smoother.method1)\n",
        "        score4 += sentence_bleu(reference, candidate, weights=(0, 0, 0, 1), smoothing_function=smoother.method1)\n",
        "    \n",
        "    bleu1 = 100 * score1/len(gt)\n",
        "    bleu2 = 100 * score2/len(gt)\n",
        "    bleu3 = 100 * score3/len(gt)\n",
        "    bleu4 = 100 * score4/len(gt)\n",
        "    \n",
        "    return bleu1, bleu2, bleu3, bleu4\n",
        "\n",
        "# End of code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKjjjkaa8Hip",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1fd13157-73a0-450a-f50e-83f7a6885354"
      },
      "source": [
        "## Use at least 3 different temperatures to generate captions on the test set. Report the BLEU scores.\n",
        "# Your code here\n",
        "## Image transformation\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        #     transforms.RandomCrop(224, pad_if_needed=True),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                             std=(0.229, 0.224, 0.225))])\n",
        "\n",
        "## Evaluate your model using BLEU score. Use Deterministic mode\n",
        "model = LSTM(vocab_size=len(vocab), emb_dim=emb_dim, hidden_dim=hidden_dim, \n",
        "                   num_layers=1, dropout=dropout).to(device)  # build a model\n",
        "model.load_state_dict(torch.load(path_to_homework + '/checkpoints/lstm/lstm-best.pth', map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "bleu1, bleu2, bleu3, bleu4 = evaluation(model, vocab, mode='Deterministic')\n",
        "print(\"BLEU 1:{}, BLEU 2:{}, BLEU 3:{}, BLEU 4:{}\".format(bleu1, bleu2, bleu3, bleu4))\n",
        "\n",
        "# End of code"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Run on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  1%|          | 1/125 [00:04<08:40,  4.20s/it]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 2/125 [00:07<07:58,  3.89s/it]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 3/125 [00:10<07:27,  3.67s/it]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 4/125 [00:13<07:06,  3.52s/it]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 5/125 [00:16<06:50,  3.42s/it]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▍         | 6/125 [00:20<06:37,  3.34s/it]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 7/125 [00:23<06:28,  3.29s/it]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▋         | 8/125 [00:26<06:21,  3.26s/it]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 9/125 [00:29<06:17,  3.25s/it]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 10/125 [00:32<06:11,  3.23s/it]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 11/125 [00:36<06:07,  3.22s/it]\u001b[A\u001b[A\n",
            "\n",
            " 10%|▉         | 12/125 [00:39<06:02,  3.21s/it]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 13/125 [00:42<05:57,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 14/125 [00:45<05:53,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 15/125 [00:48<05:50,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 16/125 [00:51<05:47,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▎        | 17/125 [00:55<05:45,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 18/125 [00:58<05:44,  3.22s/it]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 19/125 [01:01<05:42,  3.23s/it]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 20/125 [01:04<05:40,  3.25s/it]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 21/125 [01:08<05:38,  3.25s/it]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 22/125 [01:11<05:34,  3.24s/it]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 23/125 [01:14<05:30,  3.24s/it]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 24/125 [01:17<05:28,  3.26s/it]\u001b[A\u001b[A\n",
            "\n",
            " 20%|██        | 25/125 [01:21<05:24,  3.25s/it]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 26/125 [01:24<05:20,  3.24s/it]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 27/125 [01:27<05:15,  3.22s/it]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 28/125 [01:30<05:10,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 29/125 [01:33<05:06,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 30/125 [01:37<05:02,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▍       | 31/125 [01:40<04:58,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 32/125 [01:43<04:55,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▋       | 33/125 [01:46<04:51,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 34/125 [01:49<04:52,  3.22s/it]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 35/125 [01:53<04:48,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 36/125 [01:56<04:45,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 30%|██▉       | 37/125 [01:59<04:41,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 38/125 [02:02<04:37,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 39/125 [02:05<04:34,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 40/125 [02:09<04:31,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 41/125 [02:12<04:27,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▎      | 42/125 [02:15<04:23,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 43/125 [02:18<04:21,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▌      | 44/125 [02:21<04:18,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 45/125 [02:24<04:15,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 46/125 [02:28<04:12,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 47/125 [02:31<04:08,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 48/125 [02:34<04:04,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 49/125 [02:37<04:01,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 50/125 [02:40<03:58,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 51/125 [02:44<03:54,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 52/125 [02:47<03:51,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 53/125 [02:50<03:48,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 54/125 [02:53<03:45,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 55/125 [02:56<03:43,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▍     | 56/125 [02:59<03:39,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 57/125 [03:03<03:36,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▋     | 58/125 [03:06<03:32,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 59/125 [03:09<03:29,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 60/125 [03:12<03:26,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 61/125 [03:15<03:22,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|████▉     | 62/125 [03:18<03:19,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 63/125 [03:22<03:16,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 64/125 [03:25<03:13,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 65/125 [03:28<03:10,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 66/125 [03:31<03:06,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▎    | 67/125 [03:34<03:03,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 68/125 [03:37<03:00,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▌    | 69/125 [03:41<02:57,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 70/125 [03:44<02:53,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 71/125 [03:47<02:51,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 72/125 [03:50<02:48,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 73/125 [03:53<02:45,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 74/125 [03:57<02:43,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 75/125 [04:00<02:39,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 76/125 [04:03<02:36,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 77/125 [04:06<02:33,  3.21s/it]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 78/125 [04:09<02:30,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 79/125 [04:13<02:27,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 80/125 [04:16<02:24,  3.22s/it]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▍   | 81/125 [04:19<02:22,  3.23s/it]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 82/125 [04:22<02:18,  3.23s/it]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▋   | 83/125 [04:26<02:15,  3.23s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 84/125 [04:29<02:12,  3.22s/it]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 85/125 [04:32<02:08,  3.21s/it]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 86/125 [04:35<02:05,  3.21s/it]\u001b[A\u001b[A\n",
            "\n",
            " 70%|██████▉   | 87/125 [04:38<02:02,  3.21s/it]\u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 88/125 [04:42<01:58,  3.21s/it]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 89/125 [04:45<01:55,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 90/125 [04:48<01:52,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 91/125 [04:51<01:48,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▎  | 92/125 [04:54<01:45,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 93/125 [04:58<01:42,  3.21s/it]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 94/125 [05:01<01:39,  3.21s/it]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 95/125 [05:04<01:35,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 96/125 [05:07<01:32,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 97/125 [05:10<01:29,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 98/125 [05:14<01:26,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 99/125 [05:17<01:22,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 100/125 [05:20<01:19,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 101/125 [05:23<01:16,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 102/125 [05:26<01:13,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 103/125 [05:29<01:10,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 104/125 [05:33<01:06,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 105/125 [05:36<01:03,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▍ | 106/125 [05:39<01:00,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 107/125 [05:42<00:57,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▋ | 108/125 [05:45<00:53,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 109/125 [05:48<00:50,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 110/125 [05:52<00:47,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 111/125 [05:55<00:44,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 90%|████████▉ | 112/125 [05:58<00:41,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 113/125 [06:01<00:38,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 114/125 [06:04<00:35,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 115/125 [06:08<00:31,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 116/125 [06:11<00:28,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▎| 117/125 [06:14<00:25,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 118/125 [06:17<00:22,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▌| 119/125 [06:20<00:18,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 120/125 [06:23<00:15,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 121/125 [06:26<00:12,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 122/125 [06:30<00:09,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 123/125 [06:33<00:06,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 124/125 [06:36<00:03,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 125/125 [06:39<00:00,  3.20s/it]\n",
            "\n",
            "\n",
            "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 24/1000 [00:00<00:04, 232.32it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Computing BLEU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  4%|▍         | 44/1000 [00:00<00:04, 221.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▋         | 65/1000 [00:00<00:04, 216.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▊         | 86/1000 [00:00<00:04, 213.06it/s]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 109/1000 [00:00<00:04, 215.89it/s]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 128/1000 [00:00<00:04, 206.54it/s]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 151/1000 [00:00<00:04, 210.84it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 174/1000 [00:00<00:03, 215.08it/s]\u001b[A\u001b[A\n",
            "\n",
            " 20%|█▉        | 197/1000 [00:00<00:03, 217.85it/s]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 220/1000 [00:01<00:03, 220.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 244/1000 [00:01<00:03, 223.71it/s]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 267/1000 [00:01<00:03, 224.85it/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 290/1000 [00:01<00:03, 224.20it/s]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███▏      | 313/1000 [00:01<00:03, 225.37it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▎      | 336/1000 [00:01<00:02, 224.00it/s]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 359/1000 [00:01<00:02, 218.60it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 381/1000 [00:01<00:02, 217.96it/s]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 405/1000 [00:01<00:02, 223.15it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 428/1000 [00:01<00:02, 222.15it/s]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▌     | 451/1000 [00:02<00:02, 223.85it/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 474/1000 [00:02<00:02, 223.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|████▉     | 497/1000 [00:02<00:02, 222.13it/s]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 521/1000 [00:02<00:02, 225.85it/s]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 544/1000 [00:02<00:02, 221.37it/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 567/1000 [00:02<00:02, 210.26it/s]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 589/1000 [00:02<00:01, 210.61it/s]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 611/1000 [00:02<00:01, 211.63it/s]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 634/1000 [00:02<00:01, 215.16it/s]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 656/1000 [00:03<00:01, 214.51it/s]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 678/1000 [00:03<00:01, 212.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 700/1000 [00:03<00:01, 210.92it/s]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 723/1000 [00:03<00:01, 213.98it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▍  | 746/1000 [00:03<00:01, 216.38it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 769/1000 [00:03<00:01, 218.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 791/1000 [00:03<00:00, 210.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████▏ | 813/1000 [00:03<00:00, 207.77it/s]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▎ | 835/1000 [00:03<00:00, 208.65it/s]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 857/1000 [00:03<00:00, 211.79it/s]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 879/1000 [00:04<00:00, 209.46it/s]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 900/1000 [00:04<00:00, 206.31it/s]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 921/1000 [00:04<00:00, 200.87it/s]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 943/1000 [00:04<00:00, 204.39it/s]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▋| 965/1000 [00:04<00:00, 208.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 1000/1000 [00:04<00:00, 214.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU 1:90.94035469084693, BLEU 2:65.86864561698819, BLEU 3:41.163834409771844, BLEU 4:27.814403103582656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kmnmvLeGKEN"
      },
      "source": [
        "## Evaluate your model using BLEU score. Use Deterministic mode.\n",
        "# Your code here\n",
        "## evaluation code\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "smoother = SmoothingFunction()\n",
        "\n",
        "def caption_generator(model, images, vocab, img_ids, captions, mode='Deterministic', temperature=1.5):\n",
        "    \"\"\"\n",
        "    Generate captions.\n",
        "    :param mode:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    sample_idxs = model.sample_generate(images, mode=mode,\n",
        "                                        temperature=temperature).data.cpu().numpy()  # [N, max_length]\n",
        "    for i, sentence in enumerate(sample_idxs):  # every sentence in this batch\n",
        "        sentence_caption = ''\n",
        "        for word_idx in sentence:\n",
        "            word = vocab.idx2word[word_idx]\n",
        "            if word != '<start>' and word != '<end>':\n",
        "                if word == '.':\n",
        "                    sentence_caption += '.'\n",
        "                else:\n",
        "                    sentence_caption += word + ' '\n",
        "            if word == '<end>':\n",
        "                break\n",
        "        captions.append({'caption': sentence_caption})\n",
        "        # captions.append(sentence_caption)\n",
        "\n",
        "    return captions\n",
        "\n",
        "def run_test(model, data_loader, vocab, mode='Deterministic', temperature=1.5):\n",
        "    \"\"\"\n",
        "    Run your model on the test set.\n",
        "    Inputs:\n",
        "    :param model: the model you use\n",
        "    :param data_loader: the data_loader\n",
        "    :param mode: use 'deterministic' or 'stochastic'\n",
        "    Outputs:\n",
        "    :param predictions\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    for itr, (images, captions, lengths) in enumerate(tqdm(data_loader)):\n",
        "        images = Variable(images).to(device)\n",
        "        captions = Variable(captions).to(device)\n",
        "        outputs = model(images, captions, lengths)\n",
        "        \n",
        "        img_ids = list(range(itr * data_loader.batch_size, (itr + 1) * data_loader.batch_size))\n",
        "        predictions = caption_generator(model, images, vocab, img_ids, \n",
        "                                        predictions, mode=mode, temperature=temperature)\n",
        "        \n",
        "    return predictions\n",
        "\n",
        "def evaluation(model, vocab, data_path=path_to_homework + '/flickr30k_images/', mode='Deterministic', temperature=1.5,\n",
        "               split='test'):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of your model on the test set using BLEU scores.\n",
        "    Inputs:\n",
        "    :param model: the model you use\n",
        "    :param weight_path: the directory to the weights of your model\n",
        "    :param vocab: vocabulary\n",
        "    :param data_path: the directory to the dataset\n",
        "    :param mode: use 'deterministic' or 'stochastic'\n",
        "    Outputs:\n",
        "    :param predictions\n",
        "    \"\"\"\n",
        "    # data loader\n",
        "    test_data_loader = get_loader(root=path_to_homework + '/flickr30k_images/', split=split, vocab=vocab, \n",
        "                                  transform=transform, batch_size=8, shuffle=False, num_workers=4)\n",
        "    \n",
        "    # run your model on the test set\n",
        "    print('Run on the test set...')\n",
        "    preds = run_test(model, test_data_loader, vocab, mode, temperature)\n",
        "    \n",
        "    # load the groundtruth\n",
        "    gt = test_data_loader.dataset.annos\n",
        "    \n",
        "    # evaluate the performance using BLEU score\n",
        "    score1 = 0\n",
        "    score2 = 0\n",
        "    score3 = 0\n",
        "    score4 = 0\n",
        "    \n",
        "    print('Computing BLEU')\n",
        "    for itr in tqdm(range(len(gt))):\n",
        "        candidate = preds[itr]['caption']\n",
        "        reference = [sent['raw'] for sent in gt[itr]['sentences']]\n",
        "        score1 += sentence_bleu(reference, candidate, weights=(1, 0, 0, 0), smoothing_function=smoother.method1)\n",
        "        score2 += sentence_bleu(reference, candidate, weights=(0, 1, 0, 0), smoothing_function=smoother.method1)\n",
        "        score3 += sentence_bleu(reference, candidate, weights=(0, 0, 1, 0), smoothing_function=smoother.method1)\n",
        "        score4 += sentence_bleu(reference, candidate, weights=(0, 0, 0, 1), smoothing_function=smoother.method1)\n",
        "    \n",
        "    bleu1 = 100 * score1/len(gt)\n",
        "    bleu2 = 100 * score2/len(gt)\n",
        "    bleu3 = 100 * score3/len(gt)\n",
        "    bleu4 = 100 * score4/len(gt)\n",
        "    \n",
        "    return bleu1, bleu2, bleu3, bleu4\n",
        "\n",
        "# End of code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCi8oR5xGXBz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d948017-404b-43b5-f049-131e17a2a366"
      },
      "source": [
        "## Use at least 3 different temperatures to generate captions on the test set. Report the BLEU scores.\n",
        "# Your code here\n",
        "## Image transformation\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        #     transforms.RandomCrop(224, pad_if_needed=True),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                             std=(0.229, 0.224, 0.225))])\n",
        "\n",
        "## Evaluate your model using BLEU score. Use Deterministic mode\n",
        "model = LSTM(vocab_size=len(vocab), emb_dim=emb_dim, hidden_dim=hidden_dim, \n",
        "                   num_layers=1, dropout=dropout).to(device)  # build a model\n",
        "model.load_state_dict(torch.load(path_to_homework + '/checkpoints/lstm/lstm-best.pth', map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "bleu1, bleu2, bleu3, bleu4 = evaluation(model, vocab, mode='Deterministic')\n",
        "print(\"BLEU 1:{}, BLEU 2:{}, BLEU 3:{}, BLEU 4:{}\".format(bleu1, bleu2, bleu3, bleu4))\n",
        "\n",
        "# End of code"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Run on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  1%|          | 1/125 [00:00<01:11,  1.74it/s]\u001b[A\n",
            "  2%|▏         | 2/125 [00:00<00:55,  2.22it/s]\u001b[A\n",
            "  3%|▎         | 4/125 [00:00<00:41,  2.94it/s]\u001b[A\n",
            "  4%|▍         | 5/125 [00:01<00:33,  3.60it/s]\u001b[A\n",
            "  5%|▍         | 6/125 [00:01<00:27,  4.36it/s]\u001b[A\n",
            "  6%|▌         | 7/125 [00:01<00:22,  5.21it/s]\u001b[A\n",
            "  7%|▋         | 9/125 [00:01<00:18,  6.20it/s]\u001b[A\n",
            "  8%|▊         | 10/125 [00:01<00:16,  7.00it/s]\u001b[A\n",
            " 10%|▉         | 12/125 [00:01<00:13,  8.08it/s]\u001b[A\n",
            " 11%|█         | 14/125 [00:01<00:12,  9.13it/s]\u001b[A\n",
            " 13%|█▎        | 16/125 [00:02<00:11,  9.74it/s]\u001b[A\n",
            " 15%|█▌        | 19/125 [00:02<00:09, 10.85it/s]\u001b[A\n",
            " 17%|█▋        | 21/125 [00:02<00:09, 10.40it/s]\u001b[A\n",
            " 18%|█▊        | 23/125 [00:02<00:09, 10.35it/s]\u001b[A\n",
            " 20%|██        | 25/125 [00:02<00:10,  9.94it/s]\u001b[A\n",
            " 22%|██▏       | 27/125 [00:03<00:09, 10.87it/s]\u001b[A\n",
            " 23%|██▎       | 29/125 [00:03<00:08, 10.85it/s]\u001b[A\n",
            " 25%|██▍       | 31/125 [00:03<00:08, 11.66it/s]\u001b[A\n",
            " 26%|██▋       | 33/125 [00:03<00:07, 12.82it/s]\u001b[A\n",
            " 28%|██▊       | 35/125 [00:03<00:08, 10.88it/s]\u001b[A\n",
            " 30%|██▉       | 37/125 [00:03<00:08, 10.61it/s]\u001b[A\n",
            " 31%|███       | 39/125 [00:04<00:07, 10.80it/s]\u001b[A\n",
            " 33%|███▎      | 41/125 [00:04<00:07, 11.15it/s]\u001b[A\n",
            " 34%|███▍      | 43/125 [00:04<00:06, 11.95it/s]\u001b[A\n",
            " 36%|███▌      | 45/125 [00:04<00:06, 12.24it/s]\u001b[A\n",
            " 38%|███▊      | 47/125 [00:04<00:06, 12.37it/s]\u001b[A\n",
            " 39%|███▉      | 49/125 [00:04<00:06, 11.54it/s]\u001b[A\n",
            " 41%|████      | 51/125 [00:05<00:05, 12.60it/s]\u001b[A\n",
            " 42%|████▏     | 53/125 [00:05<00:05, 12.24it/s]\u001b[A\n",
            " 44%|████▍     | 55/125 [00:05<00:05, 12.42it/s]\u001b[A\n",
            " 46%|████▌     | 57/125 [00:05<00:06, 10.91it/s]\u001b[A\n",
            " 47%|████▋     | 59/125 [00:05<00:05, 11.83it/s]\u001b[A\n",
            " 49%|████▉     | 61/125 [00:05<00:05, 12.02it/s]\u001b[A\n",
            " 50%|█████     | 63/125 [00:06<00:05, 11.29it/s]\u001b[A\n",
            " 52%|█████▏    | 65/125 [00:06<00:05, 10.97it/s]\u001b[A\n",
            " 54%|█████▎    | 67/125 [00:06<00:05, 11.10it/s]\u001b[A\n",
            " 55%|█████▌    | 69/125 [00:06<00:05, 11.13it/s]\u001b[A\n",
            " 57%|█████▋    | 71/125 [00:06<00:04, 10.98it/s]\u001b[A\n",
            " 58%|█████▊    | 73/125 [00:06<00:04, 11.17it/s]\u001b[A\n",
            " 60%|██████    | 75/125 [00:07<00:04, 11.62it/s]\u001b[A\n",
            " 62%|██████▏   | 77/125 [00:07<00:03, 12.16it/s]\u001b[A\n",
            " 63%|██████▎   | 79/125 [00:07<00:03, 11.65it/s]\u001b[A\n",
            " 65%|██████▍   | 81/125 [00:07<00:03, 12.82it/s]\u001b[A\n",
            " 66%|██████▋   | 83/125 [00:07<00:03, 11.76it/s]\u001b[A\n",
            " 68%|██████▊   | 85/125 [00:07<00:03, 12.73it/s]\u001b[A\n",
            " 70%|██████▉   | 87/125 [00:08<00:03, 11.93it/s]\u001b[A\n",
            " 71%|███████   | 89/125 [00:08<00:02, 12.90it/s]\u001b[A\n",
            " 73%|███████▎  | 91/125 [00:08<00:03, 10.91it/s]\u001b[A\n",
            " 74%|███████▍  | 93/125 [00:08<00:03, 10.36it/s]\u001b[A\n",
            " 76%|███████▌  | 95/125 [00:08<00:02, 11.26it/s]\u001b[A\n",
            " 78%|███████▊  | 97/125 [00:09<00:02, 11.28it/s]\u001b[A\n",
            " 79%|███████▉  | 99/125 [00:09<00:02, 10.43it/s]\u001b[A\n",
            " 81%|████████  | 101/125 [00:09<00:02, 11.70it/s]\u001b[A\n",
            " 82%|████████▏ | 103/125 [00:09<00:01, 11.53it/s]\u001b[A\n",
            " 84%|████████▍ | 105/125 [00:09<00:01, 10.85it/s]\u001b[A\n",
            " 86%|████████▌ | 107/125 [00:09<00:01, 12.51it/s]\u001b[A\n",
            " 87%|████████▋ | 109/125 [00:10<00:01, 11.80it/s]\u001b[A\n",
            " 89%|████████▉ | 111/125 [00:10<00:01, 13.07it/s]\u001b[A\n",
            " 90%|█████████ | 113/125 [00:10<00:01, 11.88it/s]\u001b[A\n",
            " 92%|█████████▏| 115/125 [00:10<00:00, 11.34it/s]\u001b[A\n",
            " 94%|█████████▎| 117/125 [00:10<00:00, 11.60it/s]\u001b[A\n",
            " 95%|█████████▌| 119/125 [00:10<00:00, 13.24it/s]\u001b[A\n",
            " 98%|█████████▊| 122/125 [00:10<00:00, 15.01it/s]\u001b[A\n",
            "100%|██████████| 125/125 [00:11<00:00, 11.16it/s]\n",
            "\n",
            "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▎         | 25/1000 [00:00<00:04, 242.80it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Computing BLEU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  5%|▌         | 50/1000 [00:00<00:03, 244.35it/s]\u001b[A\n",
            "  7%|▋         | 73/1000 [00:00<00:03, 239.06it/s]\u001b[A\n",
            " 10%|▉         | 98/1000 [00:00<00:03, 242.00it/s]\u001b[A\n",
            " 12%|█▏        | 121/1000 [00:00<00:03, 238.08it/s]\u001b[A\n",
            " 15%|█▍        | 146/1000 [00:00<00:03, 241.27it/s]\u001b[A\n",
            " 17%|█▋        | 172/1000 [00:00<00:03, 244.41it/s]\u001b[A\n",
            " 20%|█▉        | 196/1000 [00:00<00:03, 241.82it/s]\u001b[A\n",
            " 22%|██▏       | 222/1000 [00:00<00:03, 245.40it/s]\u001b[A\n",
            " 25%|██▍       | 248/1000 [00:01<00:03, 248.16it/s]\u001b[A\n",
            " 27%|██▋       | 273/1000 [00:01<00:03, 241.46it/s]\u001b[A\n",
            " 30%|██▉       | 299/1000 [00:01<00:02, 244.78it/s]\u001b[A\n",
            " 32%|███▏      | 324/1000 [00:01<00:02, 241.56it/s]\u001b[A\n",
            " 35%|███▍      | 348/1000 [00:01<00:02, 233.89it/s]\u001b[A\n",
            " 37%|███▋      | 372/1000 [00:01<00:02, 233.18it/s]\u001b[A\n",
            " 40%|███▉      | 396/1000 [00:01<00:02, 235.14it/s]\u001b[A\n",
            " 42%|████▏     | 420/1000 [00:01<00:02, 235.96it/s]\u001b[A\n",
            " 45%|████▍     | 446/1000 [00:01<00:02, 241.60it/s]\u001b[A\n",
            " 47%|████▋     | 471/1000 [00:01<00:02, 240.46it/s]\u001b[A\n",
            " 50%|████▉     | 496/1000 [00:02<00:02, 243.17it/s]\u001b[A\n",
            " 52%|█████▏    | 522/1000 [00:02<00:01, 246.11it/s]\u001b[A\n",
            " 55%|█████▍    | 547/1000 [00:02<00:01, 238.64it/s]\u001b[A\n",
            " 57%|█████▋    | 573/1000 [00:02<00:01, 242.85it/s]\u001b[A\n",
            " 60%|█████▉    | 598/1000 [00:02<00:01, 237.59it/s]\u001b[A\n",
            " 62%|██████▏   | 622/1000 [00:02<00:01, 232.73it/s]\u001b[A\n",
            " 65%|██████▍   | 646/1000 [00:02<00:01, 230.55it/s]\u001b[A\n",
            " 67%|██████▋   | 670/1000 [00:02<00:01, 231.50it/s]\u001b[A\n",
            " 69%|██████▉   | 694/1000 [00:02<00:01, 233.41it/s]\u001b[A\n",
            " 72%|███████▏  | 718/1000 [00:03<00:01, 233.86it/s]\u001b[A\n",
            " 74%|███████▍  | 744/1000 [00:03<00:01, 240.42it/s]\u001b[A\n",
            " 77%|███████▋  | 769/1000 [00:03<00:00, 240.32it/s]\u001b[A\n",
            " 79%|███████▉  | 794/1000 [00:03<00:00, 234.41it/s]\u001b[A\n",
            " 82%|████████▏ | 819/1000 [00:03<00:00, 236.75it/s]\u001b[A\n",
            " 84%|████████▍ | 843/1000 [00:03<00:00, 229.55it/s]\u001b[A\n",
            " 87%|████████▋ | 867/1000 [00:03<00:00, 232.51it/s]\u001b[A\n",
            " 89%|████████▉ | 891/1000 [00:03<00:00, 226.37it/s]\u001b[A\n",
            " 92%|█████████▏| 915/1000 [00:03<00:00, 228.28it/s]\u001b[A\n",
            " 94%|█████████▍| 939/1000 [00:03<00:00, 231.15it/s]\u001b[A\n",
            " 96%|█████████▋| 963/1000 [00:04<00:00, 232.54it/s]\u001b[A\n",
            "100%|██████████| 1000/1000 [00:04<00:00, 237.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU 1:90.94035469084693, BLEU 2:65.86864561698819, BLEU 3:41.163834409771844, BLEU 4:27.814403103582656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAeYvD9gGsFs"
      },
      "source": [
        "## Evaluate your model using BLEU score. Use Deterministic mode.\n",
        "# Your code here\n",
        "## evaluation code\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "smoother = SmoothingFunction()\n",
        "\n",
        "def caption_generator(model, images, vocab, img_ids, captions, mode='Deterministic', temperature=0.5):\n",
        "    \"\"\"\n",
        "    Generate captions.\n",
        "    :param mode:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    sample_idxs = model.sample_generate(images, mode=mode,\n",
        "                                        temperature=temperature).data.cpu().numpy()  # [N, max_length]\n",
        "    for i, sentence in enumerate(sample_idxs):  # every sentence in this batch\n",
        "        sentence_caption = ''\n",
        "        for word_idx in sentence:\n",
        "            word = vocab.idx2word[word_idx]\n",
        "            if word != '<start>' and word != '<end>':\n",
        "                if word == '.':\n",
        "                    sentence_caption += '.'\n",
        "                else:\n",
        "                    sentence_caption += word + ' '\n",
        "            if word == '<end>':\n",
        "                break\n",
        "        captions.append({'caption': sentence_caption})\n",
        "        # captions.append(sentence_caption)\n",
        "\n",
        "    return captions\n",
        "\n",
        "def run_test(model, data_loader, vocab, mode='Deterministic', temperature=0.5):\n",
        "    \"\"\"\n",
        "    Run your model on the test set.\n",
        "    Inputs:\n",
        "    :param model: the model you use\n",
        "    :param data_loader: the data_loader\n",
        "    :param mode: use 'deterministic' or 'stochastic'\n",
        "    Outputs:\n",
        "    :param predictions\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    for itr, (images, captions, lengths) in enumerate(tqdm(data_loader)):\n",
        "        images = Variable(images).to(device)\n",
        "        captions = Variable(captions).to(device)\n",
        "        outputs = model(images, captions, lengths)\n",
        "        \n",
        "        img_ids = list(range(itr * data_loader.batch_size, (itr + 1) * data_loader.batch_size))\n",
        "        predictions = caption_generator(model, images, vocab, img_ids, \n",
        "                                        predictions, mode=mode, temperature=temperature)\n",
        "        \n",
        "    return predictions\n",
        "\n",
        "def evaluation(model, vocab, data_path=path_to_homework + '/flickr30k_images/', mode='Deterministic', temperature=0.5,\n",
        "               split='test'):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of your model on the test set using BLEU scores.\n",
        "    Inputs:\n",
        "    :param model: the model you use\n",
        "    :param weight_path: the directory to the weights of your model\n",
        "    :param vocab: vocabulary\n",
        "    :param data_path: the directory to the dataset\n",
        "    :param mode: use 'deterministic' or 'stochastic'\n",
        "    Outputs:\n",
        "    :param predictions\n",
        "    \"\"\"\n",
        "    # data loader\n",
        "    test_data_loader = get_loader(root=path_to_homework + '/flickr30k_images/', split=split, vocab=vocab, \n",
        "                                  transform=transform, batch_size=8, shuffle=False, num_workers=4)\n",
        "    \n",
        "    # run your model on the test set\n",
        "    print('Run on the test set...')\n",
        "    preds = run_test(model, test_data_loader, vocab, mode, temperature)\n",
        "    \n",
        "    # load the groundtruth\n",
        "    gt = test_data_loader.dataset.annos\n",
        "    \n",
        "    # evaluate the performance using BLEU score\n",
        "    score1 = 0\n",
        "    score2 = 0\n",
        "    \n",
        "    return bleu1, bleu2, bleu3, bleu4\n",
        "\n",
        "# End of code   score3 = 0\n",
        "    score4 = 0\n",
        "    \n",
        "    print('Computing BLEU')\n",
        "    for itr in tqdm(range(len(gt))):\n",
        "        candidate = preds[itr]['caption']\n",
        "        reference = [sent['raw'] for sent in gt[itr]['sentences']]\n",
        "        score1 += sentence_bleu(reference, candidate, weights=(1, 0, 0, 0), smoothing_function=smoother.method1)\n",
        "        score2 += sentence_bleu(reference, candidate, weights=(0, 1, 0, 0), smoothing_function=smoother.method1)\n",
        "        score3 += sentence_bleu(reference, candidate, weights=(0, 0, 1, 0), smoothing_function=smoother.method1)\n",
        "        score4 += sentence_bleu(reference, candidate, weights=(0, 0, 0, 1), smoothing_function=smoother.method1)\n",
        "    \n",
        "    bleu1 = 100 * score1/len(gt)\n",
        "    bleu2 = 100 * score2/len(gt)\n",
        "    bleu3 = 100 * score3/len(gt)\n",
        "    bleu4 = 100 * score4/len(gt)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWpodlh3G5Hd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "059647f5-9b1a-42be-e025-c8c03b315ec7"
      },
      "source": [
        "## Use at least 3 different temperatures to generate captions on the test set. Report the BLEU scores.\n",
        "# Your code here\n",
        "## Image transformation\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        #     transforms.RandomCrop(224, pad_if_needed=True),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                             std=(0.229, 0.224, 0.225))])\n",
        "\n",
        "## Evaluate your model using BLEU score. Use Deterministic mode\n",
        "model = LSTM(vocab_size=len(vocab), emb_dim=emb_dim, hidden_dim=hidden_dim, \n",
        "                   num_layers=1, dropout=dropout).to(device)  # build a model\n",
        "model.load_state_dict(torch.load(path_to_homework + '/checkpoints/lstm/lstm-best.pth', map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "bleu1, bleu2, bleu3, bleu4 = evaluation(model, vocab, mode='Deterministic')\n",
        "print(\"BLEU 1:{}, BLEU 2:{}, BLEU 3:{}, BLEU 4:{}\".format(bleu1, bleu2, bleu3, bleu4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Run on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  1%|          | 1/125 [00:00<01:12,  1.72it/s]\u001b[A\n",
            "  2%|▏         | 2/125 [00:00<00:54,  2.24it/s]\u001b[A\n",
            "  3%|▎         | 4/125 [00:00<00:41,  2.91it/s]\u001b[A\n",
            "  4%|▍         | 5/125 [00:01<00:33,  3.56it/s]\u001b[A\n",
            "  5%|▍         | 6/125 [00:01<00:27,  4.39it/s]\u001b[A\n",
            "  6%|▌         | 7/125 [00:01<00:22,  5.26it/s]\u001b[A\n",
            "  6%|▋         | 8/125 [00:01<00:19,  5.97it/s]\u001b[A\n",
            "  8%|▊         | 10/125 [00:01<00:15,  7.44it/s]\u001b[A\n",
            " 10%|▉         | 12/125 [00:01<00:14,  7.75it/s]\u001b[A\n",
            " 11%|█         | 14/125 [00:01<00:12,  8.77it/s]\u001b[A\n",
            " 13%|█▎        | 16/125 [00:02<00:10, 10.03it/s]\u001b[A\n",
            " 14%|█▍        | 18/125 [00:02<00:09, 10.77it/s]\u001b[A\n",
            " 16%|█▌        | 20/125 [00:02<00:10, 10.25it/s]\u001b[A\n",
            " 18%|█▊        | 22/125 [00:02<00:09, 11.00it/s]\u001b[A\n",
            " 19%|█▉        | 24/125 [00:02<00:09, 10.55it/s]\u001b[A\n",
            " 21%|██        | 26/125 [00:02<00:08, 11.33it/s]\u001b[A\n",
            " 22%|██▏       | 28/125 [00:03<00:08, 11.22it/s]\u001b[A\n",
            " 24%|██▍       | 30/125 [00:03<00:08, 11.65it/s]\u001b[A\n",
            " 26%|██▌       | 32/125 [00:03<00:07, 12.29it/s]\u001b[A\n",
            " 27%|██▋       | 34/125 [00:03<00:08, 10.92it/s]\u001b[A\n",
            " 29%|██▉       | 36/125 [00:03<00:08, 11.11it/s]\u001b[A\n",
            " 30%|███       | 38/125 [00:03<00:07, 12.11it/s]\u001b[A\n",
            " 32%|███▏      | 40/125 [00:04<00:07, 11.40it/s]\u001b[A\n",
            " 34%|███▎      | 42/125 [00:04<00:07, 11.58it/s]\u001b[A\n",
            " 35%|███▌      | 44/125 [00:04<00:06, 12.01it/s]\u001b[A\n",
            " 37%|███▋      | 46/125 [00:04<00:06, 11.75it/s]\u001b[A\n",
            " 38%|███▊      | 48/125 [00:04<00:06, 11.68it/s]\u001b[A\n",
            " 40%|████      | 50/125 [00:04<00:05, 12.51it/s]\u001b[A\n",
            " 42%|████▏     | 52/125 [00:05<00:05, 12.28it/s]\u001b[A\n",
            " 43%|████▎     | 54/125 [00:05<00:05, 12.88it/s]\u001b[A\n",
            " 45%|████▍     | 56/125 [00:05<00:05, 11.88it/s]\u001b[A\n",
            " 46%|████▋     | 58/125 [00:05<00:05, 12.65it/s]\u001b[A\n",
            " 48%|████▊     | 60/125 [00:05<00:05, 11.30it/s]\u001b[A\n",
            " 50%|████▉     | 62/125 [00:05<00:05, 12.12it/s]\u001b[A\n",
            " 51%|█████     | 64/125 [00:06<00:05, 11.55it/s]\u001b[A\n",
            " 53%|█████▎    | 66/125 [00:06<00:04, 11.88it/s]\u001b[A\n",
            " 54%|█████▍    | 68/125 [00:06<00:04, 12.21it/s]\u001b[A\n",
            " 56%|█████▌    | 70/125 [00:06<00:04, 11.88it/s]\u001b[A\n",
            " 58%|█████▊    | 72/125 [00:06<00:04, 12.83it/s]\u001b[A\n",
            " 59%|█████▉    | 74/125 [00:06<00:04, 11.27it/s]\u001b[A\n",
            " 61%|██████    | 76/125 [00:07<00:04, 11.84it/s]\u001b[A\n",
            " 62%|██████▏   | 78/125 [00:07<00:04, 11.54it/s]\u001b[A\n",
            " 64%|██████▍   | 80/125 [00:07<00:03, 11.82it/s]\u001b[A\n",
            " 66%|██████▌   | 82/125 [00:07<00:04, 10.56it/s]\u001b[A\n",
            " 67%|██████▋   | 84/125 [00:07<00:03, 10.82it/s]\u001b[A\n",
            " 69%|██████▉   | 86/125 [00:07<00:03, 11.70it/s]\u001b[A\n",
            " 70%|███████   | 88/125 [00:08<00:03, 11.10it/s]\u001b[A\n",
            " 72%|███████▏  | 90/125 [00:08<00:02, 12.60it/s]\u001b[A\n",
            " 74%|███████▎  | 92/125 [00:08<00:02, 12.21it/s]\u001b[A\n",
            " 75%|███████▌  | 94/125 [00:08<00:02, 11.00it/s]\u001b[A\n",
            " 77%|███████▋  | 96/125 [00:08<00:02, 11.28it/s]\u001b[A\n",
            " 78%|███████▊  | 98/125 [00:09<00:02, 11.02it/s]\u001b[A\n",
            " 80%|████████  | 100/125 [00:09<00:02, 11.36it/s]\u001b[A\n",
            " 82%|████████▏ | 102/125 [00:09<00:01, 11.65it/s]\u001b[A\n",
            " 83%|████████▎ | 104/125 [00:09<00:01, 11.33it/s]\u001b[A\n",
            " 85%|████████▍ | 106/125 [00:09<00:01, 12.23it/s]\u001b[A\n",
            " 86%|████████▋ | 108/125 [00:09<00:01, 11.28it/s]\u001b[A\n",
            " 88%|████████▊ | 110/125 [00:10<00:01, 11.48it/s]\u001b[A\n",
            " 90%|████████▉ | 112/125 [00:10<00:01, 12.18it/s]\u001b[A\n",
            " 91%|█████████ | 114/125 [00:10<00:00, 12.12it/s]\u001b[A\n",
            " 93%|█████████▎| 116/125 [00:10<00:00, 11.59it/s]\u001b[A\n",
            " 94%|█████████▍| 118/125 [00:10<00:00, 12.11it/s]\u001b[A\n",
            " 97%|█████████▋| 121/125 [00:10<00:00, 14.11it/s]\u001b[A\n",
            "100%|██████████| 125/125 [00:11<00:00, 11.23it/s]\n",
            "\n",
            "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 24/1000 [00:00<00:04, 238.35it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Computing BLEU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  5%|▍         | 46/1000 [00:00<00:04, 232.24it/s]\u001b[A\n",
            "  7%|▋         | 66/1000 [00:00<00:04, 219.42it/s]\u001b[A\n",
            "  9%|▉         | 89/1000 [00:00<00:04, 221.01it/s]\u001b[A\n",
            " 11%|█▏        | 113/1000 [00:00<00:03, 226.22it/s]\u001b[A\n",
            " 14%|█▎        | 137/1000 [00:00<00:03, 229.98it/s]\u001b[A\n",
            " 16%|█▌        | 160/1000 [00:00<00:03, 229.76it/s]\u001b[A\n",
            " 18%|█▊        | 185/1000 [00:00<00:03, 234.18it/s]\u001b[A\n",
            " 21%|██        | 209/1000 [00:00<00:03, 235.46it/s]\u001b[A\n",
            " 23%|██▎       | 233/1000 [00:01<00:03, 235.35it/s]\u001b[A\n",
            " 26%|██▌       | 259/1000 [00:01<00:03, 239.92it/s]\u001b[A\n",
            " 28%|██▊       | 283/1000 [00:01<00:03, 237.81it/s]\u001b[A\n",
            " 31%|███       | 309/1000 [00:01<00:02, 242.29it/s]\u001b[A\n",
            " 33%|███▎      | 334/1000 [00:01<00:02, 237.81it/s]\u001b[A\n",
            " 36%|███▌      | 358/1000 [00:01<00:02, 236.80it/s]\u001b[A\n",
            " 38%|███▊      | 383/1000 [00:01<00:02, 238.86it/s]\u001b[A\n",
            " 41%|████      | 408/1000 [00:01<00:02, 240.88it/s]\u001b[A\n",
            " 43%|████▎     | 433/1000 [00:01<00:02, 240.88it/s]\u001b[A\n",
            " 46%|████▌     | 458/1000 [00:01<00:02, 241.10it/s]\u001b[A\n",
            " 48%|████▊     | 483/1000 [00:02<00:02, 237.16it/s]\u001b[A\n",
            " 51%|█████     | 507/1000 [00:02<00:02, 235.37it/s]\u001b[A\n",
            " 53%|█████▎    | 533/1000 [00:02<00:01, 240.25it/s]\u001b[A\n",
            " 56%|█████▌    | 558/1000 [00:02<00:01, 241.29it/s]\u001b[A\n",
            " 58%|█████▊    | 583/1000 [00:02<00:01, 237.19it/s]\u001b[A\n",
            " 61%|██████    | 607/1000 [00:02<00:01, 237.79it/s]\u001b[A\n",
            " 63%|██████▎   | 631/1000 [00:02<00:01, 236.03it/s]\u001b[A\n",
            " 66%|██████▌   | 655/1000 [00:02<00:01, 234.47it/s]\u001b[A\n",
            " 68%|██████▊   | 679/1000 [00:02<00:01, 232.37it/s]\u001b[A\n",
            " 70%|███████   | 703/1000 [00:02<00:01, 226.55it/s]\u001b[A\n",
            " 73%|███████▎  | 728/1000 [00:03<00:01, 232.16it/s]\u001b[A\n",
            " 75%|███████▌  | 752/1000 [00:03<00:01, 231.81it/s]\u001b[A\n",
            " 78%|███████▊  | 776/1000 [00:03<00:00, 233.46it/s]\u001b[A\n",
            " 80%|████████  | 800/1000 [00:03<00:00, 232.26it/s]\u001b[A\n",
            " 82%|████████▏ | 824/1000 [00:03<00:00, 220.47it/s]\u001b[A\n",
            " 85%|████████▍ | 847/1000 [00:03<00:00, 216.53it/s]\u001b[A\n",
            " 87%|████████▋ | 870/1000 [00:03<00:00, 219.85it/s]\u001b[A\n",
            " 89%|████████▉ | 893/1000 [00:03<00:00, 220.12it/s]\u001b[A\n",
            " 92%|█████████▏| 916/1000 [00:03<00:00, 220.31it/s]\u001b[A\n",
            " 94%|█████████▍| 940/1000 [00:04<00:00, 223.62it/s]\u001b[A\n",
            " 96%|█████████▋| 964/1000 [00:04<00:00, 227.34it/s]\u001b[A\n",
            "100%|██████████| 1000/1000 [00:04<00:00, 231.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU 1:90.94035469084693, BLEU 2:65.86864561698819, BLEU 3:41.163834409771844, BLEU 4:27.814403103582656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU6TJfkrHMMK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN-lgvwkHNP_"
      },
      "source": [
        "## Evaluate your model using BLEU score. Use Deterministic mode.\n",
        "# Your code here\n",
        "## evaluation code\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "smoother = SmoothingFunction()\n",
        "\n",
        "def caption_generator(model, images, vocab, img_ids, captions, mode='Deterministic', temperature=0.1):\n",
        "    \"\"\"\n",
        "    Generate captions.\n",
        "    :param mode:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    sample_idxs = model.sample_generate(images, mode=mode,\n",
        "                                        temperature=temperature).data.cpu().numpy()  # [N, max_length]\n",
        "    for i, sentence in enumerate(sample_idxs):  # every sentence in this batch\n",
        "        sentence_caption = ''\n",
        "        for word_idx in sentence:\n",
        "            word = vocab.idx2word[word_idx]\n",
        "            if word != '<start>' and word != '<end>':\n",
        "                if word == '.':\n",
        "                    sentence_caption += '.'\n",
        "                else:\n",
        "                    sentence_caption += word + ' '\n",
        "            if word == '<end>':\n",
        "                break\n",
        "        captions.append({'caption': sentence_caption})\n",
        "        # captions.append(sentence_caption)\n",
        "\n",
        "    return captions\n",
        "\n",
        "def run_test(model, data_loader, vocab, mode='Deterministic', temperature=0.1):\n",
        "    \"\"\"\n",
        "    Run your model on the test set.\n",
        "    Inputs:\n",
        "    :param model: the model you use\n",
        "    :param data_loader: the data_loader\n",
        "    :param mode: use 'deterministic' or 'stochastic'\n",
        "    Outputs:\n",
        "    :param predictions\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    for itr, (images, captions, lengths) in enumerate(tqdm(data_loader)):\n",
        "        images = Variable(images).to(device)\n",
        "        captions = Variable(captions).to(device)\n",
        "        outputs = model(images, captions, lengths)\n",
        "        \n",
        "        img_ids = list(range(itr * data_loader.batch_size, (itr + 1) * data_loader.batch_size))\n",
        "        predictions = caption_generator(model, images, vocab, img_ids, \n",
        "                                        predictions, mode=mode, temperature=temperature)\n",
        "        \n",
        "    return predictions\n",
        "\n",
        "def evaluation(model, vocab, data_path=path_to_homework + '/flickr30k_images/', mode='Deterministic', temperature=0.1,\n",
        "               split='test'):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of your model on the test set using BLEU scores.\n",
        "    Inputs:\n",
        "    :param model: the model you use\n",
        "    :param weight_path: the directory to the weights of your model\n",
        "    :param vocab: vocabulary\n",
        "    :param data_path: the directory to the dataset\n",
        "    :param mode: use 'deterministic' or 'stochastic'\n",
        "    Outputs:\n",
        "    :param predictions\n",
        "    \"\"\"\n",
        "    # data loader\n",
        "    test_data_loader = get_loader(root=path_to_homework + '/flickr30k_images/', split=split, vocab=vocab, \n",
        "                                  transform=transform, batch_size=8, shuffle=False, num_workers=4)\n",
        "    \n",
        "    # run your model on the test set\n",
        "    print('Run on the test set...')\n",
        "    preds = run_test(model, test_data_loader, vocab, mode, temperature)\n",
        "    \n",
        "    # load the groundtruth\n",
        "    gt = test_data_loader.dataset.annos\n",
        "    \n",
        "    # evaluate the performance using BLEU score\n",
        "    score1 = 0\n",
        "    score2 = 0\n",
        "    \n",
        "    return bleu1, bleu2, bleu3, bleu4\n",
        "\n",
        "# End of code   score3 = 0\n",
        "    score4 = 0\n",
        "    \n",
        "    print('Computing BLEU')\n",
        "    for itr in tqdm(range(len(gt))):\n",
        "        candidate = preds[itr]['caption']\n",
        "        reference = [sent['raw'] for sent in gt[itr]['sentences']]\n",
        "        score1 += sentence_bleu(reference, candidate, weights=(1, 0, 0, 0), smoothing_function=smoother.method1)\n",
        "        score2 += sentence_bleu(reference, candidate, weights=(0, 1, 0, 0), smoothing_function=smoother.method1)\n",
        "        score3 += sentence_bleu(reference, candidate, weights=(0, 0, 1, 0), smoothing_function=smoother.method1)\n",
        "        score4 += sentence_bleu(reference, candidate, weights=(0, 0, 0, 1), smoothing_function=smoother.method1)\n",
        "    \n",
        "    bleu1 = 100 * score1/len(gt)\n",
        "    bleu2 = 100 * score2/len(gt)\n",
        "    bleu3 = 100 * score3/len(gt)\n",
        "    bleu4 = 100 * score4/len(gt)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxI0SIVJHWlE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "faf60b16-7d7e-4220-96d2-f6a247bc429d"
      },
      "source": [
        "## Use at least 3 different temperatures to generate captions on the test set. Report the BLEU scores.\n",
        "# Your code here\n",
        "## Image transformation\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        #     transforms.RandomCrop(224, pad_if_needed=True),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                             std=(0.229, 0.224, 0.225))])\n",
        "\n",
        "## Evaluate your model using BLEU score. Use Deterministic mode\n",
        "model = LSTM(vocab_size=len(vocab), emb_dim=emb_dim, hidden_dim=hidden_dim, \n",
        "                   num_layers=1, dropout=dropout).to(device)  # build a model\n",
        "model.load_state_dict(torch.load(path_to_homework + '/checkpoints/lstm/lstm-best.pth', map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "bleu1, bleu2, bleu3, bleu4 = evaluation(model, vocab, mode='Deterministic')\n",
        "print(\"BLEU 1:{}, BLEU 2:{}, BLEU 3:{}, BLEU 4:{}\".format(bleu1, bleu2, bleu3, bleu4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Run on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  1%|          | 1/125 [00:00<01:17,  1.60it/s]\u001b[A\n",
            "  2%|▏         | 2/125 [00:00<00:59,  2.05it/s]\u001b[A\n",
            "  2%|▏         | 3/125 [00:00<00:45,  2.69it/s]\u001b[A\n",
            "  3%|▎         | 4/125 [00:01<00:36,  3.29it/s]\u001b[A\n",
            "  4%|▍         | 5/125 [00:01<00:30,  3.91it/s]\u001b[A\n",
            "  6%|▌         | 7/125 [00:01<00:24,  4.89it/s]\u001b[A\n",
            "  7%|▋         | 9/125 [00:01<00:18,  6.13it/s]\u001b[A\n",
            "  9%|▉         | 11/125 [00:01<00:16,  7.01it/s]\u001b[A\n",
            " 10%|█         | 13/125 [00:01<00:13,  8.10it/s]\u001b[A\n",
            " 12%|█▏        | 15/125 [00:02<00:12,  8.48it/s]\u001b[A\n",
            " 14%|█▎        | 17/125 [00:02<00:11,  9.30it/s]\u001b[A\n",
            " 15%|█▌        | 19/125 [00:02<00:10,  9.82it/s]\u001b[A\n",
            " 17%|█▋        | 21/125 [00:02<00:10,  9.79it/s]\u001b[A\n",
            " 18%|█▊        | 23/125 [00:02<00:10,  9.77it/s]\u001b[A\n",
            " 20%|██        | 25/125 [00:02<00:09, 10.55it/s]\u001b[A\n",
            " 22%|██▏       | 27/125 [00:03<00:08, 11.72it/s]\u001b[A\n",
            " 23%|██▎       | 29/125 [00:03<00:08, 10.94it/s]\u001b[A\n",
            " 25%|██▍       | 31/125 [00:03<00:08, 11.22it/s]\u001b[A\n",
            " 26%|██▋       | 33/125 [00:03<00:09, 10.03it/s]\u001b[A\n",
            " 28%|██▊       | 35/125 [00:03<00:08, 11.14it/s]\u001b[A\n",
            " 30%|██▉       | 37/125 [00:04<00:07, 11.28it/s]\u001b[A\n",
            " 31%|███       | 39/125 [00:04<00:07, 11.11it/s]\u001b[A\n",
            " 33%|███▎      | 41/125 [00:04<00:07, 11.17it/s]\u001b[A\n",
            " 34%|███▍      | 43/125 [00:04<00:07, 10.89it/s]\u001b[A\n",
            " 36%|███▌      | 45/125 [00:04<00:06, 11.52it/s]\u001b[A\n",
            " 38%|███▊      | 47/125 [00:04<00:06, 11.29it/s]\u001b[A\n",
            " 39%|███▉      | 49/125 [00:05<00:07, 10.81it/s]\u001b[A\n",
            " 41%|████      | 51/125 [00:05<00:07, 10.55it/s]\u001b[A\n",
            " 42%|████▏     | 53/125 [00:05<00:06, 11.33it/s]\u001b[A\n",
            " 44%|████▍     | 55/125 [00:05<00:06, 11.24it/s]\u001b[A\n",
            " 46%|████▌     | 57/125 [00:05<00:06, 11.16it/s]\u001b[A\n",
            " 47%|████▋     | 59/125 [00:06<00:06, 10.19it/s]\u001b[A\n",
            " 49%|████▉     | 61/125 [00:06<00:05, 11.18it/s]\u001b[A\n",
            " 50%|█████     | 63/125 [00:06<00:05, 11.33it/s]\u001b[A\n",
            " 52%|█████▏    | 65/125 [00:06<00:05, 10.61it/s]\u001b[A\n",
            " 54%|█████▎    | 67/125 [00:06<00:04, 12.20it/s]\u001b[A\n",
            " 55%|█████▌    | 69/125 [00:06<00:04, 11.34it/s]\u001b[A\n",
            " 57%|█████▋    | 71/125 [00:07<00:05, 10.32it/s]\u001b[A\n",
            " 58%|█████▊    | 73/125 [00:07<00:04, 11.58it/s]\u001b[A\n",
            " 60%|██████    | 75/125 [00:07<00:04, 11.93it/s]\u001b[A\n",
            " 62%|██████▏   | 77/125 [00:07<00:04, 10.34it/s]\u001b[A\n",
            " 63%|██████▎   | 79/125 [00:07<00:04, 10.92it/s]\u001b[A\n",
            " 65%|██████▍   | 81/125 [00:07<00:03, 11.42it/s]\u001b[A\n",
            " 66%|██████▋   | 83/125 [00:08<00:03, 12.27it/s]\u001b[A\n",
            " 68%|██████▊   | 85/125 [00:08<00:03, 11.02it/s]\u001b[A\n",
            " 70%|██████▉   | 87/125 [00:08<00:03, 10.88it/s]\u001b[A\n",
            " 71%|███████   | 89/125 [00:08<00:03, 11.51it/s]\u001b[A\n",
            " 73%|███████▎  | 91/125 [00:08<00:03, 10.99it/s]\u001b[A\n",
            " 74%|███████▍  | 93/125 [00:09<00:02, 11.54it/s]\u001b[A\n",
            " 76%|███████▌  | 95/125 [00:09<00:02, 11.62it/s]\u001b[A\n",
            " 78%|███████▊  | 97/125 [00:09<00:02, 10.65it/s]\u001b[A\n",
            " 79%|███████▉  | 99/125 [00:09<00:02, 10.45it/s]\u001b[A\n",
            " 81%|████████  | 101/125 [00:09<00:02, 10.55it/s]\u001b[A\n",
            " 82%|████████▏ | 103/125 [00:09<00:01, 11.42it/s]\u001b[A\n",
            " 84%|████████▍ | 105/125 [00:10<00:01, 10.20it/s]\u001b[A\n",
            " 86%|████████▌ | 107/125 [00:10<00:01, 11.09it/s]\u001b[A\n",
            " 87%|████████▋ | 109/125 [00:10<00:01, 10.67it/s]\u001b[A\n",
            " 89%|████████▉ | 111/125 [00:10<00:01, 11.36it/s]\u001b[A\n",
            " 90%|█████████ | 113/125 [00:10<00:01, 11.46it/s]\u001b[A\n",
            " 92%|█████████▏| 115/125 [00:11<00:00, 11.28it/s]\u001b[A\n",
            " 94%|█████████▎| 117/125 [00:11<00:00, 11.62it/s]\u001b[A\n",
            " 95%|█████████▌| 119/125 [00:11<00:00, 12.93it/s]\u001b[A\n",
            " 98%|█████████▊| 122/125 [00:11<00:00, 14.69it/s]\u001b[A\n",
            "100%|██████████| 125/125 [00:11<00:00, 10.69it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-11e9810874ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_homework\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/checkpoints/lstm/lstm-best.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mbleu1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Deterministic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BLEU 1:{}, BLEU 2:{}, BLEU 3:{}, BLEU 4:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbleu1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-86-535e44600122>\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(model, vocab, data_path, mode, temperature, split)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mscore2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbleu1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m# End of code   score3 = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'bleu1' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPWDUUjR65NS"
      },
      "source": [
        "#It semms that as temperature goes up the Belu score dropes. for small values for temperature it is almost the same"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLSzznn18His"
      },
      "source": [
        "## Section 3.1.4 Discussion [5 pts]\n",
        "What's the difference between Vanilla RNN and LSTM (training loss, evaluation results, etc)? for the temperature 1 i get the same Belue4 score for both models\n",
        "and the loss for LSTM is 2.7 whic is a little bit better than rnn which is 2.99"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfTC7i--8His"
      },
      "source": [
        "**Your comments**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXkn2J7l8Hit"
      },
      "source": [
        "## Section 3.2 Using pre-trained word embeddings [20 pts]\n",
        "For now, the decoder uses a word as input by converting it into a fixed size embedding, and our networks learn these word embeddings by training. In this experiment, you will use pre-trained word embeddings like Word2Vec or GloVe in LSTM. If you use Pytorch’s nn.Embedding layer, you can initialize its weights with a matrix containing pre-trained word embeddings for all words in your vocabulary, and freeze the weights (i.e. don’t train this layer). You can find these embeddings online.\n",
        "\n",
        "Some resources:\n",
        "- GloVe: https://nlp.stanford.edu/projects/glove/\n",
        "- Word2Vec: http://jalammar.github.io/illustrated-word2vec/\n",
        "\n",
        "In case you don't know how to get one, we've already provided a light GloVe embedding: wm_06.npy, which can produce 300-d word embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGFH0w3k8Hiu"
      },
      "source": [
        "## Section 3.2.1 Encoder-decoder [10 pts]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ8WZ1aB8Hiu"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, pretrained_emb, num_layers=1, dropout=0):\n",
        "        \"\"\"\n",
        "        Use LSTM as decoder for captions.\n",
        "        :param emb_dim: Embedding dimensions.\n",
        "        :param hidden_dim: Hidden states dimensions.\n",
        "        :param pretrained_emb: the path to the pretrained embedding\n",
        "        :param num_layers: Number of LSTM layers.\n",
        "        :param vocab_size: The size of Vocabulary.\n",
        "        :param dropout: dropout probability\n",
        "        \"\"\"\n",
        "        super(Decoder, self).__init__()\n",
        "        self.max_length = 30  # in case it's trapped\n",
        "        ###### Your Code#########\n",
        "        # load pre-trained embedding weights and freeze this layer\n",
        "        pretrained_emb = '/content/drive/My Drive/Assignment_4/wm_06.npy'\n",
        "        b=np.load(pretrained_emb) \n",
        "        weights = torch.FloatTensor(b)\n",
        "        self.embedding = nn.Embedding.from_pretrained(weights, freeze=True) \n",
        "        \n",
        "      # lstm network\n",
        "        self.lstm = nn.LSTM(input_size = emb_dim,hidden_size = hidden_dim,\n",
        "                            num_layers = num_layers, batch_first = True)\n",
        "        \n",
        "        # output layer\n",
        "        self.linear = nn.Linear(hidden_dim, vocab_size)\n",
        "    \n",
        "    def forward(self, encode_features, captions, lengths):\n",
        "        \"\"\"\n",
        "        Feed forward to generate captions.\n",
        "        :param encode_features: output of encoder, size [N, emb_dim]\n",
        "        :param captions: captions, size [N, max(lengths)]\n",
        "        :param lengths: a list indicating valid length for each caption. length is (batch_size).\n",
        "        \"\"\"\n",
        "        #############Your Code###################\n",
        "        # compute the embedding using one-hot technique and linear function\n",
        "        embed = self.embedding(captions)\n",
        "        \n",
        "        # concatenate the encoded features from encoder and embeddings\n",
        "        embed = torch.cat((encode_features.unsqueeze(1), embed), dim = 1)\n",
        "        packed_input = pack_padded_sequence(embed, lengths, batch_first=True)       \n",
        "                \n",
        "        # feed into RNN\n",
        "        hiddens, _ = self.lstm(packed_input )\n",
        "        \n",
        "        # output layer\n",
        "        outputs = self.linear(hiddens[0])\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5HCCh-Z8Hiz"
      },
      "source": [
        "class Word_embeddings(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, pretrained_emb, num_layers=1, dropout=0):\n",
        "        \"\"\"\n",
        "        Encoder-decoder baseline.\n",
        "        :param vocab_size: the size of Vocabulary.\n",
        "        :param emb_dim: the dimensions of word embedding.\n",
        "        :param hidden_dim: the dimensions of hidden units.\n",
        "        :param pretrained_emb: the path to the pretrained embedding\n",
        "        :param num_layers: the number of LSTM layers.\n",
        "        :param dropout: dropout probability.\n",
        "        \"\"\"\n",
        "        super(Word_embeddings, self).__init__()\n",
        "        self.max_length = 30\n",
        "        #########Your Code################\n",
        "        # Encoder: ResNet-50\n",
        "        self.Encoder= Encoder(emb_dim)\n",
        "        # Decoder: LSTM\n",
        "        self.Decoder = Decoder(vocab_size, emb_dim, hidden_dim, pretrained_emb, num_layers=1, dropout=0)\n",
        "        #self.max_length = self.Decoder.max_length\n",
        " \n",
        "\n",
        "    def forward(self, x, captions, lengths):\n",
        "        \"\"\"\n",
        "        Feed forward.\n",
        "        :param x: Images, [N, 3, H, W]\n",
        "        :param captions: encoded captions, [N, max(lengths)]\n",
        "        :param lengths: a list indicating valid length for each caption. length is (batch_size).\n",
        "        :return: output logits, usually followed by a softmax layer.\n",
        "        \"\"\"\n",
        "        ##########Your code###################\n",
        "        # forward passing\n",
        "        Encoder= self.Encoder(x)\n",
        "        x = self.Decoder(Encoder,captions, lengths)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def sample_generate(self, x, states=None, mode='Deterministic', temperature=5.0):\n",
        "        \"\"\"\n",
        "        Generate samples.\n",
        "        :param x:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        sample_idxs = []\n",
        "        #################Your Code##################\n",
        "        sample_idxs = []  # record the index of your generated words\n",
        "        # compute the encoded features\n",
        "        features = self.Encoder(x)\n",
        "        inputs = features.unsqueeze(1)\n",
        "        if mode == 'Deterministic':\n",
        "          for i in range(self.max_length):\n",
        "              hiddens, states = self.Decoder.lstm(inputs, states)  \n",
        "              outputs = self.Decoder.linear(hiddens.squeeze(1)) \n",
        "           # take the maximum index after the softmax\n",
        "              _, predicted = outputs.max(1)                        # predicted: (batch_size)\n",
        "              sample_idxs.append(predicted)\n",
        "              inputs= self.Decoder.embedding_layer(predicted)\n",
        "              inputs = inputs.unsqueeze(1)\n",
        "          sample_idxs=torch.stack(sample_idxs, dim=1)\n",
        "            \n",
        "        elif mode == 'Stochastic':\n",
        "            for i in range(self.max_length):\n",
        "              hiddens, states = self.Decoder.lstm(inputs, states)  \n",
        "              outputs = self.Decoder.linear(hiddens.squeeze(1)) \n",
        "            # sample from the probability distribution after the softmax\n",
        "            # Hint: use torch.multinomial() to sample from a distribution.\n",
        "              probabilities = F.softmax(outputs.div(temperature), dim=1)\n",
        "              predicted = torch.multinomial(probabilities.data, 1) \n",
        "\n",
        "              sample_idxs.append(predicted[:, 0])\n",
        "              inputs = self.Decoder.embedding_layer(predicted[:,0])                       # inputs: (batch_size, embed_size)\n",
        "              inputs = inputs.unsqueeze(1)                         # inputs: (batch_size, 1, embed_size)\n",
        "            sample_idxs = torch.stack(sample_idxs, dim=1)                # sampled_ids: (batch_size, max_seq_length)\n",
        "            \n",
        "            \n",
        "        return sample_idxs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XlYzZEi8Hi1"
      },
      "source": [
        "## Section 3.2.2 Training [5 pts]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwIqC2Ua8Hi2"
      },
      "source": [
        "# some hyperparameters, you can change them\n",
        "## training parameters\n",
        "batch_size = 256\n",
        "lr = 1e-2\n",
        "num_epochs = 50\n",
        "weight_decay = 0.0\n",
        "log_step = 50\n",
        "\n",
        "## network architecture\n",
        "emb_dim = 300\n",
        "hidden_dim = 256\n",
        "num_layers = 1 # number of RNN layers\n",
        "dropout = 0.0\n",
        "\n",
        "## image transformation\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        #     transforms.RandomCrop(224, pad_if_needed=True),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                             std=(0.229, 0.224, 0.225))])\n",
        "\n",
        "## Output directory\n",
        "output_dir = path_to_homework + '/checkpoints/pretrained_emb/'\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_n7h6jy8Hi4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73105cd6-c53f-40b6-9a0f-cebd8ab31eab"
      },
      "source": [
        "# Training code here\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "train_data_loader = get_loader(root=path_to_homework + '/flickr30k_images/', split='train', vocab=vocab,\n",
        "                               transform=transform, batch_size=batch_size, shuffle=True, num_workers=12)\n",
        "val_data_loader = get_loader(root=path_to_homework + '/flickr30k_images/', split='val', vocab=vocab,\n",
        "                             transform=transform, batch_size=8, shuffle=True, num_workers=4)\n",
        "\n",
        "# pretrained embedding weights\n",
        "pre_emb_path = '/content/drive/My Drive/Assignment_4/wm_06.npy'  # type the path to the pretrained embedding you find\n",
        "\n",
        "model = Word_embeddings(vocab_size=len(vocab), emb_dim=emb_dim, hidden_dim=hidden_dim, pretrained_emb=pre_emb_path,\n",
        "                   num_layers=1, dropout=dropout).to(device)  # build a model\n",
        "\n",
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss().to(device)  # CE loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)  # optimizer\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n",
        "                                      step_size=5,\n",
        "                                      gamma=0.5)  # decay LR by a factor of 0.5 every 10 epochs. You can change this\n",
        "\n",
        "# logs\n",
        "Train_Losses = []  # record average training loss each epoch\n",
        "Val_Losses = []   # record average validation loss each epoch\n",
        "total_step = len(train_data_loader)  # number of iterations each epoch\n",
        "best_val_loss = np.inf\n",
        "\n",
        "# start training\n",
        "print('Start training...')\n",
        "import time\n",
        "tic = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    print('Switch to training...')\n",
        "    model.train()\n",
        "    Train_loss_iter = []  # record the the training loss each iteration\n",
        "    for itr, (images, captions, lengths) in enumerate(train_data_loader):\n",
        "        ########Your Code###########\n",
        "        # train your model\n",
        "        images = Variable(images).to(device)\n",
        "        captions = Variable(captions).to(device)\n",
        "        targets = Variable(pack_padded_sequence(captions, lengths, batch_first=True)[0]).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images, captions, lengths)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()  \n",
        "        optimizer.step()\n",
        "\n",
        "        # record the training loss\n",
        "        #Train_loss_iter = Train_loss_iter+loss.data.detach().cpu().numpy()\n",
        "        #Train_loss_iter = Train_loss_iter+loss.data.detach().numpy()\n",
        "        Train_loss_iter.append(loss.data.detach().cpu().numpy())\n",
        "        \n",
        "        \n",
        "        # print log info\n",
        "        if itr % log_step == 0:\n",
        "            # print current loss and perplexity\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Perplexity: {:5.4f}'\n",
        "                      .format(epoch, num_epochs, itr, total_step, loss.item(), np.exp(loss.item())))\n",
        "    scheduler.step()\n",
        "    Train_Losses.append(np.mean(Train_loss_iter))\n",
        "    np.save(os.path.join(output_dir, 'TrainingLoss_lstm.npy'), Train_Losses)  # save the training loss\n",
        "    \n",
        "    model.eval()\n",
        "    # (optional) generate a sample during the training, you can use deterministic mode\n",
        "    # Your code\n",
        "    \n",
        "    \n",
        "    # validation\n",
        "    Val_Losses.append(val(model, val_data_loader, vocab))\n",
        "    np.save(os.path.join(output_dir, 'ValLoss_lstm.npy'), Val_Losses) # save the val loss\n",
        "    \n",
        "    # save model\n",
        "    if Val_Losses[-1] < best_val_loss:\n",
        "        best_val_loss = Val_Losses[-1]\n",
        "        print('updated best val loss:', best_val_loss)\n",
        "        print('Save model weights to...', output_dir)\n",
        "        torch.save(model.state_dict(), \n",
        "                   os.path.join(output_dir, 'pretrain-best.pth'.format(epoch + 1, itr + 1)))\n",
        "\n",
        "print('It took: {} s'.format(time.time() - tic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "Switch to training...\n",
            "Epoch [0/50], Step [0/114], Loss: 9.2032, Perplexity: 9928.9960\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d8fe3e775f0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m#Train_loss_iter = Train_loss_iter+loss.data.detach().cpu().numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m#Train_loss_iter = Train_loss_iter+loss.data.detach().numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mTrain_loss_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_8FfXX28Hi7"
      },
      "source": [
        "## Section 3.2.3 Evaluation [3 pts]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFA_EiHe8Hi7"
      },
      "source": [
        "## Evaluate your model using BLEU score. Use Deterministic mode\n",
        "## Evaluate your model using BLEU score. Use Deterministic mode.\n",
        "# Your code here\n",
        "## evaluation code\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "smoother = SmoothingFunction()\n",
        "\n",
        "def caption_generator(model, images, vocab, img_ids, captions, mode='Deterministic', temperature=1.0):\n",
        "    \"\"\"\n",
        "    Generate captions.\n",
        "    :param mode:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    sample_idxs = model.sample_generate(images, mode=mode,\n",
        "                                        temperature=temperature).data.cpu().numpy()  # [N, max_length]\n",
        "    for i, sentence in enumerate(sample_idxs):  # every sentence in this batch\n",
        "        sentence_caption = ''\n",
        "        for word_idx in sentence:\n",
        "            word = vocab.idx2word[word_idx]\n",
        "            if word != '<start>' and word != '<end>':\n",
        "                if word == '.':\n",
        "                    sentence_caption += '.'\n",
        "                else:\n",
        "                    sentence_caption += word + ' '\n",
        "            if word == '<end>':\n",
        "                break\n",
        "        captions.append({'caption': sentence_caption})\n",
        "        # captions.append(sentence_caption)\n",
        "\n",
        "    return captions\n",
        "\n",
        "def run_test(model, data_loader, vocab, mode='Deterministic', temperature=1.0):\n",
        "    \"\"\"\n",
        "    Run your model on the test set.\n",
        "    Inputs:\n",
        "    :param model: the model you use\n",
        "    :param data_loader: the data_loader\n",
        "    :param mode: use 'deterministic' or 'stochastic'\n",
        "    Outputs:\n",
        "    :param predictions\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    for itr, (images, captions, lengths) in enumerate(tqdm(data_loader)):\n",
        "        images = Variable(images).to(device)\n",
        "        captions = Variable(captions).to(device)\n",
        "        outputs = model(images, captions, lengths)\n",
        "        \n",
        "        img_ids = list(range(itr * data_loader.batch_size, (itr + 1) * data_loader.batch_size))\n",
        "        predictions = caption_generator(model, images, vocab, img_ids, \n",
        "                                        predictions, mode=mode, temperature=temperature)\n",
        "        \n",
        "    return predictions\n",
        "\n",
        "def evaluation(model, vocab, data_path=path_to_homework + '/flickr30k_images/', mode='Deterministic', temperature=1.0,\n",
        "               split='test'):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of your model on the test set using BLEU scores.\n",
        "    Inputs:\n",
        "    :param model: the model you use\n",
        "    :param weight_path: the directory to the weights of your model\n",
        "    :param vocab: vocabulary\n",
        "    :param data_path: the directory to the dataset\n",
        "    :param mode: use 'deterministic' or 'stochastic'\n",
        "    Outputs:\n",
        "    :param predictions\n",
        "    \"\"\"\n",
        "    # data loader\n",
        "    test_data_loader = get_loader(root=path_to_homework + '/flickr30k_images/', split=split, vocab=vocab, \n",
        "                                  transform=transform, batch_size=8, shuffle=False, num_workers=4)\n",
        "    \n",
        "    # run your model on the test set\n",
        "    print('Run on the test set...')\n",
        "    preds = run_test(model, test_data_loader, vocab, mode, temperature)\n",
        "    \n",
        "    # load the groundtruth\n",
        "    gt = test_data_loader.dataset.annos\n",
        "    \n",
        "    # evaluate the performance using BLEU score\n",
        "    score1 = 0\n",
        "    score2 = 0\n",
        "    score3 = 0\n",
        "    score4 = 0\n",
        "    \n",
        "    print('Computing BLEU')\n",
        "    for itr in tqdm(range(len(gt))):\n",
        "        candidate = preds[itr]['caption']\n",
        "        reference = [sent['raw'] for sent in gt[itr]['sentences']]\n",
        "        score1 += sentence_bleu(reference, candidate, weights=(1, 0, 0, 0), smoothing_function=smoother.method1)\n",
        "        score2 += sentence_bleu(reference, candidate, weights=(0, 1, 0, 0), smoothing_function=smoother.method1)\n",
        "        score3 += sentence_bleu(reference, candidate, weights=(0, 0, 1, 0), smoothing_function=smoother.method1)\n",
        "        score4 += sentence_bleu(reference, candidate, weights=(0, 0, 0, 1), smoothing_function=smoother.method1)\n",
        "    \n",
        "    bleu1 = 100 * score1/len(gt)\n",
        "    bleu2 = 100 * score2/len(gt)\n",
        "    bleu3 = 100 * score3/len(gt)\n",
        "    bleu4 = 100 * score4/len(gt)\n",
        "    \n",
        "    return bleu1, bleu2, bleu3, bleu4\n",
        "\n",
        "# End of code"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}